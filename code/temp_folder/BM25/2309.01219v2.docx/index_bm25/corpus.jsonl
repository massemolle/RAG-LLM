[[" Siren’s Song in the AI Ocean:", "A Survey on Hallucination in Large Language Models", "Yue Zhang♠∗, Yafu Li♢ , Leyang Cui♡†, Deng Cai♡ , Lemao Liu♡ Tingchen Fu , Xinting Huang♡ , Enbo Zhao♡ , Yu Zhang♠ , Yulong Chen♢ Longyue Wang♡ , Anh Tuan Luu , Wei Bi♡ , Freda Shi , Shuming Shi♡", "♡ Tencent AI lab ♠ Soochow University ♢Zhejiang University  Renmin University of China  Nanyang Technological University", " Toyota Technological Institute at Chicago", "Abstract", "While large language models (LLMs) have demonstrated remarkable capabilities across a range of downstream tasks, a significant concern revolves around their propensity to exhibit hallucinations: LLMs occasionally generate content that diverges from the user input, contradicts previously generated con- text, or misaligns with established world knowledge", " This phenomenon poses a sub- stantial challenge to the reliability of LLMs in real-world scenarios", " In this paper, we survey recent efforts on the detection, ex- planation, and mitigation of hallucination, with an emphasis on the unique challenges posed by LLMs", " We present taxonomies of the LLM hallucination phenomena and evaluation benchmarks, analyze existing ap- proaches aiming at mitigating LLM halluci- nation, and discuss potential directions for future research", "", "Introduction", "Large language models (LLMs), particularly char- acterized by their substantial number of param- eters, have arisen as a promising cornerstone for the development of natural language pro- cessing (NLP) and artificial intelligence (Zhao et al", ", 2023c)", " With proper alignment techniques, such as supervised finetuning (SFT; Zhang et al", ", 2023b) and reinforcement learning from human feedback (RLHF; Ouyang et al", ", 2022; Fernan- des et al", ", 2023), recent LLMs (OpenAI, 2023a; Touvron et al", ", 2023b; OpenAI, 2023b, inter alia) have exhibited strong capabilities in solving vari- ous downstream tasks", "", "Nonetheless, as exemplified in Figure 1, LLMs, despite their remarkable success, occasionally", "∗ This survey paper was completed during Yue Zhang (yzhang21@stu", "suda", "edu", "cn), Yafu Li, Tingchen Fu, and Yu Zhang’s internships at Tencent AI Lab", "", "† Corresponding author (leyangcui@tencent", "com)", "", "Figure 1: Three types of hallucinations occurred in LLM responses (best viewed in color).", "produce outputs that, while seemingly plausible, deviate from user input (Adlakha et al", ", 2023), pre- viously generated context (Liu et al", ", 2022), or fac- tual knowledge (Min et al", ", 2023; Muhlgay et al", ", 2023; Li et al", ", 2023a)—this phenomenon is com- monly referred to as hallucination, which signifi- cantly undermines the reliability of LLMs in real- world scenarios (Kaddour et al", ", 2023)", " For in- stance, LLMs can potentially fabricate erroneous medical diagnoses or treatment plans that lead to tangible real-life risks (Umapathi et al", ", 2023)", "", "While hallucination in conventional natural lan- guage generation (NLG) settings has been widely studied (Ji et al., 2023), understanding and ad- dressing the hallucination problem within the realm of LLMs encounters unique challenges in- troduced by", "Massive training data: in contrast to care- fully curating data for a specific task, LLM pre-", "Figure 2: The overview structure of this paper: We initially categorize LLM hallucinations into three distinct types and then introduce corresponding evaluation benchmarks", " Subsequently, we explore the source of hallucinations and discuss mitigation strategies throughout the life cycle of LLMs (pre-training→SFT→RLHF→inference)", "", "training uses trillions of tokens obtained from the web, making it difficult to eliminate fabri- cated, outdated or biased information;", "Versatility of LLMs: general-purpose LLMs are expected to excel in cross-task, cross- lingual, and cross-domain settings, posing challenges for comprehensive evaluation and mitigation of hallucination.", "Imperceptibility of errors: as a byproduct of their strong abilities, LLMs may generate false information that initially seems highly plausi- ble, making it challenging for models or even humans to detect hallucination.", "In addition, the RLHF process (Ouyang et al", ", 2022), the vague knowledge boundary (Ren et al", ", 2023) and the black-box property of LLMs (Sun et al", ", 2022) also complicate the detection, expla- nation, and mitigation of hallucination in LLMs", " There has been a notable upsurge in cutting-edge research dedicated to addressing the aforemen-", "tioned challenges, which strongly motivates us to compile this survey.", "We organize this paper as follows, as also depicted in Figure 2", " We first introduce the background of LLMs and offer our definition of hallucination in LLMs (§2)", " Next, we introduce relevant benchmarks and metrics (§3)", " Subse- quently, we discuss potential sources of LLM hal- lucinations (§4), and provide an in-depth review of recent work towards addressing the problem (§5)", " Finally, we present forward-looking perspectives (§6)", " We will consistently update the related open-source materials, which can be accessed at https://github", "com/HillZhang1999/ llm-hallucination-survey", "", "Hallucination in the Era of LLM", "We begin this section by overviewing the history of LLMs (§2", "1)", " Next, we present our defini- tion of LLM hallucination, by breaking it down", "into three sub-categories (§2", "2)", " In addition, we discuss the unique challenges of hallucination in LLMs (§2", "3), and compare hallucination with other prevalent problems that are frequently en- countered in the realm of LLMs (§2", "4)", "", "Large Language Models", "An important category of LLMs is autoregressive language models (Radford et al", ", 2019; Chowd- hery et al", ", 2022; Touvron et al", ", 2023a, inter alia)", " These models take Transformers (Vaswani et al", ", 2017) as the backbone, and predict the next token based on previous tokens", "1\tPrior to the widespread adoption of Transformers, autoregres- sive language models were built on the backbones of n-grams (Bickel et al", ", 2005; Pauls and Klein, 2011) and recurrent neural networks (Mikolov et al", ", 2010), and have been applied to various NLG tasks such as summarization (Nallapati et al", ", 2017) and dialogue generation (Chen et al", ", 2017)", " Transformer-based LLMs have demonstrated exceptional performance across tasks, and have therefore shifted NLP from a paradigm centered on task-specific solutions to general-purpose pre- training (Devlin et al", ", 2019; Radford et al", ", 2019)", " The pretrained models are optimized on various self-supervision objectives (Devlin et al", ", 2019; Raffel et al", ", 2020; Lewis et al", ", 2020a, inter alia), using large-scale unlabeled corpora", " Sub- sequently, the models are fine-tuned with labeled data on target downstream tasks", " Representations from the pretrained models can typically reduce the demand for annotated data and achieve sig- nificant performance improvement across down- stream tasks (Qiu et al", ", 2020; Min et al", ", 2021;", "Li et al", ", 2022b, inter alia)", "", "In addition to performance improvement on downstream tasks, recent work has found that scal- ing up pretrained language models—both in terms of model parameter count and the volume of pre- training data—enables some remarkable abilities, including in-context learning (Brown et al", ", 2020), reasoning (Wei et al", ", 2022), and instruction fol- lowing (Ouyang et al", ", 2022)", " The community has, to some extent, popularized the term large lan- guage models (LLMs) to differentiate them from their smaller counterparts", " Notably, LLMs exhibit the potential to accurately comprehend human in- structions and efficiently tackle a variety of com-", "1Another variant of language models predicts masked to- kens in a corrupted sequence (Devlin et al", ", 2019; Liu et al", ", 2019; Lan et al", ", 2019, inter alia)", "", "plex tasks with only minimal or even no supervi- sion (OpenAI, 2023a,b; Touvron et al", ", 2023b)", "", "What is LLM Hallucination", "While LLMs have demonstrated remarkable per- formances, they still inevitably encounter different problems in practical applications, where halluci- nation is one of the most significant issues among them", " The term hallucination has already been widely adopted in the NLP community before the emergence of LLM, typically referring to gen- erating nonsensical or unfaithful to the provided source content (Ji et al", ", 2023)", "", "We argue that the definition appears to have considerably expanded due to the versatility of LLMs. To this end, we categorize hallucination within the context of LLMs as follows:", "Input-conflicting hallucination, where LLMs generate content that deviates from the source input provided by users;", "Context-conflicting hallucination, where LLMs generate content that conflicts with previously generated information by itself;", "Fact-conflicting hallucination, where LLMs generate content that is not faithful to estab- lished world knowledge.", "We present examples for each type of hallucina- tions in Table 1, and discuss them in detail below.", "Input-conflicting hallucination", " This type of hallucination arises when the content generated by LLMs deviates from user input", " Typically, user input for LLMs comprises two components: task instruction (e", "g", ", user prompt for summarization) and task input (e", "g", ", document to be summarized)", " The contradiction between LLM response and task instructions typically reflects a misunderstanding of user intents", " In contrast, when the contradiction arises between the generated content and task in- put, the hallucination is in line with the conven- tional definition in specific NLG tasks, such as machine translation (Lee et al", ", 2019) and sum- marization (Maynez et al", ", 2020; Pu et al", ", 2023)", " For instance, the first example in Table 1 appears to highlight a contradiction between the gener- ated content and task input: when users request the LLM to generate a summary, the LLM incor- rectly replaces the person’s name in its response (Hill→Lucas), even though the general form can indeed be perceived as a suitable summary", "", "Input-conflicting Hallucination", "Context-conflicting Hallucination", "Fact-conflicting Hallucination", "User Please summarize the following content: My friend Hill and I love play- ing basketball together", " We spend hours on the court, dribbling, shoot- ing, and competing against each other", " Our passion for this game brings us closer as good friends", "", "Model  Lucas and I love playing basketball and this makes us good friends.", "User  Tell me something about the NBA Commissioner.", "Model In the world’s most popular basketball league, the NBA, Commissioner Adam Silver has long been regarded as a leader and decision-maker", " Firstly, Silver has claimed his dedication to maintaining fairness and competitiveness in the game", " Secondly, Silver has repeatedly empha- sized his concern for player health and well-being", " In this case, Stern’s words and actions clash with his stated goal of caring for player welfare", "", "User  Who was the mother of Afonso II, the third king of Portugal?", "Model  The mother of Afonso II was Queen Urraca of Castile.", "Table 1: Illustrations of the three types of LLM hallucinations that we defined", " For input-conflicting hallucination, the LLM makes a mistake in the person name (Hill⇒Lucas) during summarizing", " For the context-conflicting hallucination, the LLM discusses Silver in the early stage, but later became Stern and resulting in a contradiction", " For the fact-conflicting hallucination, LLMs said the mother of Afonso II was Queen Urraca of Castile, while the correct answer is Dulce Berenguer of Barcelona", "", "Context-conflicting  hallucination", " LLMs may exhibit self-contradictions when generat- ing lengthy or multi-turn responses", " This type of hallucination arises when LLMs lose track of the context or fail to maintain consistency throughout the conversation, potentially due to their limitations in maintaining long-term memory (Liu et al", ", 2023d) or identifying relevant context (Shi et al", ", 2023a)", " The second example in Table 1 demonstrates how a user request to introduce the NBA Commissioner leads to a context-conflicting hallucination", " Specifically, the LLM initially introduces Silver (the current NBA commissioner), but later refers to Stern (the former NBA commissioner), demonstrating a lack of consistency in the generation", "", "Fact-conflicting hallucination", " This type of hallucination occurs when LLMs generate infor- mation or text that contradicts established world knowledge", " The source of fact-conflicting halluci- nations can be multifarious and introduced at dif- ferent stages of the LLM life cycle, as shown in Figure 2", " We present an illustration in Table 1 (third example): in this case, the user asks the LLM about the mother of Afonos II", " The LLM gave a wrong answer (Queen Urraca of Castile instead of Dulce Berenguer of Barcelone), which can easily mislead less knowledgeable users", "", "\tThe focus of recent hallucination re- search in LLMs is predominantly on fact- conflicting hallucination, despite the importance of the other two types", " Possible reasons in- clude but not limited to: (1) input- and context- conflicting hallucinations have been extensively studied in conventional NLG settings (Ji et al", ", 2023)", " However, fact-conflicting hallucination poses more complex challenges in LLMs due to the absence of an authoritative knowledge source as a reference; (2) fact-conflicting hallucinations tend to have more side effects on the practical ap- plications of LLMs, leading to a greater emphasis in recent studies", " In light of this research status, the following sections of our paper will primar- ily concentrate on the fact-conflicting hallucina- tions, and we will explicitly highlight them when addressing the other two types of hallucinations", "", "Unique Challenge in the Era of LLM", "Although the problem of hallucination has been extensively researched in conventional NLG tasks (Ji et al", ", 2023), hallucinations in LLMs bring forth a unique and complex set of challenges stemming from the training process and usage scenarios", "", "Massive training data", " Unlike task-specific NLG models trained on limited-scaled datasets, LLMs are pre-trained on trillions of tokens", " These", "Ambiguity\tUser\tWhat is the capital of France?", "Model\tThe capital of a European country.", "User\tHow can I replace a flat tire on my car?", "Incompleteness", "Bias", "Model\tTo replace a flat tire, there are four steps", " First, you’ll need to use a jack to lift the car", " Second, please remove the lug nuts and flat tire", "", "User\tTell me about a typical elementary school teacher.", "Model\tA typical elementary school teacher is a woman who is patient, nurtur- ing, and skilled at managing a classroom full of young children.", "Under-informativeness\tUser\tIntroduce the most popular task in NLP in 2022.", "Model\tSorry, I don’t know", " Maybe you can check external search engines", "", "Table 2: Examples of various problems that LLMs may expose, in addition to hallucinations.", "pre-training corpora are automatically collected from the web and often contain a significant amount of fabricated, outdated, or biased informa- tion (Penedo et al", ", 2023)", " Such inadequate data may lead LLMs to generate hallucinated content", " The large data scale may also increase the diffi- culty of applying data-centric approaches to miti- gate the hallucination in LLMs", "", "Versatility of LLMs", " Conventional NLG mod- els are typically designed for a single task, and thus, hallucination studies on them are usually task-specific (Maynez et al", ", 2020; Wang and Sen- nrich, 2020; Xiao and Wang, 2021); however, cur- rent LLMs are expected to excel in multi-task, multi-lingual, and multi-domain settings (Bang et al", ", 2023; Chang et al", ", 2023)", " This expectation poses thorny challenges for both the evaluation and mitigation of LLM hallucinations", " In terms of evaluation, LLMs are more commonly used for free-form text generation, and the lack of deter- ministic references in this setting complicates the automatic detection of hallucinations", " Therefore, it is crucial to establish a comprehensive, reliable, and automatic evaluation benchmark", " Regarding mitigation, the proposed methods should be ro- bustly effective, maintaining decent performance when being applied to various scenarios", "", "Invisibility of errors", " Compared to traditional NLG models, LLMs possess a significantly en- hanced writing capability and store a larger vol- ume of knowledge", " Consequently, the false in- formation hallucinated by LLMs often appears highly plausible, to the extent that even humans may feel hard to detect", " This amplifies the diffi-", "culty in detecting and reducing input- and context- conflicting hallucination, as we can no longer re- sort to simple superficial patterns", " Regarding fact- conflicting hallucinations, we also need to con- sider leveraging more knowledge sources for veri- fication", " These factors collectively introduce sub- stantial new challenges", "", "Other Problems in LLMs", "Besides hallucination, LLMs also present other problems", " We outline some common issues below and present examples in Table 2 to help readers distinguish between them and hallucination", "", "Ambiguity", " This type of issue arises when the LLM response is ambiguous, lending itself to mul- tiple interpretations", " The response may not neces- sarily be incorrect, but it falls short of providing a useful answer to the user question (Tamkin et al", ", 2022)", " The first example in Table 2 exemplifies this issue", " The desired answer is ‘Paris’, yet the LLM provides an ambiguous response", "", "Incompleteness", " The incompleteness issue oc- curs when the generated response is incomplete or fragmented", " As demonstrated in the second exam- ple in Table 2, the LLM only informs users of the first two steps in a four-step process for replacing a tire, resulting in an incomplete explanation", "", "Bias", " Bias in LLMs pertains to the manifestation of unfair or prejudiced attitudes within the gener- ated text", " These biases may originate from train- ing data, which frequently encompasses historical texts, literature, social media content, and other sources", " Such sources may inherently mirror so-", "Table 3: Representative benchmarks that can be used for evaluating LLM hallucination including TruthfulQA (Lin et al", ", 2021), FactualityPrompt (Lee et al", ", 2022), FActScore (Min et al", ", 2023), KoLA-KC (Yu et al", ", 2023a), HaluEval (Li et al", ", 2023a) and FACTOR (Muhlgay et al", ", 2023)", " Note that KoLA (Yu et al", ", 2023a) is designed for benchmarking world knowledge of LLMs, where the Knowledge Creating (KC) task can be used to assess hallu- cination", " These benchmarks all focus on the factuality aspect, but diverge in the following aspects: “Evaluation” denotes how these benchmarks evaluate hallucination, either by regarding hallucination as a generation quality metric for LLM generations (Generation, referred to as Gen) or assessing whether the LLM can discriminate be- tween factual and non-factual statements (Discrimination, referred to as Dis); “Task Format” reflects different methods of prompting language models, e", "g", ", knowledge-intensive question answering (QA), task instructions (TI) and context prefixes for text completion (TC)", "", "cietal biases, gender bias, stereotypes, or discrim- inatory beliefs (Navigli et al", ", 2023)", " As shown in the third example in Table 2, the LLM portrays the teacher as a woman, which is a gender bias", "", "Under-informativeness", " This kind of issue refers to the propensity of LLMs to evade answer- ing certain questions or providing specific infor- mation, even when they should be capable of do- ing so", " For instance, due to imperfections in the re- ward model, RLHF may lead to over-optimization of LLMs, potentially leading to a state of under- informativeness (Gao et al", ", 2022)", " An example of this is presented in Table 2, where the LLM de- clines to respond to the user query", "", "Evaluation of LLM Hallucination", "Previous research has primarily concentrated on evaluating hallucination in specific natural lan- guage generation tasks, such as machine transla- tion (Guerreiro et al", ", 2023b; Dale et al", ", 2023), di- alogue generation (Dziri et al", ", 2021), question an- swering (Durmus et al", ", 2020) and text summariza- tion (Kryscinski et al", ", 2020; Maynez et al", ", 2020; Zhong et al", ", 2021)", " These works mainly focus on the input-conflicting hallucination facet, which is relatively easy for human users to identify given the source text, as shown in Table 1", " Recently, studying this kind of hallucination in traditional NLG tasks has seen significant advancements", " However, evaluating them in the setting of LLMs becomes more challenging due to the free-form and often long-form nature of LLM generation", " Regarding context-conflicting hallucination, Cui", "et al", " (2021) and Liu et al", " (2022) evaluate mod- els’ ability to identify context conflicts introduced when BERT (Devlin et al", ", 2019) performs blank- filling", " Most benchmarks today evaluate the fact- conflicting hallucination of LLMs (Lin et al", ", 2021; Lee et al", ", 2022; Min et al", ", 2023; Yu et al", ", 2023a; Li et al", ", 2023a; Muhlgay et al", ", 2023), which refers to their tendency to generate factual errors", " This is considered a critical issue in LLMs because it is challenging for users to identify and poses real-life risks", "", "In the upcoming sections, we will review exist- ing benchmark datasets and commonly used eval- uation metrics in §3", "1 and §3", "2, respectively", "", "Evaluation Benchmarks", "Various benchmarks have been proposed for eval- uating hallucination in LLMs", " We present repre- sentative ones in Table 3 and discuss them based on their evaluation formats, task formats, and con- struction methods below", "", "Evaluation format", " Existing benchmarks mainly evaluate hallucinations based on two different abilities of LLMs: the ability to generate factual statements or to discriminate them from non-factual ones", " We present an example in Table 4 to showcase the difference between the two evaluation formats", " Generation benchmarks (Lin et al", ", 2021; Lee et al", ", 2022; Min et al", ", 2023; Yu et al", ", 2023a) consider hallucination as a gen- eration characteristic, similar to fluency (Napoles et al", ", 2017) and coherence (Du et al", ", 2022), and evaluate the generated texts from LLMs", " For", "Generation", "Question: What happens to you if you eat watermelon seeds?", "Reference: Nothing happens; You eat watermelon seeds; The watermelon seeds pass through your digestive system; You will not digest the watermelon seeds; The water- melon seeds will be excreted; There is an old wives’ tale that watermelons will grow in your stomach, but this is impossible.", "Discrimination\tQuestion: What happens to you if you eat watermelon seeds?", "Choices:", "The watermelon seeds pass through your digestive system", "You grow watermelons in your stomach", "You get sick", "You have bad dreams", "Reference: (A) The watermelon seeds pass through your digestive system.", "Table 4: Illustrative examples of two methods for evaluating hallucinations (Generation v", "s", " Discrimination)", "", "instance, TruthfulQA (Lin et al", ", 2021) evaluates the truthfulness of LLMs’ responses to questions, while FActScore (Min et al", ", 2023) scrutinizes the factual accuracy of biographies generated by LLMs for specific individuals", " In contrast, discrimination benchmarks (Li et al", ", 2023a; Muhlgay et al", ", 2023) consider LLMs’ ability to discriminate truthful statements from hallucinated ones", " Specifically, HaluEval (Li et al", ", 2023a) requires the model to determine whether a state- ment contains hallucinated information, while FACTOR (Muhlgay et al", ", 2023) investigates whether the LLM assigns a higher likelihood to the factual statement compared to non-factual ones", " Note that TruthfulQA (Lin et al", ", 2021) also supports discrimination format by offering a multiple-choice alternative to test a model’s ability to identify truthful statements", "", "Task format", " Existing benchmarks evaluate LLM hallucinations across various application tasks", " Firstly, certain benchmarks (Lin et al", ", 2021; Li et al", ", 2023a) explore the issue of hal- lucination in the context of question-answering, evaluating the ability of LLMs to provide truthful answers to knowledge-intensive questions", " Sec- ondly, FActScore (Min et al", ", 2023) and HaluE- val (Li et al", ", 2023a) employ task instructions, such as biography introduction instructions and 52K instructions from the Alpaca project (Taori et al", ", 2023), to prompt LLMs to generate re- sponses", " The factuality of these responses is then evaluated", " Thirdly, a line of work (Lee et al", ", 2022; Muhlgay et al", ", 2023) directly prompts LLMs to complete text given a prefix, and diagnoses po-", "tential hallucination during the generation of in- formative and factual statements", " For instance, FACTOR (Muhlgay et al", ", 2023) considers con- text prefixes in Wikipedia documents, while Fac- tualityPrompt (Lee et al", ", 2022) designs prefixes specifically for factual or non-factual statements to elicit hallucinations", " Table 5 provides samples under different task formats", "", "Construction methods", " Most aforementioned benchmarks involve human annotators for dataset creation or quality assurance", " TruthfulQA (Lin et al", ", 2021) carefully designs the questions to elicit imitative falsehoods, i", "e", ", false statements with a high likelihood on the training distribu- tion", " They then hire human annotators to fur- ther validate the agreement of golden answers", " FActScore (Min et al", ", 2023) conducts a man- ual annotation pipeline to transform a long-form model generation into pieces of atomic statements", " HaluEval (Li et al", ", 2023a) employs two construc- tion methods", " For the automatic generation track, they design prompts to query ChatGPT to sam- ple diverse hallucinations and automatically fil- ter high-quality ones", " For the human-annotation track, they hire human annotators to annotate the existence of hallucination in the model responses and list the corresponding spans", " FACTOR (Muhl- gay et al", ", 2023) first uses external LLMs to gen- erate non-factual completion", " Then, they man- ually validate whether the automatically created datasets meet the predefined requirements, i", "e", ", they should be non-factual, fluent, and similar to the factual completion", " To construct knowledge creation task, Yu et al", " (2023a) build an annota-", "Question Answering Question: The DutchBelgian television series that “House of Anubi” was based on first aired in what year?", "Answer: 2006", "Task Instruction\tInstruction: Give me 3 useful websites for C programming.", "Response:", "GeeksforGeeks: This website provides tutorials and practice problems on C pro- gramming.", "Programiz: This website offers tutorials, practice problems, and quizzes on C pro- gramming.", "Codeacademy: This website provides free interactive tutorials on C programming.", "Text Completion\tContext: “Sorry” is a song by American singer Madonna from her tenth studio album Confessions on a Dance Floor (2005)", " It was written and produced by Madonna and Stuart Price, and released as the second single from the album on February 7, 2006", " It later appeared on Celebration, her 2009 greatest hits album", " An uptempo dance song, “Sorry” was one of the first tracks developed for the album and had numerous remix treatments before the ultimate version of the track was finalized", "", "Completion: One of the remixes was done by the known band the Pet Shop Boys, featuring added lyrics by the band", "Table 5: Illustrative examples for the task format where existing benchmarks evaluate hallucinations.", "tion platform to facilitate fine-grained event anno- tations.", "Evaluation Metrics", "The free-form and open-ended nature of language generation makes it difficult to evaluate the hal- lucinations produced by LLMs", " The most com- monly used and reliable methods for evaluating hallucinations rely on human experts following specific principles (Lin et al", ", 2021; Lee et al", ", 2022; Min et al", ", 2023; Li et al", ", 2023a)", " It is worth noting that although existing benchmarks use hu- man evaluation to ensure reliability, they also seek to support automatic methods to facilitate effi- cient and consistent evaluation", "", "Human evaluation", " To ensure precise and re- liable evaluation, existing benchmarks focus on designing dedicated human evaluation principles that involve manual annotation for evaluating each model-generated text", " TruthfulQA (Lin et al", ", 2021) proposes a human-annotation guideline, which instructs annotators to assign one of thir- teen qualitative labels to the model output and ver- ify answers by consulting a reliable source", " Lee et al", " (2022) conduct human annotation to ver- ify the validity of the proposed automatic evalua- tion metrics", " FactScore (Min et al", ", 2023) requires annotators to assign three labels to each atomic", "fact: \"Supported\" or \"Not-supported\" for facts that are supported or unsupported by the knowledge source, and \"Irrelevant\" for statements that are not related to the prompt", " While human evaluation of- fers reliability and interpretability, it may be in- consistent due to subjectivity across annotators", " It is also prohibitively expensive due to the labor- intensive annotation processes required each time a new model needs to be evaluated", "", "Model-based automatic evaluation", " Several studies (Lin et al", ", 2021; Min et al", ", 2023; Zha et al", ", 2023; Mündler et al", ", 2023) have devised model-based methods as a proxy for human eval- uation", " Specifically, TruthfulQA (Lin et al", ", 2021) trains a GPT-3-6", "7B model to classify answers (as true or false) to questions based on their col- lected human annotations", " They observe that the fine-tuned GPT-judge model achieves a validation accuracy of 90-96% and effectively generalizes to new answer formats", " AlignScore (Zha et al", ", 2023) establishes a unified function to evaluate the factual consistency between two texts", " This alignment function is trained on a large dataset spanning seven tasks, including Natural Language Inference (NLI), Question Answering (QA), and paraphrasing", " Differently, Min et al", " (2023) and Mündler et al", " (2023) harness the capabilities of off-the-shelf models to serve as automatic evalu-", "ators", " In particular, FactScore (Min et al", ", 2023) begins by employing a passage retriever, such as Generalizable T5-based Retrievers (Ni et al", ", 2022), to gather pertinent information", " Subse- quently, an evaluation model, such as LLaMA- 65B (Touvron et al", ", 2023a), uses the retrieved knowledge to determine the truthfulness of a state- ment", " They further adopt micro F1 scores and er- ror rates to assess the reliability of the automatic metrics in comparison with human evaluation", " Mündler et al", " (2023) design dedicated prompts to query an evaluator LLM (e", "g", ", ChatGPT (OpenAI, 2023a)) whether the subjective LLM contradicts itself under the same context, and report classifi- cation metrics, including precision, recall, and F1 score", "", "Rule-based automatic evaluation", " For discrim- ination benchmarks (Li et al", ", 2023a; Muhlgay et al", ", 2023), common rule-based classification metrics such as accuracy can be directly applied to evaluating the ability of LLMs to discriminate factual statements from non-factual ones", " Bang et al", " (2023) also compute accuracy to reflect the model’s ability to identify misinformation on sci- entific and social claims related to COVID-19", " In contrast, another line of research (Lee et al", ", 2022; Yu et al", ", 2023a) focuses on devising heuristic methods specifically designed for assessing hal- lucination", " FactualityPrompt (Lee et al", ", 2022) combines named-entity-based metric and textual entailment-based metric to capture different as- pects of factuality", " To evaluate knowledge cre- ation, Yu et al", " (2023a) devise a self-contrast met- ric to quantify model consistency in generating factual statements", " They accomplish this by com- paring model-generated texts with and without in- cluding golden knowledge as part of the prompts based on Rouge-L (F1) (Lin, 2004)", "", "Sources of LLM Hallucination", "In this section, we aim to explore the various fac- tors that can induce hallucinations within LLMs", " We identify four primary sources that span differ- ent stages of the LLM life cycle", "", "LLMs lack relevant knowledge or internalize false knowledge", " During the pre-training phase, LLMs amass a vast amount of knowledge from an enormous volume of training data, which is then stored within their model parameters", " When asked to answer questions or complete tasks, LLMs of-", "ten exhibit hallucinations if they lack pertinent knowledge or have internalized false knowledge from the training corpora.", "Li et al", " (2022c) discover that LLMs sometimes misinterpret spurious correlations, such as posi- tionally close or highly co-occurring associations, as factual knowledge", " Specifically, McKenna et al", " (2023) investigate the hallucination prob- lem within the context of the natural language inference (NLI) task and find a strong correla- tion between LLM hallucination and the distri- bution of the training data", " For example, they observe that LLMs are biased toward affirm- ing test samples where the hypotheses are at- tested in the training data", " Besides, Dziri et al", " (2022) argue that hallucination is also present in human-generated corpora (can be reflected as out- dated (Liska et al", ", 2022; Luu et al", ", 2022), bi- ased (Chang et al", ", 2019; Garrido-Muñoz et al", ", 2021), or fabricated (Penedo et al", ", 2023) expres- sion)", " As a result, LLMs are prone to replicate or even amplify this hallucination behavior", " Wu et al", " (2023b) reveal that the memorizing and reason- ing performance of PLMs for ontological knowl- edge is less than perfect", " Sun et al", " (2023a) put forward a benchmark named Head-to-Tail to eval- uate the factual knowledge of LLMs for entities with different levels of popularity", " Experimental results suggest that LLMs still perform unsatisfac- torily on torso and tail facts", " Furthermore, Zheng et al", " (2023c) identified two additional abilities as- sociated with knowledge memorization that en- able LLMs to provide truthful answers: knowledge recall and knowledge reasoning", " Deficiencies in either of these abilities can lead to hallucinations", "", "LLMs sometimes overestimate their capacities", " Some studies have been conducted with the aim of understanding whether language models can assess the accuracy of their responses and rec- ognize their knowledge boundaries", " Kadavath et al", " (2022) conduct experiments that demon- strate LLMs’ ability to evaluate the correctness of their own responses (self-evaluation) and de- termine whether they know the answer to a given question", " However, for very large LLMs, the distribution entropy of correct and incorrect an- swers could be similar, suggesting that LLMs are equally confident when generating incorrect an- swers as they are generating correct ones", " Yin et al", " (2023) also evaluate the capacity of pop- ular LLMs to identify unanswerable or unknow-", "able questions", " Their empirical study reveals that even the most advanced LLM, GPT4 (OpenAI, 2023b), shows a significant performance gap when compared to humans", " Ren et al", " (2023) note a correlation between accuracy and confidence, but such confidence often surpasses the actual capa- bilities of LLMs, namely over-confidence", " In gen- eral, LLMs’ understanding of factual knowledge boundaries may be imprecise, and they frequently exhibit over-confidence", " Such over-confidence misleads LLMs to fabricate answers with unwar- ranted certainty", "", "Problematic alignment process could mislead LLMs into hallucination", " LLMs typically un- dergo an alignment process following pre-training, where they receive further training on curated instruction-following examples to align their re- sponses with human preferences", " However, when trained on instructions for which LLMs have not acquired prerequisite knowledge from the pre- training phase, this is actually a misalignment pro- cess that encourages LLMs to hallucinate (Gold- berg, 2023; Schulman, 2023)", " Another potential issue is sycophancy, where LLMs may generate responses that favor the user’s perspective rather than providing correct or truthful answers, which can result in hallucination (Perez et al", ", 2022; Rad- hakrishnan et al", ", 2023; Wei et al", ", 2023b)", "", "The generation strategy employed by LLMs has potential risks", " Today’s most advanced LLMs generate responses sequentially, outputting one token at a time", " Zhang et al", " (2023a) discover that LLMs sometimes over-commit to their early mistakes, even when they recognize they are in- correct", " In other words, LLMs may prefer snow- balling hallucination for self-consistency rather than recovering from errors", " This phenomenon is known as hallucination snowballing", " Azaria and Mitchell (2023) also contend that local opti- mization (token prediction) does not necessarily ensure global optimization (sequence prediction), and early local predictions may lead LLMs into situations where it becomes challenging to formu- late a correct response", " Lee et al", " (2022) highlight that the randomness introduced by sampling-based generation strategies, such as top-p and top-k, can also be a potential source of hallucination", "", "GLM (Zeng et al., 2022)\t400B tokens", "BLOOM (Scao et al., 2022)\t366B tokens", "GPT-3 (Brown et al", ", 2020)\t300B tokens LLaMA (Touvron et al", ", 2023a)\t 1", "4T tokens Llama 2 (Touvron et al", ", 2023b)\t\t2T tokens", "Table 6: The pre-training data size of popular LLMs.", "Mitigation of LLM Hallucination", "In this section, we provide an extensive review of recent studies focused on mitigating LLM halluci- nations", " To make the structure clear, we categorize existing mitigation works based on the timing of their application within the LLM life cycle", "", "Mitigation during Pre-training", "Existing work (Zhou et al", ", 2023a) argues that the knowledge of LLMs is mostly acquired during the pre-training phase", " The presence of noisy data such as misinformation in the pre-training corpus could corrupt the parametric knowledge of LLMs, which is a significant factor contributing to hallu- cinations, as previously discussed in § 4", " Akyürek et al", " (2022) also demonstrate that it is possible to trace the factual knowledge acquired by language models back to their training data", " Consequently, an intuitive approach to mitigating hallucinations could involve manually or automatically curating the pre-training corpus to minimize unverifiable or unreliable data as much as possible", "", "Before the LLM era, there existed a series of efforts dedicated to manually eliminating noisy training data to mitigate hallucinations", " For in- stance, Gardent et al", " (2017) focus on the data-to- text task and enlist human annotators to manually compose clean and accurate responses based on given knowledge bases", " It has been shown to ef- fectively reduce hallucinations with such curated training data", " Similarly, Wang (2019) manually refine the text in existing table-to-text datasets and observe that this process also substantially alle- viates fact hallucinations", " Besides, Parikh et al", " (2020) instruct annotators to revise verified sen- tences from Wikipedia rather than directly creat- ing new sentences when constructing table-to-text training data", " This approach has also been proven to result in improved factuality of results", "", "With the advent of the LLM era, curating train- ing data during pre-training has become increas- ingly challenging due to the vast scale of pre- training corpora (as exemplified in Table 6). For", "Alpaca (Taori et al", ", 2023)\t\t52k samples GPT4-Alpaca (Peng et al", ", 2023b) 52k samples Baize (Xu et al", ", 2023)\t210k samples Dolly (Conover et al", ", 2023)\t\t15k samples Open-assistant (Köpf et al", ", 2023) 34k samples LIMA (Zhou et al", ", 2023a)\t\t\t1k samples", "Table 7: The size of popular SFT datasets.", "instance, Llama 2 (Touvron et al", ", 2023b) conducts pre-training on about two trillion tokens", " There- fore, compared to manual curation, a more practi- cal approach today could be automatically select- ing reliable data or filtering out noisy data", " For example, the pre-training data of GPT-3 (Brown et al", ", 2020) is cleaned by using similarity to a range of high-quality reference corpora", " The de- velopers of Falcon (Penedo et al", ", 2023) carefully extract high-quality data from the web via heuris- tic rules and prove that properly curated pertaining corpora lead to powerful LLMs", " Li et al", " (2023f) propose phi-1", "5, a 1", "3 billion parameter LLMs pre-trained on filtered “textbook-like” synthetic data, which exhibits many traits of much larger LLMs", " In order to mitigate hallucinations, current LLMs tend to collect pre-training data from credi- ble text sources", " The developers of Llama 2 (Tou- vron et al", ", 2023b) strategically up-sample data from highly factual sources, such as Wikipedia, when constructing the pre-training corpus", " Lee et al", " (2022) propose to prepend the topic pre- fix to sentences in the factual documents to make each sentence serve as a standalone fact during pre-training", " Concretely, they treat the document name as the topic prefix and observe this method improves LMs’ performance on TruthfulQA", "", "Summary & Discussion", " The mitigation of hal- lucinations during pre-training is primarily cen- tred around the curation of pre-training corpora", " Given the vast scale of existing pre-training cor- pora, current studies predominantly employ sim- ple heuristic rules for data selection and filtering", " A potential avenue for exploration could be devis- ing more effective selection or filtering strategies", "", "Mitigation during SFT", "As a common practice, current LLMs collec- tively undergo the process known as supervised fine-tuning (SFT) to elicit their knowledge ac- quired from pre-training and learn how to inter- act with users (Wang et al", ", 2023c; Zhang et al", ",", "Figure 3: The SFT data usually contains samples that exceed LLMs’ parametric knowledge, which may re- sult in hallucinations.", "2023b)", " SFT generally involves first annotating or collecting massive-task instruction-following data (Chung et al", ", 2022; Taori et al", ", 2023), followed by fine-tuning pre-trained foundational LLMs on this data using maximum likelihood es- timation (MLE) (Wei et al", ", 2021)", " By employing well-designed SFT strategies, many recent stud- ies claim to have built LLMs that achieve perfor- mance on par with ChatGPT (Wang et al", ", 2023b)", "", "Similar to pre-training, one potential approach to reduce hallucination during the SFT stage could be curating the training data", " Given the rela- tively small volume of SFT data (refer to Table 7), both manual and automatic curation are viable options here", " Zhou et al", " (2023a) have meticu- lously constructed an instruction-tuning dataset, comprising 1,000 samples annotated by human ex- perts", " Some other studies (Chen et al", ", 2023b; Cao et al", ", 2023; Lee et al", ", 2023) have employed an automatic selection of high-quality instruction- tuning data, by leveraging LLMs as evaluators or designing specific rules", " Experimental results on hallucination-related benchmarks, such as Truth- fulQA (Lin et al", ", 2021), suggest that LLMs fine- tuned on such curated instruction data demonstrate higher levels of truthfulness and factuality com- pared to LLMs fine-tuned on uncurated data", " Fur- thermore, Mohamed et al", " (2023) propose the inte- gration of domain-specific knowledge sets into the SFT data, which aims to reduce hallucinations that arise from a lack of relevant knowledge", "", "It is worth noting that Schulman (2023) under- scored a potential risk of the SFT process that it could induce hallucination from LLMs due to behavior cloning", " Behavior cloning is a concept in reinforcement learning (Torabi et al", ", 2018), which means the model learns directly from im- itating the expert’s actions", " The problem here is", "that this method simply mimics behavior without learning a strategy to achieve the final goal", " The SFT process of LLMs can be viewed as a spe- cial case of behavior cloning, where LLMs learn the format and style of interaction by mimicking humans", " As for LLMs, despite having encoded a substantial amount of knowledge into their pa- rameters, there remains knowledge that surpasses their capacity (Yin et al", ", 2023; Ren et al", ", 2023)", " By cloning human behaviors during SFT, LLMs learn to respond to all questions with a predom- inantly positive tone, without assessing whether these questions exceed their knowledge bound- aries (see Figure 3)", " As a result, during inference, if prompted to answer questions related to un- learned knowledge, they are likely to confidently produce hallucinations", " One way to remit this problem can be the honesty-oriented SFT, which means introducing some honest samples into the SFT data", " The honest samples refer to responses that admit incompetence, such as “Sorry, I don’t know”", " The Moss project (Sun et al", ", 2023b) open- sourced their SFT data, which includes such hon- est samples", " We observed that models tuned with them could learn to refuse to answer specific ques- tions, therefore helping reduce hallucinations", "", "Summary & Discussion", " Curating the training data is one approach for mitigating hallucinations during the SFT phase", " Thanks to the acceptable volume of SFT data, they can be manually curated by human experts", " Recently, we have performed a preliminary human inspection and observed that some widely-used synthetic SFT data, such as Al- paca (Taori et al", ", 2023), contains a considerable amount of hallucinated answers due to the lack of human inspection", " This calls for careful attention when researchers try to build SFT datasets based on self-instruct (Wang et al", ", 2023c)", "", "Previous work also pointed out that the SFT process may inadvertently introduce hallucina- tions, by forcing LLMs to answer questions that surpass their knowledge boundaries", " Some re- searchers have suggested honesty-oriented SFT as a solution", " However, we argue this method has two main problems", " Firstly, it exhibits limited gen- eralization capabilities towards out-of-distribution (OOD) cases", " Secondly, the annotated honest samples just reflect the incompetence and uncer- tainty of annotators rather than those of LLMs, as annotators are unaware of LLMs’ real knowledge boundaries", " Such challenges make solving this is-", "Situation\tReward Value", "Unhedged Correct\t+1", "Hedged Correct\t+0.5", "Uninformative\t0", "Hedged Wrong\t-2", "Unhedged Wrong\t-4", "Table 8: An example of reward design for mitigating LLM hallucinations through RL (Schulman, 2023).", "sue during SFT sub-optimal.", "Mitigation during RLHF", "Nowadays, many researchers attempt to fur- ther improve the supervised fine-tuned LLMs via reinforcement learning from human feedback (RLHF) (Fernandes et al", ", 2023)", " This process consists of two steps: 1) train a reward model (RW) as the proxy for human preference, which aims to assign an appropriate reward value to each LLM response; 2) optimize the SFT model with the reward model’s feedback, by using RL algo- rithms such as PPO (Schulman et al", ", 2017)", "", "Leveraging human feedback not only closes the gap between machine-generated content and hu- man preference but also helps LLMs align with desired criteria or goals", " One commonly used criterion today is “3H”, which denotes helpful, honest, and harmless (Ouyang et al", ", 2022; Bai et al", ", 2022; Zheng et al", ", 2023b)", " The hon- est aspect here just refers to the minimization of hallucinations in LLM responses", " Current ad- vanced LLMs, such as InstructGPT (Ouyang et al", ", 2022), ChatGPT (OpenAI, 2023a), GPT4 (Ope-", "nAI, 2023b), and Llama2-Chat (Touvron et al", ", 2023b), have collectively considered this aspect during RLHF", " For example, GPT4 uses synthetic hallucination data to train the reward model and perform RL, which increases accuracy on Truth- fulQA (Lin et al", ", 2021) from about 30% to 60%", " Moreover, Lightman et al", " (2023) use the process supervision to detect and mitigate hallucinations for reasoning tasks, which provides feedback for each intermediate reasoning step", "", "As discussed in the previous section, the phe- nomenon of behavior cloning during the SFT stage can potentially lead to hallucinations", " Some re- searchers have attempted to address this issue by integrating honest samples into the original SFT data", " However, this approach has certain limita- tions, such as unsatisfactory OOD generalization capabilities and a misalignment between human", "System Response", "“The Only Thing” (Four Flaming Days) is a captivating drama film that delves into the complexities of human emotions, relationships, and the power of resilience", " Set against the backdrop of a small town, the story unfolds over the course of four intense, life-changing days that leave an indelible mark on the lives of the characters involved", " The film follows the journey of a young woman, Emily, who returns to her hometown after several years away, only to find it in the grip of an unprecedented crisis", " As the town faces an impending disaster, Emily is forced to confront her own demons, rekindle old friendships, and navigate the intricate web of relationships that tie her to the town’s inhabitants", " As the four days progress, Emily and the people around her are pushed to their limits, as they grapple with love, loss, betrayal, and the harsh realities of life", " The film delves deep into the human psyche, exploring themes of forgiveness, redemption, and the power of human connection in the face of adversity", "", "User Input\tWhat genre of movie is “The Only Thing” (Four Flaming Days)?", "I’m sorry", " As of my last update in September 2021, there is no film titled “The Only Thing” or “Four Flaming Days” that I’m aware of", "", "Table 9: A real example of the over-conservative phenomenon of ChatGPT (July 2023 Version)", " As demonstrated in this example, ChatGPT refuses to provide a fairly clear answer it already knows, specifically, the genre of \"The Only Thing\" being a drama film (highlighted in red within the first response)", "", "and LLM knowledge boundaries", " In light of this, Schulman (2023) propose to solve this problem during RLHF", " They design a special reward func- tion just for mitigating hallucinations, as shown in Table 8", " “Unhedged/Hedged Correct/Wrong” here means the LLM provides correct or wrong answers with a positive or hesitant tone", " “Unin- formative” denote the safe answers like “I don’t know”", " The core idea is to encourage LLMs to challenge the premise, express uncertainty, and commit incapability by learning from specially de- signed rewards", " This method, which we refer to as honesty-oriented RL, offers several advantages over honesty-oriented SFT", " The primary benefit is that it allows LLMs to freely explore their knowl- edge boundaries, thereby enhancing their general- ization capabilities to OOD cases", " Additionally, it reduces the need for extensive human annotation and eliminates the requirement for annotators to guess the knowledge boundaries of LLMs", "", "Summary & Discussion", " Reinforcement learn- ing can guide LLMs in exploring their knowl- edge boundaries, enabling them to decline to an- swer questions beyond their capacity rather than fabricating untruthful responses", " However, we note this approach also poses unique challenges", " For instance, RL-tuned LLMs may exhibit over- conservatism due to an imbalanced trade-off be- tween helpfulness and honesty (Ouyang et al", ", 2022)", " An example of this is illustrated in Ta- ble 9", " As observed in this case, ChatGPT tends to be overly hedged and refrains from providing a clear answer that it already knows, as evidenced in another dialogue turn", " This could be attributed to the unreasonable design of the reward function", "or the poor quality of the training data for the re- ward model", " We hope future work can take such problems into consideration", "", "Mitigation during Inference", "Compared with the aforementioned training-time mitigation approaches, mitigating hallucinations in the inference time could be more cost-effective and controllable", " Therefore, most existing studies focus on this direction, which we will introduce in detail in the following sections", "", "Designing Decoding Strategies", "Decoding strategies, such as greedy decoding and beam search decoding, determine how we choose output tokens from the probability distribution generated by models (Zarrieß et al", ", 2021)", "", "Lee et al", " (2022) carry out a factuality assess- ment of content generated by LLMs using differ- ent decoding strategies", " They find that nucleus sampling (a", "k", "a top-p sampling) (Holtzman et al", ", 2019) falls short of greedy decoding in terms of factuality", " They argue that this underperformance could be attributed to the randomness introduced by top-p sampling to boost diversity, which may inadvertently lead to hallucinations since LLMs tend to fabricate information to generate diverse responses", " In view of this, they introduce a decod- ing algorithm termed factual-nucleus sampling, which aims to strike a more effective balance be- tween diversity and factuality by leveraging the strengths of both top-p and greedy decoding", "", "Dhuliawala et al", " (2023) develop a decoding framework known as the Chain-of-Verification (COVE)", " This framework is based on the obser- vation that independent verification questions typ-", "Table 10: A summary of some recent studies on resorting to external knowledge to mitigate hallucinations", " We use abbreviations for some application task names, including QA (Question Answering), FV (Fact Verification), and LM (Language Modeling)", "", "ically yield more accurate facts than those pre- sented in long-form answers", " The COVE frame- work initially plans verification questions, and then answers these questions to ultimately produce an enhanced, revised response", " Experimental re- sults on list-based questions, closed book QA, and long-form text generation demonstrate that COVE can effectively mitigate hallucination", "", "Another work, Li et al", " (2023b), introduces a novel Inference-Time Intervention (ITI) method to improve the truthfulness of LLMs", " This method is based on the assumption that LLMs possess latent, interpretable sub-structures associated with factu- ality", " The ITI method comprises two steps: 1) fitting a binary classifier on top of each attention head of the LLM to identify a set of heads that ex- hibit superior linear probing accuracy for answer- ing factual questions, and 2) shifting model activa- tions along these factuality-related directions dur- ing inference", " The ITI method leads to a substan- tial performance improvement on the TruthfulQA benchmark (Lin et al", ", 2021)", "", "Distinct from the aforementioned studies, Shi et al", " (2023b) instead concentrates on the retrieval- augmentation setting", " Prior research has shown that LLMs sometimes fail to adequately attend to retrieved knowledge when addressing downstream tasks, particularly when the retrieved knowl- edge conflicts with the parametric knowledge of LLMs (Zhou et al", ", 2023b; Xie et al", ", 2023)", " To address this issue, Shi et al", " (2023b) propose a straightforward context-aware decoding (CAD) strategy", " The core idea of CAD is to perform a contrastive ensemble of pθ(yt | x, c, y<t) and pθ(yt | x, y<t), where θ represents the LM, x is the input query, c is the context, y is the response, and t is the time step", " pθ(yt | x, c, y<t) means the gen- eration probability distribution of t-th token when", "given the context while pθ(yt | x, y<t) denotes the distribution only considering the query", " The CAD method aims to compel LLMs to pay more at- tention to contextual information instead of over- relying their own parametric knowledge to make decisions", " Experimental results show that CAD effectively elicits the ability of LLMs to exploit retrieved knowledge and thus reduces factual hal- lucinations on downstream tasks", " Another work, DoLA (Chuang et al", ", 2023), also employ the idea of contrastive decoding to reduce hallucination", " However, they contrast the generation probabili- ties from different layers of LLMs, as they find that linguistic and factual information is encoded in distinct sets of layers", "", "Summary & Discussion", " Designing decoding strategies to mitigate hallucinations in LLMs dur- ing inference is typically in a plug-and-play man- ner", " Therefore, this method is easy to deploy, mak- ing it promising for practical applications", " How- ever, for this approach, most existing works re- quire accessing the token-level output probabili- ties, while a substantial number of current LLMs can only return generated content through lim- ited APIs (e", "g", ", ChatGPT)", " Consequently, we en- courage future research in this direction to explore within a more strict black-box setting", "", "Resorting to External Knowledge", "Using external knowledge as supplementary ev- idence to assist LLMs in providing truthful re- sponses recently represents a burgeoning solution (Ren et al", ", 2023; Mialon et al", ", 2023)", " This ap- proach typically consists of two steps", " The first step entails accurately obtaining knowledge re- lated to the user instructions", " Once useful knowl- edge has been achieved, the second step involves", "leveraging such knowledge to guide the genera- tion of the responses", " We provide a comprehensive review of the latest progress in this direction, fo- cusing on the specific strategies employed in these two steps, respectively", " We also present a sum- mary of recent studies in Table 4", "", "Knowledge acquisition. LLMs have internal- ized vast amounts of knowledge into their pa-", "User Query", "Knowledge Retriever", "Knowledge", "LLM", "Final Response", "Knowledge Bases", "Code Executor", "Search Engines", "Knowledge Sources", "User Query", "LLM", "Intermediate Response", "Fixer Final Response", "rameters through extensive pre-training and fine- tuning, which can be referred to as parametric", "Generation-time Supplement", "Post-hoc Correction", "knowledge (Roberts et al", ", 2020)", " However, incor- rect or outdated parametric knowledge can easily lead to hallucinations (Xie et al", ", 2023)", " To rem- edy this, researchers have proposed acquiring reli- able, up-to-date knowledge from credible sources as a form of hot patching for LLMs (Lewis et al", ", 2020b; Li et al", ", 2022a)", " We summarize the two primary sources of such knowledge as follows", "", "External knowledge bases", " The major- ity of existing works retrieve information from external knowledge bases, such as large-scale unstructured corpora (Cai et al", ", 2021; Borgeaud et al", ", 2022), structured databases (Liu, 2022; Li et al", ", 2023d), spe- cific websites like Wikipedia (Yao et al", ", 2022; Peng et al", ", 2023a; Li et al", ", 2023c; Yu et al", ", 2023b), or even the entire Inter- net (Lazaridou et al", ", 2022; Yao et al", ", 2022; Gao et al", ", 2023a; Liu et al", ", 2023c)", " The evidence retrieval process typically employs various sparse (e", "g", ", BM25 (Robertson et al", ", 2009)) or dense (e", "g", ", PLM-based meth- ods (Zhao et al", ", 2022)) retrievers", " Search engines, such as Google Search, can also be viewed as a special kind of information re- triever (Nakano et al", ", 2021; Lazaridou et al", ", 2022; Yao et al", ", 2022; Gao et al", ", 2023a)", " Be- sides, Luo et al", " (2023c) propose the param- eter knowledge guiding framework which re- trieves knowledge from the parametric mem- ory of fine-tuned white-box LLMs", " Feng et al", " (2023) try to teach LLMs to search rele- vant domain knowledge from external knowl- edge graphs to answer domain-specific ques- tions", "", "External tools", " In addition to solely retriev- ing information from knowledge bases, there are also many other tools that can provide valuable evidence to enhance the factuality of content generated by LLMs (Mialon et al", ",", "Figure 4: The illustrations of two distinct methods for utilizing external knowledge to reduce hallucinations in LLMs’ responses.", "2023; Qin et al", ", 2023; Qiao et al", ", 2023)", " For instance, FacTool (Chern et al", ", 2023) em- ploys different tools to help detect hallucina- tions in LLMs for specific downstream tasks, such as search engine API for Knowledge- based QA, code executor for code gener- ation, and Google Scholar API for scien- tific literature review", " CRITIC (Gou et al", ", 2023) also enables LLMs to interact with multiple tools and revise their responses au- tonomously, which has been proven to effec- tively improve truthfulness", "", "Knowledge utilization", " Once relevant knowl- edge is obtained, it could be employed at differ- ent stages to mitigate hallucinations within LLMs", " Existing methods for knowledge utilization can be roughly divided into two categories, as detailed below and illustrated in Figure 4", "", "Generation-time supplement", " The most straightforward approach to utilize retrieved knowledge or tool feedback is to directly concatenate them with user queries before prompting LLMs (Shi et al", ", 2023c; Mallen et al", ", 2023; Ram et al", ", 2023)", " This method is both effective and easy to implement", " Such knowledge is also referred to as con- text knowledge (Shi et al", ", 2023b)", " Existing studies have demonstrated that LLMs pos- sess a strong capability for in-context learn- ing (Dong et al", ", 2022), which enables them to extract and utilize valuable information from context knowledge to rectify nonfactual claims they previously generated", "", "Post-hoc correction. Another common prac- tice involves constructing an auxiliary fixer", "to rectify hallucinations during the post- processing stage (Cao et al", ", 2020; Zhu et al", ", 2021; Fabbri et al", ", 2022)", " The fixer can be either another LLM (Peng et al", ", 2023a; Zhang et al", ", 2023d; Chern et al", ", 2023; Gou et al", ", 2023) or a specific small model (Chen et al", ", 2023a)", " Such fix- ers first interact with external knowledge sources to gather sufficient evidence, and then correct hallucinations", " For example, RARR (Gao et al", ", 2023a) directly prompts an LLM to ask questions about the content that needs to be corrected from multiple per- spectives", " Then it uses search engines to re- trieve relevant knowledge", " The LLM-based fixer finally makes corrections based on re- trieved evidence", " The Verify-then-Edit ap- proach (Zhao et al", ", 2023a) aims to enhance the factuality of predictions by post-editing reasoning chains based on external knowl- edge sourced from Wikipedia", " To achieve better performance, LLM-Augmenter (Peng et al", ", 2023a) prompts LLMs to summarize retrieved knowledge before feeding it into the fixer", " Moreover, FacTool (Chern et al", ", 2023) and CRITIC (Gou et al", ", 2023) propose to uti- lize various external tools to obtain evidence for the fixer", "", "Summary & Discussion", " Resorting to external knowledge to mitigate hallucinations in LLMs of- fers several advantages", " Firstly, this method cir- cumvents the need for modifying LLMs, making it a plug-and-play and efficient solution", " Secondly, it facilitates the easy transfer of proprietary knowl- edge (e", "g", ", a company’s internal data) and real- time updated information to LLMs", " Lastly, this approach enhances the interpretability of infor- mation generated by LLMs by allowing the trac- ing of generation results back to the source evi- dence (Gao et al", ", 2023b; Yue et al", ", 2023)", " How- ever, this direction also presents some remaining challenges", " We discuss some of them below", "", "Knowledge verification", " In the era of LLMs, the external knowledge source could extend beyond a single document corpus or a spe- cific website to encompass the entire Internet", " However, the information from the Internet is in the wild, which means they may also be fabricated, or even generated by LLMs them- selves (Alemohammad et al", ", 2023)", " How to", "logit-based method", "verbalize-based method", "consistency-based method", "Figure 5: The illustrations of three typical methods for estimating LLM uncertainty", " In the example of the logit-based method, we use the red/green background to distinct tokens with low/high generation probabili- ties", " In the example of the consistency-based method, the responses are acquired from multiple sampling", "", "verify the authenticity of retrieved knowledge from the Internet is an open and challenging problem to be solved.", "Performance/efficiency of retriever/fixer", " The performance of the retriever/fixer plays a vital role in ensuring the effects of hallu- cination mitigation", " Future work may con- sider jointly optimising the whole working flow (retriever→LLM→fixer) via reinforce- ment learning (Qiao et al", ", 2023) or other techniques", " Besides, the efficiency of the retriever/fixer is another important factor to be considered, as the generation speed of existing LLMs is already a significant bur- den (Ning et al", ", 2023)", "", "Knowledge conflict", " As introduced be- fore, the retrieved knowledge may conflict with the parametric knowledge stored by LLMs (Qian et al", ", 2023)", " Shi et al", " (2023b) reveal that LLMs may fail to sufficiently ex- ploit retrieved knowledge when knowledge conflict happens", " Xie et al", " (2023) take a more cautious look at this phenomenon", " How to fully utilize context knowledge is an under-explored question", " For example, Liu et al", " (2023d) find the performance of retrieval-augmented LLMs significantly de- grades when they must access evidence in the middle of long contexts", "", "Exploiting Uncertainty", "Uncertainty serves as a valuable indicator for de- tecting and mitigating hallucinations during the", "inference process (Manakul et al", ", 2023)", " Typi- cally, it refers to the confidence level of model out- puts (Jiang et al", ", 2021; Huang et al", ", 2023a; Duan et al", ", 2023)", " Uncertainty can assist users in de- termining when to trust LLMs", " Provided that the uncertainty of LLM responses can be accurately characterized, users can filter out or rectify LLMs’ claims with high uncertainty since such claims are more prone to be fabricated ones (Lin et al", ", 2023)", " Generally speaking, methods for estimating the uncertainty of LLMs can be categorized into three types (Xiong et al", ", 2023), as listed below", " To fa- cilitate understanding, we also present illustrative", "examples for these methods in Figure 5.", "Logit-based estimation", " The first method is the logit-based method, which requires ac- cess to the model logits and typically mea- sures uncertainty by calculating token-level probability or entropy", " This method has been widely used in the machine learning commu- nity (Guo et al", ", 2017)", "", "Verbalize-based estimation", " The second is the verbalize-based method, which involves directly requesting LLMs to express their un- certainty, such as using the following prompt: “Please answer and provide your confidence score (from 0 to 100)", "” This method is effective due to the impressive verbal and instruction-following capabilities of LLMs", " Notably, Xiong et al", " (2023) further suggest using chain-of-thoughts prompts (Wei et al", ", 2022) to enhance this method", "", "Consistency-based estimation", " The third is the consistency-based method (Wang et al", ", 2022; Shi et al", ", 2022; Zhao et al", ", 2023a)", " This method operates on the assumption that LLMs are likely to provide logically incon- sistent responses for the same question when they are indecisive and hallucinating facts", "", "Several recent studies have leveraged uncer- tainty estimation for detecting and mitigating hal- lucinations in LLMs", " SELFCHECKGPT (Man- akul et al", ", 2023) is the first framework to detect LLM hallucinations based on uncertainty mea- surement in a zero-resource and black-box set- ting", " They employ a consistency-based approach for uncertainty estimation", " A non-trivial chal- lenge in SELFCHECKGPT is determining how to measure the consistency of different responses", "", "Manakul et al", " (2023) perform experiments with BERTScore (Zhang et al", ", 2019), QA-based met- rics (Wu and Xiong, 2023) and n-gram metrics", " They finally find that a combination of these ap- proaches yields the best results", " Mündler et al", " (2023) directly utilize an additional LLM to as- sess whether two LLM responses are logically contradictory given the same context (Luo et al", ", 2023b), which means at least one of them is hal- lucinated", " Consequently, they employ another LLM to revise such self-contradictory hallucina- tions from two responses", " Agrawal et al", " (2023) further adopt the verbalize-based method to eval- uate the hallucination rate of LLMs for fabricat- ing references", " Varshney et al", " (2023), on the other hand, use the logit-based method to detect false concepts in LLMs’ responses with high un- certainty", " They then fix such content with auxil- iary retrieval-augmented LLMs", "", "Besides, Zhao et al", " (2023b) present a Pareto optimal self-supervision framework", " This frame- work utilizes available programmatic supervision to assign a risk score to LLM responses, which can serve as an indicator of hallucinations", " Luo et al", " (2023a) introduce a pre-detection self-evaluation technique, which aims to evaluate the familiarity of LLMs with the concepts in user prompts and prevent the generation of content about those un- familiar concepts", "", "Summary & Discussion", " Exploiting uncer- tainty to identify and mitigate LLM hallucinations is a promising research direction today", " Three pri- mary approaches exist for estimating the uncer- tainty of LLMs, each presenting its unique chal- lenges", " Firstly, the logit-based method is becom- ing less applicable for modern commercial LLMs as they are usually closed-source and black-box, rendering their output logits inaccessible", " Sec- ondly, regarding the verbalize-based method, re- searchers have observed that LLMs tend to display a high degree of overconfidence when expressing their confidence (Xiong et al", ", 2023)", " Thirdly, the effective measurement of the consistency of differ- ent responses remains an unresolved issue in the consistency-based method (Manakul et al", ", 2023)", " We believe that leveraging uncertainty is crucial in developing trustworthy LLMs and encourage fu- ture research to address the aforementioned chal- lenges in this field", "", "Figure 6: An example of the process of multi-agent in- teraction for mitigating LLM hallucinations.", "Other Methods", "In addition to the above approaches, other tech- niques demonstrating the potential for reducing hallucinations are shown below.", "Multi-agent interaction", " Some recent research has sought to address the hallucination problem in LLMs from a multi-agent perspective, wherein multiple LLMs (also known as agents) indepen- dently propose and collaboratively debate their re- sponses to reach a single consensus, as exempli- fied in Figure 6", " Du et al", " (2023) is a pioneer- ing work in this line", " They initially developed a benchmark for assessing the factual accuracy of prominent computer scientist biographies gener- ated by LMs", " Their findings reveal that an indi- vidual LLM can easily generate hallucinated in- formation within this benchmark; however, such hallucinations can be mitigated by engaging mul- tiple LLMs in a debate to achieve consensus", " Be- sides, Cohen et al", " (2023) ask one LLM to gen- erate claims (acting as EXAMINEE) and another to raise questions about these claims and check the truthfulness of them (acting as EXAMINER)", " Wang et al", " (2023d) instead propose prompting a single LLM to identify, simulate, and iteratively self-collaborate with multiple personas, such as Harry Potter Fan and Jay Chou Fan", " By leverag- ing an LLM as a cognitive synergist, it effectively reduces hallucinations with relatively low costs", "", "Prompt engineering", " Existing research high- lights that the behavior of LLMs can significantly vary based on the prompts given by users (Si et al", ", 2022; Zhu et al", ", 2023)", " In terms of hallucina- tion, users may encounter an LLM that initially responds accurately but begins to hallucinate in- formation when using different prompts", " In light of this observation, Zhang et al", " (2023a) endeav- our to engineer more effective prompts to mitigate hallucination", " Concretely, they employ the chain- of-thought prompt (Wei et al", ", 2022) to compel LLMs to generate reasoning steps before provid- ing the final answers", " However, chain-of-thought may introduce some new challenges", " The po- tential of hallucinated reasoning steps is one of them", " Furthermore, a popular practice nowadays involves explicitly instructing LLMs not to dis- seminate false or unverifiable information when designing the “system prompt”, i", "e", ", the special messages used to steer the behavior of LLMs", " The following system prompt used for Llama 2- Chat (Touvron et al", ", 2023b) exemplifies this ap- proach: If you don’t know the answer to a ques- tion, please don’t share false information", "", "Analyzing LLMs’ internal states", " Azaria and Mitchell (2023) contend that LLMs may be aware of their own falsehoods, implying that their in- ternal states could be utilized to detect halluci- nations", " They propose Statement Accuracy Pre- diction based on Language Model Activations (SAPLMA), which adds a classifier on top of each hidden layer of the LLM to determine truthful- ness", " Experimental results indicate that LLMs might “know” when the statements they gener- ate are false, and SAPLMA can effectively ex- tract such information", " The Inference-Time In- tervention (ITI) method (Li et al", ", 2023b) is also grounded in a similar hypothesis", " They further shift model activations alongside factuality-related heads during inference and discover that this can mitigate hallucinations", " These studies suggest that “the hallucination within LLMs may be more a re- sult of generation techniques than the underlying representation” (Agrawal et al", ", 2023)", "", "Human-in-the-loop", " Zhang et al", " (2023c) posit that a potential cause of hallucination in LLMs could be the misalignment between knowledge and user questions, a phenomenon that is par- ticularly prevalent in the context of retrieval- augmented generation (RAG)", " To address this is-", "LLM Response (EN)\tAccording to the 2020 United States Census, the population of Denver, Colorado, is 715,522 ✓", "User Input (ZH)\t根据2020年人口普查，  丹佛的人口是多少？", "LLM Response (ZH)  根据2020年人口普查， 丹佛的人口为73,921 ✗", "LLM Response (ZH)  根据2020年人口普查， 丹佛的人口为704,621 ✗", "Table 11: A real example in which ChatGPT (July 2023 Version) accurately answered a question in English conver- sation but presented hallucinations for the same question when communicating in Chinese (the correct population of Denver in 2020 is 715,522, according to https://en", "wikipedia", "org/wiki/Denver)", "", "sue, they introduce MixAlign, a human-in-the- loop framework that utilizes LLMs to align user queries with stored knowledge, and further en- courages users to clarify this alignment", " By re- fining user queries iteratively, MixAlign not only reduces hallucinations but also enhances the qual- ity of the generated content", "", "Optimizing model architecture", " Several stud- ies have explored modifying the architecture of LMs to mitigate hallucinations", " Examples in- clude the multi-branch decoder (Rebuffel et al", ", 2022) and the uncertainty-aware decoder (Xiao and Wang, 2021)", " Li et al", " (2023g) suggest em- ploying a bidirectional autoregressive architecture in the construction of LLMs, which enables lan- guage modeling from both left-to-right and right- to-left", " They claim that this design strategy could contribute to the reduction of hallucinations by ef- fectively leveraging bidirectional information", "", "Outlooks", "In this section, we discuss a few unresolved chal- lenges in the investigation of hallucinations within LLMs and offer our insights into potential future research directions.", "Reliable evaluation", " Although considerable ef- fort has been dedicated to building evaluation benchmarks for quantitatively assessing halluci- nation in LLMs, there are still issues that need to be solved", " The automatic evaluation in the generation-style hallucination benchmark cannot accurately reflect the performance or align with human annotation", " Such inaccuracy is reflected in two ways: (1) The automatic metric does not perfectly align with human annotations (Lin et al", ", 2021; Min et al", ", 2023; Muhlgay et al", ", 2023); (2) The reliability of automatic metric varies across texts from different domains or generated by dif- ferent LLMs (Min et al", ", 2023), resulting in re- duced robustness for generalization", " Although the", "discrimination-style benchmark (Li et al", ", 2023a; Muhlgay et al", ", 2023) could relatively accurately evaluate a model’s ability to distinguish hallucina- tions, the relationship between discrimination per- formance and generation performance is still un- clear until now", " These issues all need more in- depth exploration", "", "Multi-lingual hallucination", " Existing work in LLM hallucination primarily focuses on English, despite the existence of thousands of languages in the world", " We hope that LLMs can possess the ability to handle various languages uniformly", " Some previous studies have investigated the per- formance of LLMs on some multi-lingual bench- marks (Ahuja et al", ", 2023; Lai et al", ", 2023), and collectively found that their performance degen- erates when generalizing to non-Latin languages", " In terms of the hallucination problem, Guerreiro et al", " (2023a) observe that multi-lingual LLMs predominantly struggle with hallucinations in low- resource languages in the translation task", " Po- tential follow-up work could include systemati- cally measuring and analyzing LLM hallucina- tions across a wide variety of languages", " As shown in Table 11, we find that LLMs such as ChatGPT provide accurate answers in English but expose hallucinations in other languages, leading to mul- tilingual inconsistencies", " The transfer of knowl- edge within LLMs from high-resource languages to low-resource ones also presents an interesting and promising research direction", "", "Multi-modal hallucination", " In an effort to im- prove the performance of complex multi-modal tasks, recent studies have proposed replacing the text encoder of existing vision-large models with LLMs, resulting in large vision-language mod- els (LVLMs) (Liu et al", ", 2023b; Ye et al", ", 2023)", " Despite their success, some research reveals that LVLMs inherit the hallucination problem from LLMs and exhibit more severe multi-modal hal-", "Figure 7: An example of object hallucination in LVLMs", " We highlight the hallucination in red, as there is no person under the tree in this picture", "", "lucinations compared to smaller models", " For in- stance, Li et al", " (2023e) discuss the object halluci- nation of LVLMs, wherein LVLMs generate con- tent containing objects that are inconsistent with or absent from the input image, such as the ex- ample in Figure 7", " To effectively measure ob- ject hallucinations generated by LVLMs, Liu et al", " (2023a) propose a GPT4-Assisted Visual Instruc- tion Evaluation (GAVIE) benchmark", " Gunjal et al", " (2023) introduce a multi-modal hallucination de- tection dataset named M-HalDetect, further study the unfaithful descriptions and inaccurate rela- tionships beyond object hallucinations in LVLMs", " Furthermore, in addition to images, some stud- ies have extended LLMs to other modalities such as audio (Wu et al", ", 2023a; Su et al", ", 2023) and video (Maaz et al", ", 2023), making it interesting to investigate hallucination in these new scenarios", "", "Model editing", " As elaborated in § 4, hallucina- tions in LLMs may primarily stem from the mem- orization of false information or the absence of correct factual knowledge", " To mitigate these is- sues in LLMs with minimal computational over- head, the concept of model editing has been in- troduced (Sinitsin et al", ", 2020; De Cao et al", ", 2021)", " This approach involves modifying the be- havior of models in a manner that is both data- and computation-efficient", " At present, there are two mainstream paradigms for model editing", " The first involves the incorporation of an auxiliary sub-network (Mitchell et al", ", 2022; Huang et al", ",", "2023b), while the second entails direct modifi- cation of the original model parameters (Meng et al", ", 2022a,b)", " This technique may be instrumen- tal in eliminating LLMs’ hallucinations by editing their stored factual knowledge in purpose (Lan- ham et al", ", 2023; Onoe et al", ", 2023)", " How- ever, this emerging field still faces numerous chal- lenges", " These could include editing black-box LLMs (Murty et al", ", 2022), in-context model edit- ing (Zheng et al", ", 2023a), and multi-hop model editing (Zhong et al", ", 2023), etc", "", "Attack/defense for inducing hallucination", " As previously discussed, significant efforts have been undertaken by both researchers and companies to guarantee that LLMs produce truthful responses, ultimately improving the overall user experi- ence", " Cutting-edge commercial LLMs, such as GPT4 (OpenAI, 2023b), appear to have acquired a decent ability to generate proper responses to factuality-related queries", " However, they are not invincible", " Several studies show that LLMs can be manipulated using techniques like meticulously crafted jailbreak prompts to elicit arbitrary desired responses (Wei et al", ", 2023a; Zou et al", ", 2023), in- cluding hallucinations", " Consequently, the attack- ing and defending strategies for inducing halluci- nations could also be a promising research direc- tion", " This is particularly important as the gener- ation of fabricated information could potentially breach relevant laws, leading to the forced shut- down of LLM applications", " This direction is also intimately tied to the robustness of existing hallu- cination mitigation methods", "", "Others", " Given that the current research on hal- lucinations in LLMs is still in its early stages, there are also many other intriguing and promis- ing avenues for further investigation", " For in- stance, researchers have begun to treat LLMs as agents for open-world planning in the pursuit of AGI (Park et al", ", 2023; Wang et al", ", 2023a)", " Ad- dressing the hallucination problem within the con- text of LLMs-as-agents presents brand-new chal- lenges and holds considerable practical value", " Be- sides, analyzing and tracing LLM hallucinations from the linguistic aspect is another interesting re- search topic", " Rawte et al", " (2023) show that the oc- currence of LLM hallucination is closely related to linguistic nuances of the user prompts, such as readability, formality, and concreteness", " We believe all these directions merit thorough explo-", "ration in future research.", "Conclusion", "With their strong understanding and generation ca- pabilities in the open domain, LLMs have gar- nered significant attention from both academic and industrial communities", " However, hallucination remains a critical challenge that impedes the prac- tical application of LLMs", " In this survey, we of- fer a comprehensive review of the most recent ad- vances, primarily post the release of ChatGPT, that aim to evaluate, trace, and eliminate hallucinations within LLMs", " We also delve into the existing chal- lenges and discuss potential future directions", " We aspire for this survey to serve as a valuable re- source for researchers intrigued by the mystery of LLM hallucinations, thereby fostering the practi- cal application of LLMs", "", "Acknowledgments", "We would like to thank Yu Wu and Yang Liu for their valuable suggestions.", "References", "Vaibhav Adlakha, Parishad BehnamGhader, Xing Han Lu, Nicholas Meade, and Siva Reddy", " 2023", " Evaluating correctness and faithfulness of instruction-following mod- els for question answering", " arXiv preprint arXiv:2307", "16877", "", "Ayush Agrawal, Lester Mackey, and Adam Tau- man Kalai", " 2023", " Do language models know when they’re hallucinating references? arXiv preprint arXiv:2305", "18248", "", "Kabir Ahuja, Rishav Hada, Millicent Ochieng, Prachi Jain, Harshita Diddee, Samuel Maina, Tanuja Ganu, Sameer Segal, Maxamed Axmed, Kalika Bali, et al", " 2023", " Mega: Multilin- gual evaluation of generative ai", " arXiv preprint arXiv:2303", "12528", "", "Ekin Akyürek, Tolga Bolukbasi, Frederick Liu, Binbin Xiong, Ian Tenney, Jacob Andreas, and Kelvin Guu", " 2022", " Tracing knowledge in lan- guage models back to the training data", " arXiv preprint arXiv:2205", "11482", "", "Sina Alemohammad, Josue Casco-Rodriguez, Lorenzo Luzi, Ahmed Imtiaz Humayun, Hos- sein Babaei, Daniel LeJeune, Ali Siahkoohi,", "and Richard G Baraniuk", " 2023", " Self-consuming generative models go mad", " arXiv preprint arXiv:2307", "01850", "", "Amos Azaria and Tom Mitchell", " 2023", " The inter- nal state of an llm knows when its lying", " arXiv preprint arXiv:2304", "13734", "", "Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al", " 2022", " Training a help- ful and harmless assistant with reinforcement learning from human feedback", " arXiv preprint arXiv:2204", "05862", "", "Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al", " 2023", " A multitask, multilingual, multi- modal evaluation of chatgpt on reasoning, hal- lucination, and interactivity", " arXiv preprint arXiv:2302", "04023", "", "Steffen Bickel, Peter Haider, and Tobias Scheffer", " 2005", " Predicting sentences using n-gram lan- guage models", " In Proceedings of human lan- guage technology conference and conference on empirical methods in natural language process- ing, pages 193–200", "", "Sebastian Borgeaud, Arthur Mensch, Jordan Hoff- mann, Trevor Cai, Eliza Rutherford, Katie Mil- lican, George Bm Van Den Driessche, Jean- Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al", " 2022", " Improving language models by re- trieving from trillions of tokens", " In Interna- tional conference on machine learning, pages 2206–2240", " PMLR", "", "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al", " 2020", " Language models are few-shot learners", " Ad- vances in neural information processing sys- tems, 33:1877–1901", "", "Deng Cai, Yan Wang, Huayang Li, Wai Lam, and Lemao Liu", " 2021", " Neural machine translation with monolingual translation memory", " In Pro- ceedings of the 59th Annual Meeting of the As- sociation for Computational Linguistics and the 11th International Joint Conference on Natural", "Language Processing (Volume 1: Long Papers), pages 7307–7318.", "Meng Cao, Yue Dong, Jiapeng Wu, and Jackie Chi Kit Cheung", " 2020", " Factual error correc- tion for abstractive summarization models", " In Proceedings of the 2020 Conference on Empir- ical Methods in Natural Language Processing (EMNLP), pages 6251–6258", "", "Yihan Cao, Yanbin Kang, and Lichao Sun", " 2023", " Instruction mining: High-quality instruction data selection for large language models", " arXiv preprint arXiv:2307", "06290", "", "Kai-Wei Chang, Vinodkumar Prabhakaran, and Vicente Ordonez", " 2019", " Bias and fairness in natural language processing", " In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th In- ternational Joint Conference on Natural Lan- guage Processing (EMNLP-IJCNLP): Tutorial Abstracts", "", "Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen, Linyi Yang, Xi- aoyuan Yi, Cunxiang Wang, Yidong Wang, et al", " 2023", " A survey on evaluation of large language models", " arXiv preprint arXiv:2307", "03109", "", "Anthony Chen, Panupong Pasupat, Sameer Singh, Hongrae Lee, and Kelvin Guu", " 2023a", " Purr: Efficiently editing language model hallucina- tions by denoising language model corruptions", " arXiv preprint arXiv:2305", "14908", "", "Hongshen Chen, Xiaorui Liu, Dawei Yin, and Jil- iang Tang", " 2017", " A survey on dialogue systems: Recent advances and new frontiers", " Acm Sigkdd Explorations Newsletter, 19(2):25–35", "", "Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, et al", " 2023b", " Alpagasus: Training a bet- ter alpaca with fewer data", " arXiv preprint arXiv:2307", "08701", "", "I-Chun Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, and Pengfei Liu", " 2023", " Factool: Factuality detection in generative ai – a tool augmented framework for multi-task", "and multi-domain scenarios", "\tarXiv preprint arXiv:2307", "13528", "", "Aakanksha Chowdhery, Sharan Narang, Jacob De- vlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al", " 2022", " Palm: Scaling language modeling with pathways", " arXiv preprint arXiv:2204", "02311", "", "Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James Glass, and Pengcheng He", " 2023", " Dola: Decoding by contrasting layers improves factuality in large language models", " arXiv preprint arXiv:2309", "03883", "", "Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al", " 2022", " Scaling instruction- finetuned language models", " arXiv preprint arXiv:2210", "11416", "", "Roi Cohen, May Hamri, Mor Geva, and Amir Globerson", " 2023", " Lm vs lm: Detecting factual errors via cross examination", " arXiv preprint arXiv:2305", "13281", "", "Mike Conover, Matt Hayes, Ankit Mathur, Jian- wei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin", " 2023", " Free dolly: Introducing the world’s first truly open instruction-tuned llm", "", "Leyang Cui, Yu Wu, Shujie Liu, and Yue Zhang", " 2021", " Knowledge enhanced fine-tuning for bet- ter handling unseen entities in dialogue genera- tion", " In EMNLP", "", "David Dale, Elena Voita, Loïc Barrault, and Marta R", " Costa-jussà", " 2023", " Detecting and mit- igating hallucinations in machine translation: Model internal workings alone do well, sen- tence similarity even better", " In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Pa- pers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 36–50", " Association for Computa- tional Linguistics", "", "Nicola De Cao, Wilker Aziz, and Ivan Titov", " 2021", " Editing factual knowledge in language models", " In Proceedings of the 2021 Conference on Em- pirical Methods in Natural Language Process- ing, pages 6491–6506", "", "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova", " 2019", " BERT: Pre-training of deep bidirectional transformers for language understanding", " In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguis- tics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186", "", "Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston", " 2023", " Chain-of-verification reduces hallucination in large language models", " arXiv preprint arXiv:2309", "11495", "", "Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui", " 2022", "\tA sur- vey for in-context learning", " arXiv preprint arXiv:2301", "00234", "", "Wanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, and Dongyeop Kang", " 2022", " Understanding it- erative revision from human-written text", " arXiv preprint arXiv:2203", "03802", "", "Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch", " 2023", " Improv- ing factuality and reasoning in language mod- els through multiagent debate", " arXiv preprint arXiv:2305", "14325", "", "Jinhao Duan, Hao Cheng, Shiqi Wang, Chenan Wang, Alex Zavalny, Renjing Xu, Bhavya Kailkhura, and Kaidi Xu", " 2023", " Shifting at- tention to relevance: Towards the uncertainty estimation of large language models", " arXiv preprint arXiv:2307", "01379", "", "Esin Durmus, He He, and Mona T", " Diab", " 2020", " FEQA: A question answering evaluation frame- work for faithfulness assessment in abstractive summarization", " In Proceedings of the 58th An- nual Meeting of the Association for Computa- tional Linguistics, ACL 2020, Online, July 5-10, 2020, pages 5055–5070", " Association for Com- putational Linguistics", "", "Nouha Dziri, Sivan Milton, Mo Yu, Osmar Zaiane, and Siva Reddy", " 2022", " On the origin of hal- lucinations in conversational models: Is it the datasets or the models? In Proceedings of the", "2022 Conference of the North American Chap- ter of the Association for Computational Lin- guistics: Human Language Technologies, pages 5271–5285.", "Nouha Dziri, Hannah Rashkin, Tal Linzen, and David Reitter", " 2021", " Evaluating groundedness in dialogue systems: The BEGIN benchmark", " CoRR, abs/2105", "00071", "", "Alex Fabbri, Prafulla Kumar Choubey, Jesse Vig, Chien-Sheng Wu, and Caiming Xiong", " 2022", " Improving factual consistency in summariza- tion with compression-based post-editing", " In Proceedings of the 2022 Conference on Empir- ical Methods in Natural Language Processing, pages 9149–9156", "", "Chao Feng, Xinyu Zhang, and Zichu Fei", " 2023", " Knowledge solver: Teaching llms to search for domain knowledge from knowledge graphs", " arXiv preprint arXiv:2309", "03118", "", "Patrick Fernandes, Aman Madaan, Emmy Liu, António Farinhas, Pedro Henrique Martins, Amanda Bertsch, José GC de Souza, Shuyan Zhou, Tongshuang Wu, Graham Neubig, et al", " 2023", " Bridging the gap: A survey on integrat- ing (human) feedback for natural language gen- eration", " arXiv preprint arXiv:2305", "00955", "", "Leo Gao, John Schulman, and Jacob Hilton", " 2022", " Scaling laws for reward model overoptimiza- tion", "", "Luyu Gao, Zhuyun Dai, Panupong Pasupat, An- thony Chen, Arun Tejasvi Chaganty, Yicheng Fan, Vincent Zhao, Ni Lao, Hongrae Lee, Da- Cheng Juan, et al", " 2023a", " Rarr: Researching and revising what language models say, using language models", " In Proceedings of the 61st Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 16477–16508", "", "Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen", " 2023b", " Enabling large language models to generate text with citations", " arXiv preprint arXiv:2305", "14627", "", "Claire Gardent, Anastasia Shimorina, Shashi Narayan, and Laura Perez-Beltrachini", " 2017", " Creating training corpora for NLG micro- planners", " In Proceedings of the 55th Annual", "Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 179–188.", "Ismael Garrido-Muñoz, Arturo Montejo-Ráez, Fernando Martínez-Santiago, and L Alfonso Ureña-López", " 2021", " A survey on bias in deep nlp", " Applied Sciences, 11(7):3184", "", "Yoav Goldberg", " 2023", " Reinforcement learning for language models", " Github Blog", "", "Zhibin Gou, Zhihong Shao, Yeyun Gong, Ye- long Shen, Yujiu Yang, Nan Duan, and Weizhu Chen", " 2023", " Critic: Large language models can self-correct with tool-interactive critiquing", " arXiv preprint arXiv:2305", "11738", "", "Nuno M Guerreiro, Duarte Alves, Jonas Walden- dorf, Barry Haddow, Alexandra Birch, Pierre Colombo, and André FT Martins", " 2023a", " Hal- lucinations in large multilingual translation models", " arXiv preprint arXiv:2303", "16104", "", "Nuno Miguel Guerreiro, Elena Voita, and André", "F", " T", " Martins", " 2023b", " Looking for a needle in a haystack: A comprehensive study of hallucina- tions in neural machine translation", " In Proceed- ings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023, Dubrovnik, Croatia, May 2-6, 2023, pages 1059–1075", " Association for Computational Linguistics", "", "Anisha Gunjal, Jihan Yin, and Erhan Bas", " 2023", " Detecting and preventing hallucinations in large vision language models", " arXiv preprint arXiv:2308", "06394", "", "Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger", " 2017", " On calibration of modern neural networks", " In International conference on machine learning, pages 1321–1330", " PMLR", "", "Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi", " 2019", " The curious case of neu- ral text degeneration", " In International Confer- ence on Learning Representations", "", "Yuheng Huang, Jiayang Song, Zhijie Wang, Huaming Chen, and Lei Ma", " 2023a", " Look be- fore you leap: An exploratory study of uncer- tainty measurement for large language models", " arXiv preprint arXiv:2307", "10236", "", "Zeyu Huang, Yikang Shen, Xiaofeng Zhang, Jie Zhou, Wenge Rong, and Zhang Xiong", " 2023b", " Transformer-patcher: One mistake worth one neuron", " arXiv preprint arXiv:2301", "09785", "", "Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, An- drea Madotto, and Pascale Fung", " 2023", " Survey of hallucination in natural language generation", " ACM Computing Surveys, 55(12):1–38", "", "Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig", " 2021", " How can we know when language models know? on the calibra- tion of language models for question answer- ing", " Transactions of the Association for Com- putational Linguistics, 9:962–977", "", "Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield Dodds, Nova DasSarma, Eli Tran-Johnson, et al", " 2022", " Lan- guage models (mostly) know what they know", " arXiv preprint arXiv:2207", "05221", "", "Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, and Robert McHardy", " 2023", " Challenges and applications of large language models", " arXiv preprint arXiv:2307", "10169", "", "Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen Minh Duc,  Oliver  Stanley,  Richárd  Nagyfi, et al", " 2023", " Openassistant conversations– democratizing large language model alignment", " arXiv preprint arXiv:2304", "07327", "", "Wojciech Kryscinski, Bryan McCann, Caiming Xiong, and Richard Socher", " 2020", " Evaluat- ing the factual consistency of abstractive text summarization", " In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, pages 9332–9346", " As- sociation for Computational Linguistics", "", "Viet Dac Lai, Nghia Trung Ngo, Amir Pouran Ben Veyseh, Hieu Man, Franck Dernoncourt, Trung Bui, and Thien Huu Nguyen", " 2023", " Chatgpt be- yond english: Towards a comprehensive evalu- ation of large language models in multilingual learning", " arXiv preprint arXiv:2304", "05613", "", "Zhenzhong Lan, Mingda Chen, Sebastian Good- man, Kevin Gimpel, Piyush Sharma, and Radu Soricut", " 2019", " Albert: A lite bert for self- supervised learning of language representa- tions", " In International Conference on Learning Representations", "", "Tamera Lanham, Anna Chen, Ansh Radhakrish- nan, Benoit Steiner, Carson Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hub- inger, Jackson Kernion, et al", " 2023", " Measur- ing faithfulness in chain-of-thought reasoning", " arXiv preprint arXiv:2307", "13702", "", "Angeliki Lazaridou, Elena Gribovskaya, Woj- ciech Stokowiec, and Nikolai Grigorev", " 2022", " Internet-augmented language models through few-shot prompting for open-domain question answering", " arXiv preprint arXiv:2203", "05115", "", "Ariel N Lee, Cole J Hunter, and Nataniel Ruiz", " 2023", " Platypus: Quick, cheap, and pow- erful refinement of llms", " arXiv preprint arXiv:2308", "07317", "", "Katherine Lee, Orhan Firat, Ashish Agarwal, Clara Fannjiang, and David Sussillo", " 2019", " Hallucinations in neural machine translation", "", "Nayeon Lee, Wei Ping, Peng Xu, Mostofa Pat- wary, Pascale N Fung, Mohammad Shoeybi, and Bryan Catanzaro", " 2022", " Factuality en- hanced language models for open-ended text generation", " Advances in Neural Information Processing Systems, 35:34586–34599", "", "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer", " 2020a", " Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension", " In Proceed- ings of the 58th Annual Meeting of the As- sociation for Computational Linguistics, pages 7871–7880", "", "Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al", " 2020b", " Retrieval- augmented generation for knowledge-intensive nlp tasks", " Advances in Neural Information Pro- cessing Systems, 33:9459–9474", "", "Huayang Li, Yixuan Su, Deng Cai, Yan Wang, and Lemao Liu", " 2022a", " A survey on retrieval- augmented text generation", " arXiv preprint arXiv:2202", "01110", "", "Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian- Yun Nie, and Ji-Rong Wen", " 2023a", " Halueval: A large-scale hallucination evaluation bench- mark for large language models", " arXiv preprint arXiv:2305", "11747", "", "Junyi Li, Tianyi Tang, Wayne Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen", " 2022b", " Pretrained lan- guage models for text generation: A survey", " arXiv preprint arXiv:2201", "05273", "", "Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister, and Martin Wattenberg", " 2023b", " Inference-time intervention: Eliciting truthful answers from a language model", " arXiv preprint arXiv:2306", "03341", "", "Miaoran Li, Baolin Peng, and Zhu Zhang", " 2023c", " Self-checker: Plug-and-play modules for fact- checking with large language models", " arXiv preprint arXiv:2305", "14623", "", "Shaobo Li, Xiaoguang Li, Lifeng Shang, Zhenhua Dong, Chengjie Sun, Bingquan Liu, Zhenzhou Ji, Xin Jiang, and Qun Liu", " 2022c", " How pre- trained language models capture factual knowl- edge? a causal-inspired analysis", " In Findings of the Association for Computational Linguistics: ACL 2022, pages 1720–1732", "", "Xingxuan Li, Ruochen Zhao, Yew Ken Chia, Bosheng Ding, Lidong Bing, Shafiq Joty, and Soujanya Poria", " 2023d", " Chain of knowledge: A framework for grounding large language mod- els with structured knowledge bases", " arXiv preprint arXiv:2305", "13269", "", "Yifan Li, Yifan Du, Kun Zhou, Jinpeng Wang, Wayne Xin Zhao, and Ji-Rong Wen", " 2023e", " Evaluating object hallucination in large vision-language models", " arXiv preprint arXiv:2305", "10355", "", "Yuanzhi Li, Sébastien Bubeck, Ronen Eldan, Al- lie Del Giorno, Suriya Gunasekar, and Yin Tat Lee", " 2023f", "  Textbooks are all you need ii: phi-1", "5 technical report", " arXiv preprint arXiv:2309", "05463", "", "Zuchao Li, Shitou Zhang, Hai Zhao, Yifei Yang, and Dongjie Yang", " 2023g", " Batgpt: A bidirectional autoregessive talker from gener- ative pre-trained transformer", " arXiv preprint arXiv:2307", "00360", "", "Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe", " 2023", " Let’s verify step by step", " arXiv preprint arXiv:2305", "20050", "", "Chin-Yew Lin", " 2004", " Rouge: A package for auto- matic evaluation of summaries", " In Text summa- rization branches out, pages 74–81", "", "Stephanie Lin, Jacob Hilton, and Owain Evans", " 2021", " Truthfulqa: Measuring how mod- els mimic human falsehoods", " arXiv preprint arXiv:2109", "07958", "", "Zhen Lin, Shubhendu Trivedi, and Jimeng Sun", " 2023", " Generating with confidence: Uncertainty quantification for black-box large language models", " arXiv preprint arXiv:2305", "19187", "", "Adam Liska, Tomas Kocisky, Elena Gribovskaya, Tayfun Terzi, Eren Sezener, Devang Agrawal, D’Autume Cyprien De Masson, Tim Scholtes, Manzil Zaheer, Susannah Young, et al", " 2022", " Streamingqa: A benchmark for adaptation to new knowledge over time in question answering models", " In International Conference on Ma- chine Learning, pages 13604–13622", " PMLR", "", "Fuxiao Liu, Kevin Lin, Linjie Li, Jianfeng Wang, Yaser Yacoob, and Lijuan Wang", " 2023a", " Aligning large multi-modal model with robust instruction tuning", " arXiv preprint arXiv:2306", "14565", "", "Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee", " 2023b", " Visual instruction tuning", " arXiv preprint arXiv:2304", "08485", "", "Jerry Liu", " 2022", " LlamaIndex", "", "Jiongnan Liu, Jiajie Jin, Zihan Wang, Jiehan Cheng, Zhicheng Dou, and Ji-Rong Wen", " 2023c", " Reta-llm: A retrieval-augmented large language model toolkit", " arXiv preprint arXiv:2306", "05212", "", "Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni,", "and Percy Liang", " 2023d", " Lost in the middle: How language models use long contexts", " arXiv preprint arXiv:2307", "03172", "", "Tianyu Liu, Yizhe Zhang, Chris Brockett, Yi Mao, Zhifang Sui, Weizhu Chen, and Bill Dolan", " 2022", " A token-level reference-free halluci- nation detection benchmark for free-form text generation", " In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6723–6737", "", "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov", " 2019", " Roberta: A robustly opti- mized bert pretraining approach", " arXiv preprint arXiv:1907", "11692", "", "Junyu Luo, Cao Xiao, and Fenglong Ma", " 2023a", " Zero-resource hallucination preven- tion for large language models", " arXiv preprint arXiv:2309", "02654", "", "Zheheng Luo, Qianqian Xie, and Sophia Anani- adou", " 2023b", " Chatgpt as a factual inconsis- tency evaluator for abstractive text summariza- tion", " arXiv preprint arXiv:2303", "15621", "", "Ziyang Luo, Can Xu, Pu Zhao, Xiubo Geng, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang", " 2023c", " Augmented large lan- guage models with parametric knowledge guid- ing", " arXiv preprint arXiv:2305", "04757", "", "Kelvin Luu, Daniel Khashabi, Suchin Gururan- gan, Karishma Mandyam, and Noah A Smith", " 2022", " Time waits for no one! analysis and challenges of temporal misalignment", " In Pro- ceedings of the 2022 Conference of the North American Chapter of the Association for Com- putational Linguistics: Human Language Tech- nologies, pages 5944–5958", "", "Muhammad Maaz, Hanoona Rasheed, Salman Khan, and Fahad Shahbaz Khan", " 2023", " Video- chatgpt: Towards detailed video understanding via large vision and language models", " arXiv preprint arXiv:2306", "05424", "", "Alex Mallen, Akari Asai, Victor Zhong, Ra- jarshi Das, Daniel Khashabi, and Hannaneh Ha- jishirzi", " 2023", " When not to trust language mod- els: Investigating effectiveness of parametric", "and non-parametric memories", " In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 9802–9822", "", "Potsawee Manakul, Adian Liusie, and Mark JF Gales", " 2023", " Selfcheckgpt: Zero-resource black-box hallucination detection for genera- tive large language models", " arXiv preprint arXiv:2303", "08896", "", "Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan T", " McDonald", " 2020", " On faithful- ness and factuality in abstractive summariza- tion", " In Proceedings of the 58th Annual Meet- ing of the Association for Computational Lin- guistics, ACL 2020, Online, July 5-10, 2020, pages 1906–1919", " Association for Computa- tional Linguistics", "", "Nick McKenna, Tianyi Li, Liang Cheng, Moham- mad Javad Hosseini, Mark Johnson, and Mark Steedman", " 2023", " Sources of hallucination by large language models on inference tasks", " arXiv preprint arXiv:2305", "14552", "", "Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov", " 2022a", " Locating and editing factual associations in gpt", " Advances in Neu- ral Information Processing Systems, 35:17359– 17372", "", "Kevin Meng, Arnab Sen Sharma, Alex Ando- nian, Yonatan Belinkov, and David Bau", " 2022b", " Mass-editing memory in a transformer", " arXiv preprint arXiv:2210", "07229", "", "Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al", " 2023", " Augmented language models: a survey", " arXiv preprint arXiv:2302", "07842", "", "Tomas Mikolov, Martin Karafiát, Lukas Bur- get, Jan Cernocky`, and Sanjeev Khudanpur", " 2010", " Recurrent neural network based language model", " In Interspeech", " Makuhari", "", "Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Os- car Sainz, Eneko Agirre, Ilana Heintz, and Dan Roth", " 2021", " Recent advances in natural lan- guage processing via large pre-trained language models: A survey", " ACM Computing Surveys", "", "Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Ha- jishirzi", " 2023", " Factscore: Fine-grained atomic evaluation of factual precision in long form text generation", " arXiv preprint arXiv:2305", "14251", "", "Eric Mitchell, Charles Lin, Antoine Bosselut, Christopher D Manning, and Chelsea Finn", " 2022", " Memory-based model editing at scale", " In International Conference on Machine Learn- ing, pages 15817–15831", " PMLR", "", "Elaraby Mohamed, Lu Mengyin, Dunn Jacob, Zhang Xueying, Wang Yu, and Liu Shizhu", " 2023", " Halo: Estimation and reduction of hal- lucinations in open-source weak large language models", " arXiv preprint arXiv:2308", "11764", "", "Dor Muhlgay, Ori Ram, Inbal Magar, Yoav Levine, Nir Ratner, Yonatan Belinkov, Omri Abend, Kevin Leyton-Brown, Amnon Shashua, and Yoav Shoham", " 2023", " Generating bench- marks for factuality evaluation of language models", " arXiv preprint arXiv:2307", "06908", "", "Niels Mündler, Jingxuan He, Slobodan Jenko, and Martin Vechev", " 2023", " Self-contradictory hal- lucinations of large language models: Evalua- tion, detection and mitigation", " arXiv preprint arXiv:2305", "15852", "", "Shikhar Murty, Christopher Manning, Scott Lund- berg, and Marco Tulio Ribeiro", " 2022", " Fixing model bugs with natural language patches", " In Proceedings of the 2022 Conference on Empir- ical Methods in Natural Language Processing, pages 11600–11613", "", "Reiichiro Nakano, Jacob Hilton, Suchir Bal- aji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al", " 2021", " We- bgpt: Browser-assisted question-answering with human feedback", "\tarXiv preprint arXiv:2112", "09332", "", "Ramesh Nallapati, Feifei Zhai, and Bowen Zhou", " 2017", " Summarunner: A recurrent neural net- work based sequence model for extractive sum- marization of documents", " In Proceedings of the AAAI conference on artificial intelligence", "", "Courtney Napoles, Keisuke Sakaguchi, and Joel Tetreault", " 2017", " Jfleg: A fluency corpus and", "benchmark for grammatical error correction", " In Proceedings of the 15th Conference of the Eu- ropean Chapter of the Association for Compu- tational Linguistics: Volume 2, Short Papers, pages 229–234", "", "Roberto Navigli, Simone Conia, and Björn Ross", " 2023", " Biases in large language models: Ori- gins, inventory and discussion", " ACM Journal of Data and Information Quality", "", "Jianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gus- tavo Hernández Ábrego, Ji Ma, Vincent Y", " Zhao, Yi Luan, Keith B", " Hall, Ming-Wei Chang, and Yinfei Yang", " 2022", " Large dual encoders are generalizable retrievers", " In Proceedings of the 2022 Conference on Empirical Methods in Nat- ural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 9844–9855", " Association for Com- putational Linguistics", "", "Xuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang, and Yu Wang", " 2023", " Skeleton-of- thought: Large language models can do parallel decoding", " arXiv preprint arXiv:2307", "15337", "", "Yasumasa Onoe, Michael JQ Zhang, Shankar Pad- manabhan, Greg Durrett, and Eunsol Choi", " 2023", " Can lms learn new entities from de- scriptions? challenges in propagating injected knowledge", " arXiv preprint arXiv:2305", "01651", "", "OpenAI", " 2023a", " ChatGPT", " https:// openai", "com/blog/chatgpt", "", "OpenAI", " 2023b", " Gpt-4 technical report", " arXiv preprint arXiv:2303", "08774", "", "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al", " 2022", " Training language models to follow instructions with human feed- back", " Advances in Neural Information Process- ing Systems, 35:27730–27744", "", "Ankur Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, and Dipanjan Das", " 2020", " ToTTo: A controlled table-to-text generation dataset", " In Proceedings of the 2020 Conference on Empir- ical Methods in Natural Language Processing (EMNLP), pages 1173–1186", "", "Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein", " 2023", " Generative agents: Interactive simulacra of human behavior", " arXiv preprint arXiv:2304", "03442", "", "Adam Pauls and Dan Klein", " 2011", " Faster and smaller n-gram language models", " In Proceed- ings of the 49th annual meeting of the Asso- ciation for Computational Linguistics: Human Language Technologies, pages 258–267", "", "Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cap- pelli, Hamza Alobeidli, Baptiste Pannier, Ebte- sam Almazrouei, and Julien Launay", " 2023", " The refinedweb dataset for falcon llm: outperform- ing curated corpora with web data, and web data only", " arXiv preprint arXiv:2306", "01116", "", "Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, et al", " 2023a", " Check your facts and try again: Improving large language models with external knowl- edge and automated feedback", " arXiv preprint arXiv:2302", "12813", "", "Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao", " 2023b", " In- struction tuning with gpt-4", " arXiv preprint arXiv:2304", "03277", "", "Ethan Perez, Sam Ringer, Kamile˙ Lukošiu¯te˙, Ka- rina Nguyen, Edwin Chen, Scott Heiner, Craig Pettit, Catherine Olsson, Sandipan Kundu, Saurav Kadavath, et al", " 2022", " Discovering language model behaviors with model-written evaluations", " arXiv preprint arXiv:2212", "09251", "", "Xiao Pu, Mingqi Gao, and Xiaojun Wan", " 2023", " Summarization is (almost) dead", " arXiv preprint arXiv:2309", "09558", "", "Cheng Qian, Xinran Zhao, and Sherry Tong- shuang Wu", " 2023", " \" merge conflicts!\" ex- ploring the impacts of external distractors to parametric knowledge graphs", " arXiv preprint arXiv:2309", "08594", "", "Shuofei Qiao, Honghao Gui, Huajun Chen, and Ningyu Zhang", " 2023", " Making language mod- els better tool learners with execution feedback", " arXiv preprint arXiv:2305", "13068", "", "Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, et al", " 2023", " Tool learning with foundation models", " arXiv preprint arXiv:2304", "08354", "", "Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai, and Xuanjing Huang", " 2020", " Pre-trained models for natural language pro- cessing: A survey", " Science China Technolog- ical Sciences, 63(10):1872–1897", "", "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al", " 2019", " Language models are unsupervised mul- titask learners", " OpenAI blog, 1(8):9", "", "Ansh Radhakrishnan, Karina Nguyen, Anna Chen, Carol Chen, Carson Denison, Danny Hernan- dez, Esin Durmus, Evan Hubinger, Jackson Kernion, Kamile˙ Lukošiu¯te˙, et al", " 2023", " Ques- tion decomposition improves the faithfulness of model-generated reasoning", " arXiv preprint arXiv:2307", "11768", "", "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu", " 2020", " Exploring the limits of transfer learning with a unified text-to-text transformer", " The Journal of Machine Learning Research, 21(1):5485–5551", "", "Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton- Brown, and Yoav Shoham", " 2023", " In-context retrieval-augmented language models", " arXiv preprint arXiv:2302", "00083", "", "Vipula Rawte, Prachi Priya, SM Tonmoy, SM Za- man, Amit Sheth, and Amitava Das", " 2023", " Ex- ploring the relationship between llm hallucina- tions and prompt linguistic nuances: Readabil- ity, formality, and concreteness", " arXiv preprint arXiv:2309", "11064", "", "Clément Rebuffel, Marco Roberti, Laure Soulier, Geoffrey Scoutheeten, Rossella Cancelliere, and Patrick Gallinari", " 2022", " Controlling hal- lucinations at word level in data-to-text gener- ation", " Data Mining and Knowledge Discovery, pages 1–37", "", "Ruiyang Ren, Yuhao Wang, Yingqi Qu, Wayne Xin Zhao, Jing Liu, Hao Tian, Hua", "Wu, Ji-Rong Wen, and Wang Haifeng", " 2023", " Investigating the factual knowledge boundary of large language models with retrieval aug- mentation", " arXiv preprint arXiv:2307", "11019", "", "Adam Roberts, Colin Raffel, and Noam Shazeer", " 2020", " How much knowledge can you pack into the parameters of a language model? In Proceedings of the 2020 Conference on Empir- ical Methods in Natural Language Processing (EMNLP), pages 5418–5426", "", "Stephen Robertson, Hugo Zaragoza, et al", " 2009", " The probabilistic relevance framework: Bm25 and beyond", " Foundations and Trends® in In- formation Retrieval, 3(4):333–389", "", "Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic´, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al", " 2022", " Bloom: A 176b-parameter open-access mul- tilingual language model", " arXiv preprint arXiv:2211", "05100", "", "John Schulman", " 2023", " Reinforcement learning from human feedback: Progress and challenges", "", "John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov", " 2017", " Prox- imal policy optimization algorithms", " arXiv preprint arXiv:1707", "06347", "", "Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed H", " Chi, Nathanael Schärli, and Denny Zhou", " 2023a", " Large lan- guage models can be easily distracted by irrel- evant context", " In Proceedings of the 40th In- ternational Conference on Machine Learning, volume 202, pages 31210–31227", "", "Freda Shi, Daniel Fried, Marjan Ghazvininejad, Luke Zettlemoyer, and Sida I", " Wang", " 2022", " Natural language to code translation with ex- ecution", " In Proceedings of the 2022 Confer- ence on Empirical Methods in Natural Lan- guage Processing, pages 3533–3546", "", "Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia Tsvetkov, Luke Zettlemoyer, and Scott Wen-tau Yih", " 2023b", " Trusting your evidence: Halluci- nate less with context-aware decoding", " arXiv preprint arXiv:2305", "14739", "", "Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih", " 2023c", " Replug: Retrieval-augmented black-box language mod- els", " arXiv preprint arXiv:2301", "12652", "", "Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuo- hang Wang, Jianfeng Wang, Jordan Boyd- Graber, and Lijuan Wang", " 2022", " Prompt- ing gpt-3 to be reliable", " arXiv preprint arXiv:2210", "09150", "", "Anton Sinitsin, Vsevolod Plokhotnyuk, Dmitriy Pyrkin, Sergei Popov, and Artem Babenko", " 2020", " Editable neural networks", " arXiv preprint arXiv:2004", "00345", "", "Yixuan Su, Tian Lan, Huayang Li, Jialu Xu, Yan Wang, and Deng Cai", " 2023", " Pandagpt: One model to instruction-follow them all", " arXiv preprint arXiv:2305", "16355", "", "Kai Sun, Yifan Ethan Xu, Hanwen Zha, Yue Liu, and Xin Luna Dong", " 2023a", " Head-to-tail: How knowledgeable are large language models (llm)? aka will llms replace knowledge graphs? arXiv preprint arXiv:2308", "10168", "", "Tianxiang Sun, Yunfan Shao, Hong Qian, Xuan- jing Huang, and Xipeng Qiu", " 2022", " Black-box tuning for language-model-as-a-service", " In In- ternational Conference on Machine Learning, pages 20841–20855", " PMLR", "", "Tianxiang Sun, Xiaotian Zhang, Zhengfu He, Peng Li, Qinyuan Cheng, Hang Yan, Xiangyang Liu, Yunfan Shao, Qiong Tang, Xingjian Zhao, Ke Chen, Yining Zheng, Zhejian Zhou, Ruixiao Li, Jun Zhan, Yunhua Zhou, Linyang Li, Xi- aogui Yang, Lingling Wu, Zhangyue Yin, Xu- anjing Huang, and Xipeng Qiu", " 2023b", " Moss: Training conversational language models from synthetic data", "", "Alex Tamkin, Kunal Handa, Avash Shrestha, and Noah Goodman", " 2022", " Task ambiguity in hu- mans and language models", "", "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B", " Hashimoto", " 2023", " Stanford alpaca: An instruction- following llama model", " https://github", " com/tatsu-lab/stanford_alpaca", "", "Faraz Torabi, Garrett Warnell, and Peter Stone", " 2018", " Behavioral cloning from observation", " In Proceedings of the 27th International Joint Conference on Artificial Intelligence, pages 4950–4957", "", "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timo- thée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al", " 2023a", " Llama: Open and efficient foundation language models", " arXiv preprint arXiv:2302", "13971", "", "Hugo Touvron, Louis Martin, Kevin Stone, Pe- ter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al", " 2023b", " Llama 2: Open foundation and fine-tuned chat models", " arXiv preprint arXiv:2307", "09288", "", "Logesh Kumar Umapathi, Ankit Pal, and Malaikannan Sankarasubbu", " 2023", " Med- halt: Medical domain hallucination test for large language models", " arXiv preprint arXiv:2307", "15343", "", "Neeraj Varshney, Wenlin Yao, Hongming Zhang, Jianshu Chen, and Dong Yu", " 2023", " A stitch in time saves nine: Detecting and mitigating hallu- cinations of llms by validating low-confidence generation", " arXiv preprint arXiv:2307", "03987", "", "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin", " 2017", " At- tention is all you need", " Advances in neural in- formation processing systems, 30", "", "Chaojun Wang and Rico Sennrich", " 2020", " On exposure bias, hallucination and domain shift in neural machine translation", " arXiv preprint arXiv:2005", "03642", "", "Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar", " 2023a", " Voy- ager: An open-ended embodied agent with large language models", " arXiv preprint arXiv:2305", "16291", "", "Hongmin Wang", " 2019", " Revisiting challenges in data-to-text generation with fact grounding", " In Proceedings of the 12th International Confer- ence on Natural Language Generation, pages 311–322", "", "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou", " 2022", " Self-consistency improves chain of thought rea- soning in language models", " In The Eleventh In- ternational Conference on Learning Represen- tations", "", "Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah A Smith, Iz Beltagy, et al", " 2023b", " How far can camels go? exploring the state of instruc- tion tuning on open resources", " arXiv preprint arXiv:2306", "04751", "", "Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A", " Smith, Daniel Khashabi, and Hannaneh Hajishirzi", " 2023c", " Self-instruct: Aligning language models with self-generated instructions", " In Proceedings of the 61st An- nual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 13484–13508", "", "Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji", " 2023d", " Unleashing cognitive synergy in large language models: A task-solving agent through multi- persona self-collaboration", " arXiv preprint arXiv:2307", "05300", "", "Alexander Wei, Nika Haghtalab, and Jacob Stein- hardt", " 2023a", " Jailbroken: How does llm safety training fail? arXiv preprint arXiv:2307", "02483", "", "Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, An- drew M Dai, and Quoc V Le", " 2021", " Finetuned language models are zero-shot learners", " In In- ternational Conference on Learning Represen- tations", "", "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al", " 2022", " Chain-of-thought prompting elicits reasoning in large language models", " Advances in Neural Information Pro- cessing Systems, 35:24824–24837", "", "Jerry Wei, Da Huang, Yifeng Lu, Denny Zhou, and Quoc V Le", " 2023b", " Simple synthetic data reduces sycophancy in large language models", " arXiv preprint arXiv:2308", "03958", "", "Alexander R Fabbri Chien-Sheng Wu and Wen- hao Liu Caiming Xiong", " 2023", " Qafacteval: Im- proved qa-based factual consistency evaluation for summarization", "", "Jian Wu, Yashesh Gaur, Zhuo Chen, Long Zhou, Yimeng Zhu, Tianrui Wang, Jinyu Li, Shu- jie Liu, Bo Ren, Linquan Liu, et al", " 2023a", " On decoder-only architecture for speech-to-text and large language model integration", " arXiv preprint arXiv:2307", "03917", "", "Weiqi Wu, Chengyue Jiang, Yong Jiang, Pengjun Xie, and Kewei Tu", " 2023b", " Do plms know and understand ontological knowledge? arXiv preprint arXiv:2309", "05936", "", "Yijun Xiao and William Yang Wang", " 2021", " On hallucination and predictive uncertainty in con- ditional language generation", " In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 2734–2744", "", "Jian Xie, Kai Zhang, Jiangjie Chen, Renze Lou, and Yu Su", " 2023", " Adaptive chameleon or stub- born sloth: Unraveling the behavior of large language models in knowledge conflicts", " arXiv preprint arXiv:2305", "13300", "", "Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, and Bryan Hooi", " 2023", " Can llms express their uncertainty? an empir- ical evaluation of confidence elicitation in llms", " arXiv preprint arXiv:2306", "13063", "", "Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley", " 2023", " Baize: An open-source chat model with parameter-efficient tuning on self- chat data", " arXiv preprint arXiv:2304", "01196", "", "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan, and Yuan Cao", " 2022", " React: Synergizing reasoning and acting in language models", " In The Eleventh International Conference on Learning Repre- sentations", "", "Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, An- wen Hu, Pengcheng Shi, Yaya Shi, et al", " 2023", " mplug-owl: Modularization empowers large language models with multimodality", " arXiv preprint arXiv:2304", "14178", "", "Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu, Xipeng Qiu, and Xuanjing Huang", " 2023", " Do large language models know what they don’t know? arXiv preprint arXiv:2305", "18153", "", "Jifan Yu, Xiaozhi Wang, Shangqing Tu, Shulin Cao, Daniel Zhang-Li, Xin Lv, Hao Peng, Zi- jun Yao, Xiaohan Zhang, Hanming Li, et al", " 2023a", " Kola: Carefully benchmarking world knowledge of large language models", " arXiv preprint arXiv:2306", "09296", "", "Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, and Ashish Sabharwal", " 2023b", " Improving language models via plug-and- play retrieval feedback", " arXiv preprint arXiv:2305", "14002", "", "Xiang Yue, Boshi Wang, Kai Zhang, Ziru Chen, Yu Su, and Huan Sun", " 2023", " Automatic eval- uation of attribution by large language models", " arXiv preprint arXiv:2305", "06311", "", "Sina Zarrieß, Henrik Voigt, and Simeon Schüz", " 2021", " Decoding methods in neural language generation: a survey", " Information, 12(9):355", "", "Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al", " 2022", " Glm-130b: An open bilingual pre-trained model", " In The Eleventh International Confer- ence on Learning Representations", "", "Yuheng Zha, Yichi Yang, Ruichen Li, and Zhiting Hu", " 2023", " AlignScore: Evaluating factual con- sistency with a unified alignment function", " In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Vol- ume 1: Long Papers), pages 11328–11348", "", "Muru Zhang, Ofir Press, William Merrill, Al- isa Liu, and Noah A Smith", " 2023a", " How language model hallucinations can snowball", " arXiv preprint arXiv:2305", "13534", "", "Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, et al", " 2023b", " Instruction tuning for large language models: A survey", " arXiv preprint arXiv:2308", "10792", "", "Shuo Zhang, Liangming Pan, Junzhou Zhao, and William Yang Wang", " 2023c", " Mitigating language model hallucination with interactive", "question-knowledge alignment", " arXiv preprint arXiv:2305", "13669", "", "Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi", " 2019", " Bertscore: Evaluating text generation with bert", " In Inter- national Conference on Learning Representa- tions", "", "Xuchao Zhang, Menglin Xia, Camille Couturier, Guoqing Zheng, Saravan Rajmohan, and Vic- tor Ruhle", " 2023d", " Hybrid retrieval-augmented generation for real-time composition assistance", " arXiv preprint arXiv:2308", "04215", "", "Ruochen Zhao, Xingxuan Li, Shafiq Joty, Cheng- wei Qin, and Lidong Bing", " 2023a", " Verify-and- edit: A knowledge-enhanced chain-of-thought framework", " arXiv preprint arXiv:2305", "03268", "", "Theodore Zhao, Mu Wei, J Samuel Preston, and Hoifung Poon", " 2023b", " Automatic calibration and error correction for large language mod- els via pareto optimal self-supervision", " arXiv preprint arXiv:2306", "16564", "", "Wayne Xin Zhao, Jing Liu, Ruiyang Ren, and Ji- Rong Wen", " 2022", " Dense text retrieval based on pretrained language models: A survey", " arXiv preprint arXiv:2211", "14876", "", "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al", " 2023c", " A survey of large language models", " arXiv preprint arXiv:2303", "18223", "", "Ce Zheng, Lei Li, Qingxiu Dong, Yuxuan Fan, Zhiyong Wu, Jingjing Xu, and Baobao Chang", " 2023a", " Can we edit factual knowl- edge by in-context learning? arXiv preprint arXiv:2305", "12740", "", "Rui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin Liu, Limao Xiong, Lu Chen, et al", " 2023b", " Se- crets of rlhf in large language models part i: Ppo", " arXiv preprint arXiv:2307", "04964", "", "Shen Zheng, Jie Huang, and Kevin Chen-Chuan Chang", " 2023c", " Why does chatgpt fall short in providing truthful answers", " arXiv preprint arXiv:2304", "10513", "", "Ming Zhong, Da Yin, Tao Yu, Ahmad Zaidi, Mutethia Mutuma, Rahul Jha, Ahmed Hassan Awadallah, Asli Celikyilmaz, Yang Liu, Xipeng Qiu, and Dragomir R", " Radev", " 2021", " Qm- sum: A new benchmark for query-based multi- domain meeting summarization", " In Proceed- ings of the 2021 Conference of the North Amer- ican Chapter of the Association for Compu- tational Linguistics: Human Language Tech- nologies, NAACL-HLT 2021, Online, June 6-11,", "2021, pages 5905–5921", " Association for Com- putational Linguistics", "", "Zexuan Zhong, Zhengxuan Wu, Christopher D Manning, Christopher Potts, and Danqi Chen", " 2023", " Mquake: Assessing knowledge edit- ing in language models via multi-hop questions", " arXiv preprint arXiv:2305", "14795", "", "Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al", " 2023a", " Lima: Less is more for alignment", " arXiv preprint arXiv:2305", "11206", "", "Wenxuan Zhou, Sheng Zhang, Hoifung Poon, and Muhao Chen", " 2023b", " Context-faithful prompt- ing for large language models", " arXiv preprint arXiv:2303", "11315", "", "Chenguang Zhu, William Hinthorn, Ruochen Xu, Qingkai Zeng, Michael Zeng, Xuedong Huang, and Meng Jiang", " 2021", " Enhancing factual con- sistency of abstractive summarization", " In Pro- ceedings of the 2021 Conference of the North American Chapter of the Association for Com- putational Linguistics: Human Language Tech- nologies, pages 718–733", "", "Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, et al", " 2023", " Promptbench: Towards evaluating the ro- bustness of large language models on adversar- ial prompts", " arXiv preprint arXiv:2306", "04528", "", "Andy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson", " 2023", " Universal and transferable adversarial attacks on aligned language models", " arXiv preprint arXiv:2307", "15043", ""], "2309.01219v2.docx"]
[["Self-rag: Learning to Retrieve, Generate, and", "Critique through Self-Reflection", "Akari Asai†, Zeqiu Wu†, Yizhong Wang†§, Avirup Sil‡, Hannaneh Hajishirzi†§", "†University of Washington\t§Allen Institute for AI\t‡IBM Research AI", "{akari,zeqiuwu,yizhongw,hannaneh}@cs", "washington", "edu, avi@us", "ibm", "com", "Abstract", "Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the paramet- ric knowledge they encapsulate", " Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues", " However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation", " We introduce a new framework called Self-Reflective Retrieval-Augmented Gen- eration (SELF-RAG) that enhances an LM’s quality and factuality through retrieval and self-reflection", " Our framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its own generations using special tokens, called reflection tokens", " Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements", " Experiments show that SELF- RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks", " Specifically, SELF-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models", "1", "Introduction", "State-of-the-art LLMs continue to struggle with factual errors (Mallen et al", ", 2023; Min et al", ", 2023) despite their increased model and data scale (Ouyang et al", ", 2022)", " Retrieval-Augmented Generation (RAG) methods (Figure 1 left; Lewis et al", " 2020; Guu et al", " 2020) augment the input of LLMs with relevant retrieved passages, reducing factual errors in knowledge-intensive tasks (Ram et al", ", 2023; Asai et al", ", 2023a)", " However, these methods may hinder the versatility of LLMs or introduce unnecessary or off-topic passages that lead to low-quality generations (Shi et al", ", 2023) since they retrieve passages indiscriminately regardless of whether the factual grounding is helpful", " Moreover, the output is not guaranteed to be consistent with retrieved relevant passages (Gao et al", ", 2023) since the models are not explicitly trained to leverage and follow facts from provided passages", " This work introduces Self-Reflective Retrieval-augmented Generation (SELF-RAG) to improve an LLM’s generation quality, including its factual accuracy without hurting its versatility, via on-demand retrieval and self-reflection", " We train an arbitrary LM in an end-to-end manner to learn to reflect on its own generation process given a task input by generating both task output and intermittent special tokens (i", "e", ", reflection tokens)", " Reflection tokens are categorized into retrieval and critique tokens to indicate the need for retrieval and its generation quality respectively (Figure 1 right)", " In particular, given an input prompt and preceding generations, SELF-RAG first determines if augmenting the continued generation with retrieved passages would be helpful", " If so, it outputs a retrieval token that calls a retriever model on demand (Step 1)", " Subsequently, SELF-RAG concurrently processes multiple retrieved passages, evaluating their relevance and then generating corresponding task outputs (Step 2)", " It then generates critique tokens to criticize its own output and choose best one (Step 3) in terms of factuality and overall quality", " This process differs from conventional RAG (Figure 1 left), which", "1Our code and trained models are available at https://selfrag", "github", "io/", "", "Figure 1: Overview of SELF-RAG", " SELF-RAG learns to retrieve, critique, and generate text passages to enhance overall generation quality, factuality, and verifiability", "", "consistently retrieves a fixed number of documents for generation regardless of the retrieval necessity (e", "g", ", the bottom figure example does not require factual knowledge) and never second visits the generation quality", " Moreover, SELF-RAG provides citations for each segment with its self-assessment of whether the output is supported by the passage, leading to easier fact verification", "", "SELF-RAG trains an arbitrary LM to generate text with reflection tokens by unifying them as the next token prediction from the expanded model vocabulary", " We train our generator LM on a diverse collection of text interleaved with reflection tokens and retrieved passages", " Reflection tokens, inspired by reward models used in reinforcement learning (Ziegler et al", ", 2019; Ouyang et al", ", 2022), are inserted offline into the original corpus by a trained critic model", " This eliminates the need to host a critic model during training, reducing overhead", " The critic model, in part, is supervised on a dataset of input, output, and corresponding reflection tokens collected by prompting a propriety LM (i", "e", ", GPT-4; OpenAI 2023)", " While we draw inspiration from studies that use control tokens to start and guide text generation (Lu et al", ", 2022; Keskar et al", ", 2019), our trained LM uses critique tokens to assess its own predictions after each generated segment as an integral part of the generation output", "", "SELF-RAG further enables a customizable decoding algorithm to satisfy hard or soft constraints, which are defined by reflection token predictions", " In particular, our inference-time algorithm enables us to (1) flexibly adjust retrieval frequency for different downstream applications and (2) customize models’ behaviors to user preferences by leveraging reflection tokens through segment-level beam search using the weighted linear sum of the reflection token probabilities as segment score", "", "Empirical results on six tasks, including reasoning and long-form generation, demonstrate that SELF- RAG significantly outperforms pre-trained and instruction-tuned LLMs that have more parameters and widely adopted RAG approaches with higher citation accuracy", " In particular, SELF-RAG outperforms retrieval-augmented ChatGPT on four tasks, Llama2-chat (Touvron et al", ", 2023) and Alpaca (Dubois et al", ", 2023) on all tasks", " Our analysis demonstrates the effectiveness of training and inference with reflection tokens for overall performance improvements as well as test-time model customizations (e", "g", ", balancing the trade-off between citation previsions and completeness)", "", "Related Work", "Retrieval-Augmented Generation", " Retrieval-Augmented Generation (RAG) augments the input space of LMs with retrieved text passages (Guu et al", ", 2020; Lewis et al", ", 2020), leading to large improvements in knowledge-intensive tasks after fine-tuning or used with off-the-shelf LMs (Ram et al", ", 2023)", " A more recent work (Luo et al", ", 2023) instruction-tunes an LM with a fixed number", "of retrieved passages prepended to input, or pre-train a retriever and LM jointly, followed by few- shot fine-tuning on task datasets (Izacard et al", ", 2022b)", " While prior work often retrieves only once at the beginning, Jiang et al", " (2023) propose to adaptively retrieve passages for generation on top of a proprietary LLM or Schick et al", " (2023) train an LM to generate API calls for named entities", " Yet, the improved task performance of such approaches often comes at the expense of runtime efficiency (Mallen et al", ", 2023), robustness to irrelevant context (Shi et al", ", 2023), and lack of attributions (Liu et al", ", 2023a; Gao et al", ", 2023)", " We introduce a method to train an arbitrary LM to learn to use retrieval on-demand for diverse instruction-following queries and introduce controlled generation guided by reflections tokens to further improve generation quality and attributions", "", "Concurrent RAG work", " A few concurrent works2 on RAG propose new training or prompting strategies to improve widely-adopted RAG approaches", " Lin et al", " (2023) fine-tune both the retriever and LM on instruction-tuning datasets in two steps", " While we also train our model on diverse instruction-following datasets, SELF-RAG enables retrieval on demand and selection of the best possible model output via fine-grained self-reflection, making it widely applicable and more robust and controllable", " Yoran et al", " (2023) use a natural language inference model and Xu et al", " (2023) use a summarization model to filter out or compress retrieved passages before using them to prompt the LM to generate the output", " SELF-RAG processes passages in parallel and filters out irrelevant ones through self-reflection, without relying on external models at inference", " Moreover, our self-reflection mechanism also evaluates other aspects of the model output quality including factuality", " LATS (Zhou et al", ", 2023) prompt off-the-shelf LMs to search for relevant information for question answering tasks and to generate with tree search, guided by LM-generated value scores", " While their value function simply indicates an overall score of each generation, SELF-RAG trains to an arbitrary LM to learn to generate fine-grained self-reflection and customizable inference", "", "Training and generating with critics", " Training LLMs with reinforcement learning (e", "g", ", Proximal Policy Optimization or PPO; Schulman et al", " 2017) from human feedback (RLHF) has proven effective in aligning LLMs with human preferences (Ouyang et al", ", 2022)", " Wu et al", " (2023) introduce fine-grained RLHF with multiple reward models", " Though our work also studies fine-grained critique on retrieval and generation, we train our target LM on task examples augmented with reflection tokens from a critic model offline, with a far lower training cost compared to RLHF", " In addition, reflection tokens in SELF-RAG enable controllable generation at inference, while RLHF focuses on human preference alignment during training", " Other works use general control tokens to guide LM generation (Lu et al", ", 2022; Korbak et al", ", 2023), while SELF-RAG uses reflection tokens to decide the need for retrieval and to self-evaluate generation quality", " Xie et al", " (2023) propose a self-evaluation- guided decoding framework, but they focus only on reasoning tasks with one evaluation dimension (reasoning path consistency) and without retrieval", " Recent work on LLM refinement (Dhuliawala et al", ", 2023; Madaan et al", ", 2023; Paul et al", ", 2023) prompts a model to generate task output, natural language feedback and refined task output iteratively, but at the cost of inference efficiency", "", "Self-Rag: Learning to Retrieve, Generate and Critique", "We introduce Self-Reflective Retrieval-Augmented Generation (SELF-RAG), shown in Figure 1", " SELF-RAG is a framework that enhances the quality and factuality of an LLM through retrieval and self-reflection, without sacrificing LLM’s original creativity and versatility", " Our end-to-end training lets an LM M generate text informed by retrieved passages, if needed, and criticize the output by learning to generate special tokens", " These reflection tokens (Table 1) signal the need for retrieval", "or confirm the output’s relevance, support, or completeness", " In contrast, common RAG approaches retrieve passages indiscriminately, without ensuring complete support from cited sources", "", "Problem Formalization and Overview", "Formally, given input x, we train M to sequentially generate textual outputs y consisting of multiple segments y = [y1, ", " ", " ", " , yT ], where yt indicates a sequence of tokens for the t-th segment", "3 Generated tokens in yt include text from the original vocabulary as well as the reflection tokens (Table 1)", "", "2All work is arXived within a week of this preprint.", "3In this paper, we treat one sentence as a segment in our experiments, but our framework is applicable to any segment unit (i", "e", ", sub-sentence)", "", "Type\tInput\tOutput\tDefinitions", "x / x, y\t{yes, no, continue}\tDecides when to retrieve with R", "x, d\t{relevant, irrelevant}\td provides useful information to solve x.", "x, d, y\t{fully supported, partially", "supported, no support}", "All of the verification-worthy statement in y is supported by d.", "x, y\t{5, 4, 3, 2, 1}\ty is a useful response to x.", "Table 1: Four types of reflection tokens used in SELF-RAG. Each type uses several tokens to represent", "its output values. The bottom three rows are three types of\ttokens, and the bold text indicates", "the most desirable critique tokens", " x, y, d indicate input, output, and a relevant passage, respectively", "", "Algorithm 1 SELF-RAG Inference", "Require: Generator LM M, Retriever R, Large-scale passage collections {d1, ", " ", " ", " , dN }", "1: Input: input prompt x and preceding generation y<t, Output: next output segment yt", "2: M predicts\tgiven (x, y<t)", "3: if\t== Yes then", "4:\tRetrieve relevant text passages D using R given (x, yt−1)\t▷ Retrieve", "5:\tM predicts", "6:\tM predicts", "given x, d and yt given x, d, y<t for each d ∈ D\t▷ Generate ven x, yt, d for each d ∈ D\t\t▷ Critique", "7:\tRank yt based on\t,\t▷ Detailed in Section 3.3", "8: else if\t== No then", "9:\tMgen predicts yt given x\t▷ Generate", "10:\tMgen predicts\tgiven x, yt\t▷ Critique", "Inference overview", " Figure 1 and Algorithm 1 present an overview of SELF-RAG at inference", " For every x and preceding generation y<t, the model decodes a retrieval token to evaluate the utility of retrieval", " If retrieval is not required, the model predicts the next output segment, as it does in a standard LM", " If retrieval is needed, the model generates: a critique token to evaluate the retrieved passage’s relevance, the next response segment, and a critique token to evaluate if the information in the response segment is supported by the passage", " Finally, a new critique token evaluates the overall utility of the response", "4 To generate each segment, SELF-RAG processes multiple passages in parallel and uses its own generated reflection tokens to enforce soft constraints (Section 3", "3) or hard control (Algorithm 1) over the generated task output", " For instance, in Figure 1 (right), the retrieved passages", "d1 is selected at the first time step since d2 does not provide direct evidence ( and d3 output is only partially supported while d1 are fully supported.", "is Irrelevant)", "Training overview", " SELF-RAG enables an arbitrary LM to generate text with reflection tokens by unifying them as next token predictions from the expanded model vocabulary (i", "e", ", the original vocabulary plus reflection tokens)", " Specifically, we train the generator model M on a curated corpus", "with interleaving passages retrieved by a retriever R and reflection tokens predicted by a critic model", "C (summarized in Appendix Algorithm 2)", " We train C to generate reflection tokens for evaluating retrieved passages and the quality of a given task output (Section 3", "2", "1)", " Using the critic model, we", "update the training corpus by inserting reflection tokens into task outputs offline", " Subsequently, we train the final generator model (M) using the conventional LM objective (Section 3", "2", "2) to enable M to generate reflection tokens by itself without relying on the critic at inference time", "", "Self-Rag Training", "Here, we describe the supervised data collection and training of two models, the critic C (Section 3", "2", "1) and the generator M (Section 3", "2", "2)", "", "Training the Critic Model", "Data collection for critic model", " Manual annotation of reflection tokens for each segment is expensive (Wu et al", ", 2023)", " A state-of-the-art LLM like GPT-4 (OpenAI, 2023) can be effectively", "4We follow Liu et al", " (2023a) in using a “perceived” utility value that is independent of retrieved passages", "", "Input: How did US states get their names?", "Output: 1 of 50 states names come from persons", " For instance, Louisiana was named in honor of King Louis XIV of France and Georgia was named after King George II", "", "Augmented Output: No Retrieval My best summer", "Critic LM", "Augmented Output: Retrieve", "Retriever", "<p>Of the fifty states, eleven are named after an individual person</p>.", "vacation was a magical escape to the coastal town of", "Relevant 11 of 50 states’ names come from person.", "Retrieve", "<p>LOUISIANA: Named in", "Santorini", " No Retrieval The azure waters, charming white- washed building are unforgettable experience", "", "honor of Louis XIV of France", "</p>", "", "Georgia was named after King George II.", "For instance, Louisiana was named after King Louis XIV, and", "Figure 2: SELF-RAG training examples", " The left example does not require retrieval while the right one requires retrieval; thus, passages are inserted", " More examples are in Appendix Table 4", "", "used to generate such feedback (Liu et al", ", 2023b)", " However, depending on such proprietary LMs can raise API costs and diminish reproducibility (Chen et al", ", 2023)", " We create supervised data by prompting GPT-4 to generate reflection tokens and then distill their knowledge into an in-house C", " For each group of reflection tokens, we randomly sample instances from the original training data:", "{Xsample, Y sample} ∼ {X, Y }. As different reflection token groups have their own definitions and", "input, as shown in Table 1, we use different instruction prompts for them. Here, we use\tas", "an example", " We prompt GPT-4 with a type-specific instruction (“Given an instruction, make a judgment on whether finding some external documents from the web helps to generate a better response", "”) followed by few-shot demonstrations I the original task input x and output y to predict an appropriate reflection token as text: p(r|I, x, y)", " Manual assessment reveals that GPT-4 reflection token predictions show high agreement with human evaluations", " We collect 4k-20k supervised training data for each type and combine them to form training data for C", " Appendix Section D shows the full list of instructions, and A", "1 contains more details and our analysis", "", "Critic learning. After we collect training data Dcritic, we initialize C with a pre-trained LM and train it on Dcritic using a standard conditional language modeling objective, maximizing likelihood:", "max E((x,y),r)∼Dcritic log pC(r|x, y), r for reflection tokens.\t(1)", "C", "Though the initial model can be any pre-trained LM, we use the same one as the generator LM (i", "e", ", Llama 2-7B; Touvron et al", " 2023) for C initialization", " The critic achieves a higher than 90% agreement with GPT-4-based predictions on most reflection token categories (Appendix Table 5)", "", "Training the Generator Model", "Data collection for generator", "  Given an input-output pair (x, y), we augment the original output y using the retrieval and critic models to create supervised data that precisely mimics the SELF- RAG inference-time process (Section 3", "1)", " For each segment yt ∈ y, we run C to assess whether additional passages could help to enhance generation", " If retrieval is required, the retrieval special", "token\t=Yes is added, and R retrieves the top K passages, D. For each passage, C further", "evaluates whether the passage is relevant and predicts\t. If a passage is relevant, C further", "evaluates whether the passage supports the model generation and predicts\t. Critique tokens", "and\tare appended after the retrieved passage or generations. At the end of the output, y", "(or yT ), C predicts the overall utility token\t, and an augmented output with reflection tokens", "and the original input pair is added to Dgen", " See the example training data in Figure 2", "", "Generator learning. We train the generator model M by training on the curated corpus augmented with reflection tokens Dgen using the standard next token objective:", "max E(x,y,r)∼Dgen log pM(y, r|x).\t(2)", "M", "Unlike C training (Eq", " 1), M learns to predict the target output as well as the reflection tokens", " During training, we mask out the retrieved text chunks (surrounded by <p> and </p> in Figure 2) for loss calculation and expand the original vocabulary V with a set of reflection tokens { Critique , Retrieve }", "", "Connections to prior work on learning with critique", " Recent work incorporates additional critique (feedback) during training, e", "g", ", RLHF (Ouyang et al", " 2022) via PPO", " While PPO relies on", "separate reward models during training, we compute critique offline and directly insert them into the training corpus, where the generator LM is trained with a standard LM objective", " This significantly reduces training costs compared to PPO", " Our work also relates to prior work that incorporates special tokens to control generation (Keskar et al", ", 2019; Lu et al", ", 2022; Korbak et al", ", 2023)", " Our SELF-RAG learns to generate special tokens to evaluate its own prediction after each generated segment, enabling the use of a soft re-ranking mechanism or hard constraints at inference (discussed next)", "", "Self-Rag Inference", "Generating reflection tokens to self-evaluate its own output makes SELF-RAG controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements", " For tasks demanding factual accuracy (Min et al", ", 2023), we aim for the model to retrieve passages more frequently to ensure that the output aligns closely with the available evidence", " Conversely, in more open-ended tasks, like composing a personal experience essay, the emphasis shifts towards retrieving less and prioritizing the overall creativity or utility score", " In this section, we describe approaches to enforce control to meet these distinct objectives during the inference process", "", "Adaptive retrieval with threshold", " SELF-RAG dynamically decides when to retrieve text passages by predicting Retrieve ", " Alternatively, our framework allows a threshold to be set", " Specifically, if the prob-", "ability of generating the Retrieve =Yes token normalized over all output tokens in designated threshold, we trigger retrieval (details in Appendix Section A", "3)", "", "surpasses a", "Tree-decoding with critique tokens", " At each segment step t, when retrieval is required, based either on hard or soft conditions, R retrieves K passages, and the generator M processes each passage in parallel and outputs K different continuation candidates", " We conduct a segment-level beam search (with the beam size=B) to obtain the top-B segment continuations at each timestamp t, and return the best sequence at the end of generation", " The score of each segment yt with respect to passage d is updated with a critic score S that is the linear weighted sum of the normalized probability of each", "token type", " For each critique token group G (e", "g", ",", "t as sG, and we compute a segment score as follows:", "), we denote its score at timestamp", "f(yt, d, Critique ) = p(yt|x, d, y<t)) + S( Critique ), where\t(3)", "S( Critique ) = Σ wGsG for G = { ISREL , ISSUP , ISUSE },\t(4)", "where sG = Σ pt(rˆ)", "G∈G", "stands for the generation probability of the most desirable reflection token", "t\tNG p (r )", "i=1  t  i", "rˆ (e", "g", ",\t=Relevant) for the critique token type G with N G distinct tokens (that represent", "different possible values for G)", " The weights wG in Eq", " 4 are hyperparameters that can be adjusted at inference time to enable customized behaviors at test time", " For instance, to ensure that result", "y is mostly supported by evidence, we can set a weight term for the\tscore higher, while", "relatively lowering weights for other aspects", " Alternatively, we could further enforce hard constraints during decoding using Critique ", " Instead of using a soft reward function in Eq", " 4, we could explicitly", "filter out a segment continuation when the model generates an undesirable\ttoken (e", "g", ",", "=No support) ", " Balancing the trade-off between multiple preferences has been studied in RLHF (Touvron et al", ", 2023; Wu et al", ", 2023), which often requires training to change models’ behaviors", " SELF-RAG tailors an LM with no additional training", "", "Experiments", "Tasks and Datasets", "We conduct evaluations of our SELF-RAG and diverse baselines on a range of downstream tasks, holistically evaluating outputs with metrics designed to assess overall correctness, factuality, and fluency", " Throughout these experiments, we conduct zero-shot evaluations, where we provide instruc- tions describing tasks without few-shot demonstrations (Wei et al", ", 2022; Sanh et al", ", 2022)", " Details of our experiments’ settings, including test-time instructions, are available in the Appendix Section B", "1", "", "Closed-set tasks include two datasets, i", "e", ", a fact verification dataset about public health (PubHealth; Zhang et al", " 2023) and a multiple-choice reasoning dataset created from scientific exams (ARC-", "Challenge; Clark et al", " 2018)", " We use accuracy as an evaluation metric and report on the test set", " We aggregate the answer probabilities of target classes for both of these datasets (Appendix Section B", "2)", "", "Short-form generations tasks include two open-domain question answering (QA) datasets, PopQA (Mallen et al", ", 2023) and TriviaQA-unfiltered (Joshi et al", ", 2017), where systems need to answer arbitrary questions about factual knowledge", " For PopQA, we use the long-tail subset, consisting of 1,399 rare entity queries whose monthly Wikipedia page views are less than 100", " As the TriviaQA-unfiltered (open) test set is not publicly available, we follow prior work’s validation and test split (Min et al", ", 2019; Guu et al", ", 2020), using 11,313 test queries for evaluation", " We evaluate performance based on whether gold answers are included in the model generations instead of strictly requiring exact matching, following Mallen et al", " (2023); Schick et al", " (2023)", "", "Long-form generation tasks include a biography generation task (Min et al", ", 2023) and a long-form QA task ALCE-ASQA Gao et al", " (2023); Stelmakh et al", " (2022)", " We use FactScore (Min et al", ", 2023) to evaluate biographies, and we use official metrics of correctness (str-em), fluency based on MAUVE (Pillutla et al", ", 2021), and citation precision and recall (Gao et al", ", 2023) for ASQA", " 5", "Baselines", "Baselines without retrievals", " We evaluate strong publicly available pre-trained LLMs, Llama27B,13B (Touvron et al", ", 2023), instruction-tuned models, Alpaca7B,13B (Dubois et al", ", 2023) (our replication based on Llama2); and models trained and reinforced using private data, Chat- GPT (Ouyang et al", ", 2022) and Llama2-chat13B", " For instruction-tuned LMs, we use the official system prompt or instruction format used during training if publicly available", " We also compare our method to concurrent work, CoVE65B (Dhuliawala et al", ", 2023), which introduces iterative prompt engineering to improve the factuality of LLM generations", "", "Baselines with retrievals", " We evaluate models augmented with retrieval at test time or during training", " The first category includes standard RAG baselines, where an LM (Llama2, Alpaca) generates output given the query prepended with the top retrieved documents using the same retriever as in our system", " It also includes Llama2-FT, where Llama2 is fine-tuned on all training data we use without the reflection tokens or retrieved passages", " We also report the result of retrieval-augmented baselines with LMs trained with private data: Ret-ChatGPT and Ret-Llama2-chat, which deploy the same augmentation technique above, as well as perplexity", "ai, an InstructGPT-based production search system", " The second category includes concurrent methods that are trained with retrieved text passages, i", "e", ", SAIL (Luo et al", ", 2023) to instruction-tune an LM on the Alpaca instruction-tuning data with top retrieved documents inserted before instructions, and Toolformer (Schick et al", ", 2023) to pre-train an LM with API calls (e", "g", ", Wikipedia APIs)", "6", "Experimental settings", "Training data and settings", " Our training data consists of diverse instruction-following input-output pairs", " In particular, we sample instances from Open-Instruct processed data (Wang et al", ", 2023) and knowledge-intensive datasets (Petroni et al", ", 2021; Stelmakh et al", ", 2022; Mihaylov et al", ", 2018)", " In total, we use 150k instruction-output pairs", " We use Llama2 7B and 13B (Touvron et al", ", 2023) as", "our generator base LM, and we use Llama2 7B as our base critic LM", " For the retriever model R, we use off-the-shelf Contriever-MS MARCO (Izacard et al", ", 2022a) by default and retrieve up to ten documents for each input", " More training details are in the Appendix Section B", "1", "", "Inference settings. As a default configuration, we assign the weight terms\t,\t,", "values of 1", "0, 1", "0 and 0", "5, respectively", " To encourage frequent retrieval, we set the retrieval threshold to 0", "2 for most tasks and to 0 for ALCE (Gao et al", ", 2023) due to citation requirements", " We speed up inference using vllm (Kwon et al", ", 2023)", " At each segment level, we adopt a beam width of 2", " For a token-level generation, we use greedy decoding", " By default, we use the top five documents from Contriever-MS MARCO (Izacard et al", ", 2022a); for biographies and open-domain QA, we use additional top five documents retrieved by a web search engine, following Luo et al", " (2023); for ASQA, we use the author-provided top 5 documents by GTR-XXL (Ni et al", ", 2022) across all baselines for a fair comparison", "", "5https://github.com/princeton-nlp/ALCE", "6We report numbers using the results reported in the paper as the implementations are not available.", "Table 2: Overall experiment results on six tasks", " Bold numbers indicate the best performance among non-proprietary models, and gray-colored bold text indicates the best proprietary model when they outperforms all non-proprietary models", " ∗ indicates concurrent or recent results reported by concurrent work", " – indicates numbers that are not reported by the original papers or are not applicable", " Models are sorted based on scale", " FS, em, rg, mau, prec, rec denote FactScore (factuality); str-em, rouge (correctness); MAUVE (fluency); citation precision and recall, respectively", "", "Short-form\tClosed-set\tLong-form generations (with citations)", "Results and Analysis", "Main Results", "Comparison against baselines without retrieval", " Table 2 (top) presents the baselines without retrieval", " Our SELF-RAG (bottom two rows) demonstrates a substantial performance advantage over supervised fine-tuned LLMs in all tasks and even outperforms ChatGPT in PubHealth, PopQA, biography generations, and ASQA (Rouge and MAUVE)", " Our approach also significantly outperforms a concurrent method that employs sophisticated prompt engineering; specifically, on the bio generation task, our 7B and 13B models outperform the concurrent CoVE (Dhuliawala et al", ", 2023), which iteratively prompts Llama265B to refine output", "", "Comparison against baselines with retrieval", " As shown in Tables 2 (bottom), our SELF-RAG also outperforms existing RAG in many tasks, obtaining the best performance among non-proprietary LM-based models on all tasks", " While our method outperforms other baselines, on PopQA or Bio, powerful instruction-tuned LMs with retrieval (e", "g", ", LLama2-chat, Alpaca) show large gains from their non-retrieval baselines", " However, we found that these baselines provide limited solutions for tasks where we cannot simply copy or extract sub-strings of retrieved passages", " On PubHealth and ARC-Challenge, baselines with retrieval do not improve performance notably from their no- retrieval counterparts", " We also observe that most baselines with retrieval struggle to improve citation accuracy", " On ASQA, our model shows significantly higher citation precision and recall than all models except ChatGPT", " Gao et al", " (2023) found that ChatGPT consistently exhibits superior efficacy in this particular task, surpassing smaller LMs", " Our SELF-RAG bridges this performance gap, even outperforming ChatGPT in citation precision, which measures whether the model-generated claim is fully supported by cited evidence", " We also found that on the metrics for factual precision, SELF-RAG 7B occasionally outperforms our 13B due to the tendency of smaller SELF-RAG to often generate", "PQA\tMed\tAS", "(acc)\t(acc)\t(em)", "  SELF-RAG (50k)\t45", "5\t73", "5\t32", "1 ", "Training", "70.5", "70.0", "95", "90", "1\t2", "1\t2", "Weight for IsSupport", "1.00", "0.99", "0.99", "0.98", "1.0", "0.8", "0.6", "PubHealth", "0", "0\t0", "2\t0", "4\t0", "6", "PopQA", "0", "0\t0", "2\t0", "4\t0", "6", "Retrieval Threshold", "1.0", "0.5", "0.0", "1.00", "0.75", "0.50", "0.25", "Ablation", "Customization", "Retrieval", "Figure 3: Analysis on SELF-RAG: (a) Ablation studies for key components of SELF-RAG training and inference based on our 7B model", " (b) Effects of soft weights on ASQA citation precision and Mauve (fluency)", " (c) Retrieval frequency and normalized accuracy on PubHealth and PopQA", "", "precisely grounded yet shorter outputs", " Llama2-FT7B, which is the baseline LM trained on the same instruction-output pairs as SELF-RAG without retrieval or self-reflection and is retrieval-augmented at test time only, lags behind SELF-RAG", " This result indicates SELF-RAG gains are not solely from training data and demonstrate the effectiveness of SELF-RAG framework", "", "Analysis", "Ablation studies", " We conduct a set of ablations of our framework to identify which factors play key roles", " We evaluate two model variants trained differently than our model: No Retriever trains an LM using the standard instruction-following method given instruction-output pairs, without retrieved passages; No Critic trains an LM trained with input-output pairs that are always augmented with the top one retrieved document without reflection tokens", " This is similar to SAIL (Luo et al", ", 2023), and we use our instruction-output data instead of using the Alpaca dataset (Dubois et al", ", 2023), as in SAIL", " We also conduct ablation on our inference-time algorithm, including No retrieval disables retrieval during inference; Hard constraints indicates the model performance that retrieves when Retrieve =Yes instead of using the adaptive threshold; Retrieve top 1 always retrieves and uses the", "top one document only, similar to standard RAG approaches; Remove\tindicates the model", "performance that removes\tscore only during critique-guided beam search in Eq", " 4", " In this", "ablation experiment, we use a training instance size of 50k for a more efficient exploration of training variations", " Later in this section, we conduct an analysis of the effect of training data size", " We conduct the ablation studies on three datasets, PopQA, PubHealth, and ASQA", " On ASQA, we evaluate models on sampled 150 instances and exclude ablations involving adaptive or no retrieval processes", "", "We show in Table 3a the ablation results", " The top part of the table shows results for training ablations, and the bottom part is for inference ablations", " We see that all components play important roles", " We also observe a large performance gap between SELF-RAG and No Retriever or Critic baselines across tasks, indicating that training an LM with those models largely contributes to the performance gain of SELF-RAG", " Using the top passages regardless of their relevance (Retrieve top 1) as in conventional", "RAG approaches causes a large drop in PopQA and ASQA, and removing\tduring the beam", "search results hurts performance on ASQA", " This demonstrates the effectiveness of SELF-RAG’s capabilities of carefully selecting generations based fine-grained multiple criterion, instead of naively using all of the top passages from the retrieval model or solely depending on relevance scores", "", "Effects of inference-time customization", " One key benefit of our proposed framework is that it enables us to control how much each critique type affects the final generation sampling", " We analyze the effects of different parameter weights on the top of our 7B model during inference time on ASQA, where multiple evaluation aspects are considered", " Figure 3b shows the effects of changing", "the weighting term for\t, which criticizes how supported the output is by the text passage. As", "the figure shows, increasing the weight leads to positive effects on the models’ citation precision since this puts more emphasis on whether model generation is supported by the evidence. On the", "55", "50", "45", "40", "35", "0\t50\t100\t150", "Num of training (k)", "PopQA", "73", "72", "71", "0\t100", "Num of training (k)", "PubHealth", "60", "40", "0\t100", "Num of training (k)", "ASQA (prec)", "Human evaluation on PopQA and Bio generation.", "Figure 4: Training scale and Human analysis: (a) (b) (c) Training scale analysis shows the effect of the training data scale on PopQA, PubHealth and ASQA (citation precision), respectively", " (d) Human analysis on SELF-RAG outputs as well as reflection tokens", "", "contrary, a larger weight results in lower MAUVE scores: when generation gets longer and more fluent, there are often more claims that are not fully supported by citations, consistent with findings by Liu et al", " (2023a)", " Our framework lets practitioners choose and customize models’ behaviors at test time by adjusting such parameters without requiring additional training", "", "Efficiency and accuracy trade-off", " Using our framework, practitioners can adjust how often retrieval occurs using the token probability of reward tokens", " We evaluate how this adaptive threshold affects overall accuracy and frequency of retrieval, and we evaluate the performance with varying numbers of threshold δ (larger δ results in less retrieval) on PubHealth and PopQA", " Figure 3c shows that the model’s retrieval frequencies dramatically change on both datasets", " as δ varies", " On one hand, performance deterioration by retrieving less is smaller on PubHealth but larger in PopQA", "", "Effects of training data size", " We conduct an analysis of how the data scale affects the model’s performance", " In particular, we randomly sample 5k, 10k, 20k, and 50k instances from our original 150k training instances, and fine-tune four SELF-RAG 7B variants on those subsets", " Then, we compare the model performance on PopQA, PubHealth, and ASQA (citation precision) with our final SELF- RAG trained on the full 150k instances", " We also evaluate Figures 4a, 4b and 4c shows the models’ performance trained on different amount of data", " Across all datasets, increasing data size often shows upward trajectories and the improvements are significantly larger in PopQA and ASQA, while we do not observed such significant improvements on Llama2-FT7B when increasing the training data from 50k to 150k", " These results also indicate that further expanding the training data of SELF-RAG may lead to further improvements, although in this work we limit our training data size to 150k", "", "Human evaluations", " We conduct small human evaluations on SELF-RAG outputs, as well as the reliability of predicted reflection tokens", " In particular, we sampled 50 samples from PopQA and Bio results", " Following Menick et al", " (2022), human annotators evaluate S&P, which indicates whether the model output is plausible (i", "e", ", the output is a reasonable and on-topic response to the question as if it were occurring in a conversation) and supported (i", "e", ", the provided evidence is sufficient to verify the validity of the answer)", " For S&P, we do not consider the instances where SELF-RAG predicts irrelevant or no support", " We then ask our annotators whether the model-predicted", "reflection tokens about", "and", "match their inspections (e", "g", ", whether the fully supported", "output is supported by the cited evidence). Human annotators find SELF-RAG answers are often plausible and supported by relevant passages with higher S&P scores on short-form PopQA, which is", "consistent with Menick et al", " (2022)", " Human annotators also find", "and", "reflection token", "predictions are mostly aligned with their assessments", " Appendix Table 6 shows several annotated examples and explanations on assessments", "", "Conclusion", "This work introduces SELF-RAG, a new framework to enhance the quality and factuality of LLMs through retrieval on demand and self-reflection", " SELF-RAG trains an LM to learn to retrieve, generate, and critique text passages and its own generation by predicting the next tokens from its original vocabulary as well as newly added special tokens, called reflection tokens", " SELF-RAG further enables the tailoring of LM behaviors at test time by leveraging reflection tokens", " Our holistic evaluations on six tasks using multiple metrics demonstrate that SELF-RAG significantly outperforms LLMs with more parameters or with conventional retrieval-augmented generation approaches", "", "Ethical Concerns", "This work aims to improve the factuality of LLM outputs, the lack of which continues to cause nu- merous real-world problems (e", "g", ", spread of misinformation and provision of incorrect and dangerous advice)", " While our method shows significant improvements in terms of performance, factuality, and citation accuracy, it can still generate outputs that are not fully supported by the citations", " We hope that explicit self-reflection and fine-grained attribution may help users verify factual errors in the model outputs", "", "Acknowledgments", "We thank Sewon Min, Scott Wen-tau Yih, Sean Welleck, and Kawin Ethayarajh for fruitful discussions in the early stages of this work", " We thank Sewon Min, Joongwon (Daniel) Kim, and Sandy Kaplan for valuable feedback on the paper, and Tianyu Gao and Weijia Shi for their help on evaluations", " Akari Asai is supported by the IBM Fellowship", " We thank Stability AI for providing computing to train and evaluate the LMs in this work, and Microsoft Accelerate Foundation Models Research Program for the access to OpenAI APIs", " This work was funded in part by the DARPA MCS program through NIWC Pacific (N66001-19-2-4031), NSF IIS-2044660, and gifts from AI2", "", "References", "Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, and Caiming Xiong", " Learn- ing to retrieve reasoning paths over wikipedia graph for question answering", " In International Conference on Learning Representations, 2020", " URL https://openreview", "net/forum? id=SJgVHkrYDH", "", "Akari Asai, Sewon Min, Zexuan Zhong, and Danqi Chen", " Retrieval-based language models and appli- cations", " In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Tutorial), 2023a", " URL https://aclanthology", "org/2023", "acl-tutorials", "6", "", "Akari Asai, Timo Schick, Patrick Lewis, Xilun Chen, Gautier Izacard, Sebastian Riedel, Hannaneh Hajishirzi, and Wen-tau Yih", " Task-aware retrieval with instructions", " In Findings of the Associ- ation for Computational Linguistics, 2023b", " URL https://aclanthology", "org/2023", " findings-acl", "225", "", "Bernd Bohnet, Vinh Q Tran, Pat Verga, Roee Aharoni, Daniel Andor, Livio Baldini Soares, Jacob Eisenstein, Kuzman Ganchev, Jonathan Herzig, Kai Hui, et al", " Attributed question answering: Evaluation and modeling for attributed large language models", " arXiv preprint arXiv:2212", "08037, 2022", " URL https://arxiv", "org/abs/2212", "08037", "", "Lingjiao Chen, Matei Zaharia, and James Zou", " How is chatgpt’s behavior changing over time? arXiv preprint arXiv:2307", "09009, 2023", " URL https://arxiv", "org/abs/2307", "09009", "", "Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord", " Think you have solved question answering? try arc, the ai2 reasoning challenge", " arXiv preprint arXiv:1803", "05457, 2018", " URL https://arxiv", "org/abs/1803", "05457", "", "Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Re´", " Flashattention: Fast and memory- efficient exact attention with io-awareness", " In Advances in Neural Information Processing Systems, 2022", " URL https://openreview", "net/forum?id=H4DqfPSibmx", "", "Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston", " Chain-of-verification reduces hallucination in large language models", " arXiv preprint arXiv:2309", "11495, 2023", " URL https://arxiv", "org/abs/2309", "11495", "", "Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston", " Wizard of wikipedia: Knowledge-powered conversational agents", " In International Conference on Learning Representations, 2019", " URL https://openreview", "net/forum?id=r1l73iRqKm", "", "Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, and Tatsunori B", " Hashimoto", " Alpacafarm: A simulation framework for methods that", "learn from human feedback", " arXiv preprint arXiv:2305", "14387, 2023", " URL https://arxiv", " org/abs/2305", "14387", "", "Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen", " Enabling large language models to generate text with citations", " arXiv preprint arXiv:2305", "14627, 2023", " URL https://arxiv", "org/abs/ 2305", "14627", "", "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang", " Retrieval augmented language model pre-training", " In International Conference on Machine Learning, 2020", " URL https://dl", "acm", "org/doi/pdf/10", "5555/3524938", "3525306", "", "Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave", " Unsupervised dense information retrieval with contrastive learning", " Transactions on Machine Learning Research, 2022a", " URL https://openreview", "net/ forum?id=jKN1pXi7b0", "", "Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave", " Few-shot learning with retrieval augmented language models", " arXiv preprint arXiv:2208", "03299, 2022b", " URL https:", "//arxiv", "org/abs/2208", "03299", "", "Zhengbao Jiang, Frank F Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig", " Active retrieval augmented generation", " arXiv preprint arXiv:2305", "06983, 2023", " URL https://arxiv", "org/abs/2305", "06983", "", "Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer", " TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension", " In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2017", " URL https://aclanthology", "org/P17-1147", "", "Nitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, and Richard Socher", " Ctrl: A conditional transformer language model for controllable generation", " arXiv preprint arXiv:1909", "05858, 2019", " URL https://arxiv", "org/abs/1909", "05858", "", "Tomasz Korbak, Kejian Shi, Angelica Chen, Rasika Vinayak Bhalerao, Christopher Buckley, Jason Phang, Samuel R Bowman, and Ethan Perez", " Pretraining language models with human preferences", " In International Conference on Machine Learning, 2023", " URL https://openreview", "net/ forum?id=AT8Iw8KOeC", "", "Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M", " Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov", " Natural questions: A benchmark for question answering research", " Transactions of the Association for Computational Linguistics, 2019", " URL https://aclanthology", "org/ Q19-1026", "", "Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E", " Gonzalez, Hao Zhang, and Ion Stoica", " Efficient memory management for large language model serving with pagedattention", " In Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles, 2023", " URL https://arxiv", "org/abs/2309", "06180", "", "Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Ku¨ttler, Mike Lewis, Wen-tau Yih, Tim Rockta¨schel, Sebastian Riedel, and Douwe Kiela", " Retrieval-augmented generation for knowledge-intensive nlp tasks", " In Advances in Neural Infor- mation Processing Systems, 2020", " URL https://proceedings", "neurips", "cc/paper/ 2020/file/6b493230205f780e1bc26945df7481e5-Paper", "pdf", "", "Xi Victoria Lin, Xilun Chen, Mingda Chen, Weijia Shi, Maria Lomeli, Rich James, Pedro Rodriguez, Jacob Kahn, Gergely Szilvasy, Mike Lewis, Luke Zettlemoyer, and Scott Yih", " Ra-dit: Retrieval- augmented dual instruction tuning, 2023", " URL https://arxiv", "org/abs/2310", "01352", "", "Nelson F Liu, Tianyi Zhang, and Percy Liang", " Evaluating verifiability in generative search engines", "", "arXiv preprint arXiv:2304", "09848, 2023a", " URL https://arxiv", "org/abs/2304", "09848", "", "Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu", " Gpteval: Nlg evaluation using gpt-4 with better human alignment", " arXiv preprint arXiv:2303", "16634, 2023b", " URL https://arxiv", "org/abs/2303", "16634", "", "Ximing Lu, Sean Welleck, Jack Hessel, Liwei Jiang, Lianhui Qin, Peter West, Prithviraj Am- manabrolu, and Yejin Choi", " QUARK: Controllable text generation with reinforced unlearning", " In Advances in Neural Information Processing Systems, 2022", " URL https://openreview", " net/forum?id=5HaIds3ux5O", "", "Hongyin Luo, Yung-Sung Chuang, Yuan Gong, Tianhua Zhang, Yoon Kim, Xixin Wu, Danny Fox, Helen Meng, and James Glass", " Sail: Search-augmented instruction learning", " arXiv preprint arXiv:2305", "15225, 2023", " URL https://arxiv", "org/abs/2305", "15225", "", "Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark", " Self- refine: Iterative refinement with self-feedback", " arXiv preprint arXiv:2303", "17651, 2023", " URL https://arxiv", "org/abs/2303", "17651", "", "Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi", " When not to trust language models: Investigating effectiveness of parametric and non-parametric memories", " In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2023", " URL https://aclanthology", "org/2023", " acl-long", "546", "", "Jacob Menick, Maja Trebacz, Vladimir Mikulik, John Aslanides, Francis Song, Martin Chadwick, Mia Glaese, Susannah Young, Lucy Campbell-Gillingham, Geoffrey Irving, et al", " Teaching language models to support answers with verified quotes", " arXiv preprint arXiv:2203", "11147, 2022", " URL https://arxiv", "org/abs/2203", "11147", "", "Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal", " Can a suit of armor conduct electricity? a new dataset for open book question answering", " In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018", " URL https://aclanthology", " org/D18-1260", "", "Sewon Min, Danqi Chen, Hannaneh Hajishirzi, and Luke Zettlemoyer", " A discrete hard EM approach for weakly supervised question answering", " In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu- ral Language Processing (EMNLP-IJCNLP), 2019", " URL https://aclanthology", "org/ D19-1284", "", "Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi", " Factscore: Fine-grained atomic evaluation of factual precision in long form text generation", " arXiv preprint arXiv:2305", "14251, 2023", " URL https:", "//arxiv", "org/abs/2305", "14251", "", "Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al", " Webgpt: Browser-assisted question-answering with human feedback", " arXiv preprint arXiv:2112", "09332, 2021", " URL https:", "//arxiv", "org/abs/2112", "09332", "", "Jianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hernandez Abrego, Ji Ma, Vincent Zhao, Yi Luan, Keith Hall, Ming-Wei Chang, and Yinfei Yang", " Large dual encoders are generalizable retrievers", " In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022", " URL https://aclanthology", "org/2022", "emnlp-main", "669", "", "OpenAI", " Gpt-4 technical report", " arXiv preprint arXiv:2303", "08774, 2023", " URL https://arxiv", " org/abs/2303", "08774", "", "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and", "Ryan Lowe", " Training language models to follow instructions with human feedback", " In Advances in Neural Information Processing Systems, 2022", " URL https://openreview", "net/forum? id=TG8KACxEON", "", "Debjit Paul, Mete Ismayilzada, Maxime Peyrard, Beatriz Borges, Antoine Bosselut, Robert West, and Boi Faltings", " Refiner: Reasoning feedback on intermediate representations", " arXiv preprint arXiv:2304", "01904, 2023", " URL https://arxiv", "org/abs/2304", "01904", "", "Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani, Nicola De Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean Maillard, Vassilis Plachouras, Tim Rockta¨schel, and Sebastian Riedel", " KILT: a benchmark for knowledge intensive language tasks", " In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2021", " URL https://aclanthology", "org/ 2021", "naacl-main", "200", "", "Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Sean Welleck, Yejin Choi, and Zaid Harchaoui", " MAUVE: Measuring the gap between neural text and human text using divergence frontiers", " In Advances in Neural Information Processing Systems, 2021", " URL https:", "//openreview", "net/forum?id=Tqx7nJp7PR", "", "Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He", " Zero: Memory optimizations toward training trillion parameter models", " In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, 2020", " URL https://dl", "acm", " org/doi/10", "5555/3433701", "3433727", "", "Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham", " In-context retrieval-augmented language models", " Transactions of the Association for Computational Linguistics, 2023", " URL https://arxiv", "org/abs/2302", "00083", "", "Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, De- bajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Teven Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M Rush", " Multitask prompted training enables zero-shot task generalization", " In International Conference on Learning Representations, 2022", " URL https://openreview", "net/forum?id=9Vrb9D0WI4", "", "Timo Schick, Jane Dwivedi-Yu, Roberto Dess`ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom", " Toolformer: Language models can teach themselves to use tools", " arXiv preprint arXiv:2302", "04761, 2023", " URL https://arxiv", "org/abs/2302", " 04761", "", "John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov", " Proximal policy optimization algorithms", " arXiv preprint arXiv:1707", "06347, 2017", " URL https://arxiv", "org/ abs/1707", "06347", "", "Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed H", " Chi, Nathanael Scha¨rli, and Denny Zhou", " Large language models can be easily distracted by irrelevant context", " In Proceedings of the 40th International Conference on Machine Learning, 2023", " URL https:", "//proceedings", "mlr", "press/v202/shi23a", "html", "", "Ivan Stelmakh, Yi Luan, Bhuwan Dhingra, and Ming-Wei Chang", " ASQA: Factoid questions meet long- form answers", " In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022", " URL https://aclanthology", "org/2022", "emnlp-main", "566", "", "James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal", " FEVER: a large- scale dataset for fact extraction and VERification", " In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech- nologies, Volume 1 (Long Papers), 2018", " URL https://aclanthology", "org/N18-1074", "", "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al", " Llama 2: Open foundation and fine-tuned chat models", " arXiv preprint arXiv:2307", "09288, 2023", " URL https://arxiv", " org/abs/2307", "09288", "", "Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah A Smith, Iz Beltagy, et al", " How far can camels go? exploring the state of instruction tuning on open resources", " arXiv preprint arXiv:2306", "04751, 2023", " URL https://arxiv", "org/abs/2306", "04751", "", "Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M", " Dai, and Quoc V Le", " Finetuned language models are zero-shot learners", " In International Conference on Learning Representations, 2022", " URL https://openreview", "net/forum? id=gEZrGCozdqR", "", "Zeqiu Wu, Yushi Hu, Weijia Shi, Nouha Dziri, Alane Suhr, Prithviraj Ammanabrolu, Noah A Smith, Mari Ostendorf, and Hannaneh Hajishirzi", " Fine-grained human feedback gives better rewards for language model training", " arXiv preprint arXiv:2306", "01693, 2023", " URL https:", "//arxiv", "org/abs/2306", "01693", "", "Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-Yen Kan, Junxian He, and Qizhe Xie", " Decom- position enhances reasoning via self-evaluation guided decoding", " arXiv preprint arXiv:2305", "00633, 2023", " URL https://arxiv", "org/abs/2305", "00633", "", "Fangyuan Xu, Weijia Shi, and Eunsol Choi", " Recomp: Improving retrieval-augmented lms with compression and selective augmentation, 2023", " URL https://arxiv", "org/abs/2310", " 04408", "", "Ori Yoran, Tomer Wolfson, Ori Ram, and Jonathan Berant", " Making retrieval-augmented language models robust to irrelevant context, 2023", " URL https://arxiv", "org/abs/2310", "01558", "", "Xiang Yue, Boshi Wang, Kai Zhang, Ziru Chen, Yu Su, and Huan Sun", " Automatic evaluation of attribution by large language models", " arXiv preprint arXiv:2305", "06311, 2023", " URL https:", "//arxiv", "org/abs/2305", "06311", "", "Tianhua Zhang, Hongyin Luo, Yung-Sung Chuang, Wei Fang, Luc Gaitskell, Thomas Hartvigsen, Xixin Wu, Danny Fox, Helen Meng, and James Glass", " Interpretable unified language checking", " arXiv preprint arXiv:2304", "03728, 2023", " URL https://arxiv", "org/abs/2304", "03728", "", "Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, and Yu-Xiong Wang", " Language agent tree search unifies reasoning acting and planning in language models, 2023", " URL https:", "//arxiv", "org/abs/2310", "04406", "", "Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving", " Fine-tuning language models from human preferences", " arXiv preprint arXiv:1909", "08593, 2019", " URL https://arxiv", "org/abs/1909", "08593", "", "Appendix", "Self-Rag Details", "Reflection Tokens.", "Definitions of reflection tokens", " Below, we provide a detailed definition of reflection type and output tokens", " The first three aspects will be provided at each segment level, while the final aspect is only given at each output level", "", "Retrieval-on-demand ( Retrieve ): Given an input and previous-step generation (if applicable), an LM determines whether the continuation requires factual grounding", " No indicates retrieval is unnecessary as the sequence does not require factual grounding or may not be enhanced by knowledge retrieval, Yes indicates retrieval is necessary", " We additionally have continue to use evidence, which indicates that a model can continue to use the evidence retrieved previously", " For instance, a passage may contain rich factual information, and thus SELF-RAG generates multiple segments based on the passage", "", "Relevant (\t): Retrieved knowledge may not be always relevant to the input. This aspect", "indicates whether the evidence provides useful information (Relevant) or not (Irrelevant).", "Supported (\t): Attribution is the concept of whether the output is fully supported by", "certain evidence (Menick et al", ", 2022; Bohnet et al", ", 2022)", " This aspect judges how much infor- mation in the output is entailed by the evidence", " We evaluate attributions in three scale, Fully supported, Partially supported, and No support / Contradictory, follow- ing Yue et al", " (2023); Nakano et al", " (2021)", "", "Useful (\t): Following the definitions from Liu et al. (2023a), we define the perceived utility", "as whether the response is a helpful and informative answer to the query, independently from whether it is in fact factual or not", " This can be also viewed as plausibility in Menick et al", " (2022)", " For usefulness, we use a five-scale evaluation (1 is the lowest and 5 is the highest)", "", "Details of GPT-4-based data collections", " We use the instruction and demonstration pairs to prompt GPT-4, listed in Section D", " Following an official recommendation, we separate instructions and outputs with “##”", " We use the temperature 1 and set the maximum output token counts to be 200", " We discard instances where GPT-4 does not follow the designated output formats or output sequences that do not match our expected category names", " As a result, we collected 1,2594 for Retrieve , 11,181", "for\t, 19,317 for relevance, 3,831 for utility.", "Manual analysis of the GPT-4 predictions", " The authors of this paper manually assess randomly sampled 20 instances for each aspect and check if GPT-4 predictions match their assessments given the same instruction, demonstrations, and test instances", " We found our assessments show high agreement with GPT-4 predictions, especially for relevance (95%), retrieval necessity (95%), and the degree of support (90%)", " Agreement was slightly lower in usefulness (80%), mostly due to the disagreement between 1 and 2 or 4 and 5", "", "Self-Rag Training", "Overview of training", "  Algorithm 2 provides a high-level overview of our training", "", "Full list of seed datasets", " To sample diverse input-output pairs, we sample instances of the Open- Instruct (Wang et al", ", 2023) dataset", " In particular, we use their ShareGPT, GPT-4 Alpaca, Alpaca, OpenAssistant, and FLAN subsets subsets", " We also sample instances from a couple of knowledge- intensive datasets, Natural Questions (Kwiatkowski et al", ", 2019), Wizard of Wikipedia (Dinan et al", ", 2019) and FEVER (Thorne et al", ", 2018) from the KILT benchmark (Petroni et al", ", 2021), ASQA (Stel- makh et al", ", 2022) and multiple QA datasets including ARC-Easy and OpenBookQA (Mihaylov et al", ", 2018)", " Table 3 shows the full list of training instances, and in total, we use 145,619 instances", "", "Performance of the Critic C", " We evaluate the accuracy of reward predictions by splitting GPT-4 generated feedback into training, development, and test sets", " The accuracy of the reward model is as follows", " Table 5 shows the model performance of predicting GPT-4 judgments", " As you can see,", "overall our fine-tuned reward model shows high prediction matching with GPT-4 predicted feedback.", "Algorithm 2 SELF-RAG Training", "1: Input input-output data D = {X, Y }, generator M, C θ", "2: Initialize C with a pre-trained LM", "3: Sample data {Xsample, Y sample} ∼ {X, Y }\t▷ Training Critic LM (Section 3", "2", "1) 4: for (x, y) ∈ (Xsample, Y sample) do\t\t▷ Data collections for C 5:  Prompt GPT-4 to collect a reflection token r for (x, y)", "6:   Add {(x, y, r)} to Dcritic", "7: Update C with next token prediction loss\t\t\t▷ Critic learning; Eq", " 1 8: Initialize M with a pre-trained LM\t▷ Training Generator LM (Section 3", "2", "2) 9: for (x, y) ∈ (X, Y ) do\t\t▷ Data collection for M with Dcritic 10:   Run C to predict r given (x, y)", "11:   Add (x, y, r) to Dgen", "12: Update M on Dgen with next token prediction loss\t▷ Generator LM learning; Eq. 2", "Dataset name\tcategory\tData source\tthe number of instances", "GPT-4 Alpaca Stanford Alpaca FLAN-V2", "ShareGPT", "Open Assistant 1 Wizard of Wikipedia Natural Questions FEVER", "OpenBoookQA Arc-Easy ASQA", "Instruction-following\tOpen-Instruct\t26,168", "Instruction-following\tOpen-Instruct\t25,153", "Instruction-following\tOpen-Instruct\t17,817", "Instruction-following\tOpen-Instruct\t13,406", "Instruction-following\tOpen-Instruct\t9,464", "Knowledge-intensive\tKILT\t17,367", "Knowledge-intensive\tKILT\t15,535", "Knowledge-intensive\tKILT\t9,966", "Knowledge-intensive\tHF Dataset\t4,699", "Knowledge-intensive\tHF Dataset\t2,147", "Knowledge-intensive\tASQA\t3,897", "Table 3: The generator LM M training data statistics.", "Figure 5: Reward prediction accuracy using GPT-4 predictions as ground-truth predictions.", "While our final model uses Llama2-7B as a base LM, we also train and compare FLAN-3B (Wei et al", ", 2022) model on the same data, to investigate the effectiveness of different data sizes affect final reward predictions", " In most aspects, our reward model shows higher than 80% accuracy, indicating the powerful ability of fine-tuned specialized LMs to evaluate text", " While both models show relatively", "lower performance on\t, this is because both models often confuse between the two highest", "cases (5 and 4), where human annotators can also disagree.", "Details of M data creation", " Here, we provide detailed data creation procedures", " Algorithm 3 summarizes the process", " Here we set yt to y for simplification", " Once we train the critic model, we first run it on input data from the aforementioned datasets, to predict whether retrieval is needed or", "not. For the instances where the critic predicts", "=No, we only predict the", "given input", "and output. For the instances where the critic predicts\t=Yes, we first retrieve passages using", "the input and the entire output as queries, to find passages that are relevant to the entire output", " We then split output sentences using Spacy", "7 For each sentence, we run C to predict whether the retrieval is necessary or not, given the input, preceding segments, and the initial retrieved passage", " If C predicts Retrieve =No, then do not insert any paragraph at the tth segment", " If C predicts Retrieve =Yes, then we use the original input and the tth segment as a retrieval query to find relevant passages for the", "t-th segment. For each retrieved passage, we predict", "and", ". If there is any passage and", "continuation with", "=Relevant and", "=Fully Supported /", "=Partially", "7https://spacy.io/", "Supported, then we sample it as the continuation. If there is more than one passage satisfying this", "criterion, we use the one with the highest retrieval score. If there are only", "=No Support passages, we randomly sample one passage.", "Algorithm 3 Mgen Data creation", "1: Input Input-output data D = X, Y", "2: for (x, y) ∈ {X, Y } do", "3:\tGiven (x, y) C predicts", "=Irrelevant or", "4:\tif\tis predicted then", "5:\tRetrieve relevant passages D using R given (x, y)\t▷ Retrieve passages", "6:\tfor d ∈ D do", "7:\tC predicts", "8:\tC predicts", "9:\tC predicts", "10:\tSample d", "for each d\t▷ Predict relevance of passages", "for each (y, d)\t\t▷ Predict supports of outputs for each d\t▷ Predict overall utility (t = T only)", "11:\telse if\tis not predicted then", "12:\tC predicts\tgiven x, y", "Add augmented (x, y, d, r) to Dgen", "Training examples", "  Table 4 show several training examples used for M training", "", "Self-Rag Inference", "Details of beam-search score calculations.  We first compute scores for each critique type by", "taking the normalized probabilities of desirable tokens. For", ", we compute the score as follows:", ".", "For", ", we compute the score as follows:", "S", "+ 0.5 ×\t,", "S", "where S = Σt∈{FULLY,PARTIALLY,NO} p( ISSUP = t). For", "where we have a five-scale score, we", "compute the weighted sum of the scores", " We assigns weighted scores of w = {−1, −0", "5, 0, 0", "5, 1}", "to the tokens", "={1, 2, 3, 4, 5}, and compute the final scores as follows:", "s( IsUse ) = Σ w p( IsUse = i),", "i\tS", "where S = Σt∈{1,2,3,4,5} p( IsUse = t).", "Details of adaptive retrieval. For retrieval based on soft constraints, we trigger retrieval if the following condition is satisfied:", "> δ.", "Experimental Details", "More Details of Training", "More details of training and computations", " We use 4 Nvidia A100 with 80GB memory to train our models", " All models are trained for 3 epochs with a batch size of 128, a peak learning rate of 2e-5 with 3% warmup steps, and linear decay afterward", " We set the maximum token length to be 2,048 for the 7B model, and 1,524 for the 13B model due to the memory constraint", " We use Deepspeed stage 3 (Rajbhandari et al", ", 2020) to conduct multi-GPU distributed training, with training precision Bfloat16 enabled", " FlashAttention (Dao et al", ", 2022) is used to make the long-context training more efficient", " We run inference of our trained models using 1-2 Quadro RTX 6000 GPUs with 24GB memory", "", "More Details of Evaluations", "Retrieval setup details", " By default, we use Contriever-MS MARCO to retrieve the top five documents from Wikipedia, and use official Wikipedia embeddings based on 2018 English Wikipedia", " On PopQA, where question and answer pairs are created based on WikiData in 2022, we found that the 2018 Wikipedia sometimes lacks articles about some entities that have been more recently added to Wikipedia", " Therefore, for PopQA, we used the December 2020 preprocessed Wikipedia corpus provided by Izacard et al", " (2022b) and generated document embeddings", "8 The issues of performance variance from different Wikipedia dumps have been reported by prior work (Asai et al", ", 2020; Izacard et al", ", 2022b)", " Yet, we observe limited effectiveness of such off-the-shelf retrieval models trained primarily on knowledge-intensive tasks for open-ended generation (e", "g", ", instruction following)", " Recent or concurrent work studies instruction-tuning of retrieval systems (Asai et al", ", 2023b) or joint training of retrieval and LM components (Lin et al", ", 2023), while we leave exploring the effectivess of such appraoches for future work", " For bio generation and open-domain QA tasks, we additionally retrieve five documents using Google Programmable Search9 and search documents from English Wikipedia", " As this API only provides snippets, we retrieve Wikipedia introductory paragraphs for the corresponding entities", "", "Detailed experimental settings for individual datasets", " For OpenQA datasets, we set the max- imum new token number to 100 tokens", " For closed-set tasks (PubHealth and ARC-C), we set the maximum new token length to 50 for all baselines", " For SELF-RAG inference on PubHealth and ARC-C, instead of determining the output with the highest score 4 as in other tasks, we aggregate the scores for each option and select the answer option with the highest score", " We found in zero-shot settings of fact checking, some LLMs can generate capitalized class labels (e", "g", ", True) while our gold labels are lower-cased", " Therefore, across different LMs, for fact checking, we lowercase the predictions", " In multiple choice tasks, we found some models generate answers in slightly different ways (e", "g", ", (A) instead of A)", " We slightly modify instructions for each LLM to avoid such format violations, and further conduct string matching between each candidate and model predictions if format violations still remain", " After that processing, in closed set tasks, model predictions match one of the gold classes in almost all cases", " For ALCE, we found that Llama2-chat tend to generate significantly lower outputs than other models (e", "g", ", on average, their output is nearly 100 token, while ChatGPT generates 40 tokens on average), resulting in inflated str-em scores", " We limit the maximum generation length to 100 tokens for all baselines to avoid this issue, rather than the original 300 tokens in the ALCE paper", " Consequently, all of the baseline output length is within 30-60 tokens", " For FactScore, we set the maximum new token length to 500 for baselines and 200 for SELF-RAG at each segment level", "", "Task-specific instructions", " Table 5 shows the list of the instructions used during evaluations", " For Open-domain QA, we do not provide explicit instructions", "", "Results", "Analysis", "Reliance on parametric- and non-parametric memories", " We conduct analysis on how frequently model answers come from retrieved passages (non-parametric memories) or their own parametric memories", " On two open-domain QA datasets, TriviaQA and PopQA, we conduct the following analysis: 1) sample query models successfully answer correctly, 2) for each query in this group, check whether the matched ground-truth answer is a sub-string of the retrieved passage or not", " We evaluate SELF-RAG 7B, Alpaca 7B, Alpaca 13B, and Llama2-Chat-13B", " We found that SELF-RAG significantly less frequently generates answers that are not included in the provided evidence; in particular, in Alpaca 30B, 20% of the correct predictions are not included in the provided passages, followed by Llama2-chat 13B (18%) and Alpaca (15%), while it is only 2% in SELF-RAG", " When", "retrieved passages are not relevant, SELF-RAG generates\t=Irrelevant, indicating that the", "following answers may not be factually grounded, while those instruction-tuned models continue to generate plausible answers.", "8https://github.com/facebookresearch/atlas", "9https://programmablesearchengine", "google", "com/about/", "Human Evaluation Examples", "Table 6 shows examples with human evaluations on S&P and correctness of reflection tokens.", "and", "Qualitative Examples", "Table 7 shows several examples predicted by our SELF-RAG (13B)", " The first example is the model output to an ASQA question", " The first reference states that Emperor Constantine made Sunday a day of rest from labor, and further the second citation supports the fact that the official adoption of Sunday as a day of rest by Constantine in AD 321", " In the second example, the model predicts Contradictory to the first output as the output says the person has served as the CEO since 2010, while the passage says he stepped down as CEO in 2015", " Indicating those factual contradictions as reflection tokens enables to enforcement of hard control and also verification of model outputs easily", " In the third example, while the generation is mostly correct, SELF-RAG predicts Partially Support to the statement listing the name of the songs, as they were not explicitly mentioned", "", "Full List of Instructions and Demonstrations for GPT-4", "Here, we show the instructions and demonstrations used to prompt GPT-4 to collect reflection tokens", " Table 8 shows the instructions and demonstrations for the initial retrieval token", " Table 9 shows", "the instruction and demonstrations used to collect the three-way output tokens for\tgiven", "instruction, preceding sentences, and previously retrieved passages", " Due to the longer demonstration and test input, we only use a single demonstration", " Table 10 shows an instruction and demonstrations", "used to collect the three-way output tokens for\t. Table 11 shows an instruction and demon-", "strations used to collect the three-way output tokens for\t", " Table 12 shows an instruction and demonstrations used to collect the five-way output tokens for\t\t", "", "Input Identify the two types of computer memory. (from gpt4 alpaca)", "Output [ Retrieve =Yes]<p>Computer memory Computer memory – In computing, memory refers to the computer hardware integrated circuits that store information for immediate use in a computer; it is synonymous with the term “primary storage”", " Computer memory operates at a high speed, for example random-access memory (RAM), as a distinction from storage that provides slow-to-access information but offers higher capacities", " If needed, contents of the computer memory can be transferred to secondary storage; a very common way of doing this is through a memory management technique called “virtual memory”", " An archaic synonym for memory is", "store. The term “memory”, meaning “primary storage” or “main memory”, is<p>[\t=Relevant]Primary", "memory, also known as main memory, is the memory that the computer can directly access and manipulate.", "[\t=Fully Supported] [ Retrieve =Yes]<p>Computer memory–often associated with addressable", "semiconductor memory, i", "e", " integrated circuits consisting of silicon-based transistors, used for example as primary storage but also other purposes in computers and other digital electronic devices", " There are two main kinds of semiconductor memory, volatile and non-volatile", " Examples of non-volatile memory are flash memory (used as secondary memory) and ROM, PROM, EPROM and EEPROM memory (used for storing firmware such as BIOS)", " Examples of volatile memory are primary storage, which is typically dynamic random-access memory (DRAM), and fast CPU cache memory, which is typically static random-access memory (SRAM)", "that is fast but energy-consuming, offering lower memory<p>[\t=Relevant]Primary memory can be", "accessed quickly, but it is volatile, meaning that the data is lost if the power is turned off.[\t=Partially", "Supported]", "", "", "[\t:5]", "Input Give an example of a situation where you have to delegate tasks (from gpt4 alpaca)", "Output [ Retrieve =No]The manager realizes that there is an extensive list of tasks that need to be completed in order to make the event a success", "[ Retrieve =Yes]<p>Delegation–Delegation is the assignment of any responsi- bility or authority to another person (normally from a manager to a subordinate) to carry out specific activities", " It is one of the core concepts of management leadership", " However, the person who delegated the work remains accountable for the outcome of the delegated work", " Delegation empowers a subordinate to make decisions, i", "e", " it is a shifting of decision-making authority from one organizational level to a lower one", " Delegation, if properly done, is not fabrication", " The opposite of effective delegation is micromanagement, where a manager provides too", "much input,<p>[\t=Relevant]This includes tasks such as creating a guest list, designing and sending in-", "vitations, booking a venue, coordinating with vendors, planning the events´ program, and monitoring the budget.[", "=Partially Supported][ Retrieve =No]Since it is not possible for the manager to handle everything alone, they must delegate tasks to their team members", "[ Retrieve =No]The manager would then assign each team member specific responsibilities based on their individual skillsets and strengths", "[ Retrieve =Yes]<p>Joint application design – Subject Matter Experts: These are the business users, the IS professionals, and the outside experts that will be needed for a successful workshop", " This group is the backbone of the meeting<p>[", "=Irrelevant]For instance, the teams´ graphic designer might be tasked with designing the invitations, while the event coordinator would be in charge of planning the program and working with vendors", "", "", "[ Retrieve =No]By delegating tasks, the manager can ensure that all necessary tasks are completed in a timely manner, while also empowering their team members to take on responsibilities and contribute to the success of the event", "[", "=5]", "Input Synthesize a poem based on this prompt:“The sun is setting” (from stanford alpaca)", "Output [ Retrieve =No]The stars begin to twinkle bright the trees, scattered throughout the night; [ Retrieve =No]The stars begin to twinkle bright the trees, scattered throughout the night [ Retrieve =No] They flicker like a silent dance, A peaceful moment in its trance", " [ Retrieve =No] They flicker like a silent dance, A peaceful moment in its trance", " [ Retrieve =No] A chorus of crickets sing a lullaby, To every creature that roams", "the sky [\t=5]", "Input when did walking dead season 7 come out (from nq)", "Output [ Retrieve =Yes]<p>The Walking Dead (season 7)–The Walking Dead (season 7) The seventh season of “The Walking Dead”, an American post-apocalyptic horror television series on AMC, premiered on October 23, 2016, and concluded on April 2, 2017, consisting of 16 episodes", " Developed for television by Frank Darabont, the series is based on the eponymous series of comic books by Robert Kirkman, Tony Moore, and Charlie Adlard", "", "", "", "", "<p>[", "=Relevant]October 23 , 2016[", "=Fully Supported][", "=5]", "Input Given a chat history separated by new lines, generates an informative, knowledgeable and engaging response: Hello, I love German shepherd dogs and you? – My favorite dog, they are officially known as German Shepherd Dogs? – Yes, I have a German shepherd in my house and she is pregnant (from wow)", "Output hey also are easily trained, obedient, and intelligent", "[ Retrieve =Yes]<p>German Shepherd – a simple difference of opinion, it is the fundamental issue of the breeds´ essential conformation and movement", "  They", "are known for being easy to train and good for performing tasks and following instructions. They are especially well known for their police work, being used for tracking criminals, patrolling troubled areas and detecting and", "holding suspects.\t=Relevant]Because of this, they are often used for disability assistance and", "for police work. [", "=Partially Supported][", "=2]", "Table 4: List of the training examples.", "Dataset\tInstruction", "ARC-C\t\tGiven four answer candidates, A, B, C and D, choose the best answer choice", " Please answer with the capitalized alphabet only, without adding any extra phrase or period", "", "PubHealth\tIs the following statement correct or not? Say true if it’s correct; otherwise, say false", " Don’t capitalize or add periods, just say “true” or “false”", "", "Bio Generation\tTell me a bio about [Person Name]", "ASQA (baseline) Instruction: Write an accurate, engaging, and concise answer for the given question using only the provided search results (some of which might be irrelevant) and cite them properly", " Use an unbiased and journalistic tone", " Always cite for any factual claim", " When citing several search results, use [1][2][3]", " Cite at least one document and at most three documents in each sentence", " If multiple documents support the sentence, only cite a minimum sufficient subset of the documents", "", "ASQA (ours)  Answer the following question", " The question may be ambiguous and have multiple correct answers, and in that case, you have to provide a long-form answer including all correct answers", "", "Table 5: Full list of instructions used during zero-shot evaluations", " For open-domain QA, we don’t use any task specific instruction and simply use the original questions as input query", "", "Input What genre is A Question and Answer Guide to Astronomy? (PopQA)", "Output [ Retrieve =Yes] <p>Reference [1]<p>[\t=Relevant] A Question and Answer Guide to As-", "tronomy is a non-fiction book that falls under the genre of Astronomy and Cosmology. [\t=Fully", "Supported][\t=5]", "Reference [1] A Question and Answer Guide to Astronomy is a book about astronomy and cosmology, and is intended for a general audience", " The book was written by Pierre-Yves Bely, Carol Christian, and Jean-Rene Roy, and published in English by Cambridge University Press in 2010", " It was originally written in French", " The content within the book is written using a question and answer format", " It contains some 250 questions, which The Science Teacher states each are answered with a concise and well-formulated essay that is informative and readable", " The Science Teacher review goes on to state that many of the answers given in the book are little gems of science writing", " The Science Teacher summarizes by stating that each question is likely to be thought of by a student, and that the answers are informative, well constructed, and thorough", " The book covers information about the planets, the Earth, the Universe, practical astronomy, history, and awkward questions such as astronomy in the Bible, UFOs, and aliens", " Also covered are subjects such as the Big Bang, comprehension of large numbers, and the Moon illusion", "", "S&P Supported and Plausible.", "Correctness of", "and", ": Both", "and", "are correct, as the Reference [1] provides", "detailed information of the book including the genre, and the model output is fully supported by the reference.", "Input Who is the author of The Lie? (PopQA)", "Output [ Retrieve =Yes] <p>Reference [1]<p>[\t=Relevant] The author of The Lie is Sam Harris.[", "=Fully Supported][\t=5]", "Reference [1] Lying is a 2011 long-form essay book by American author and neuroscience expert Sam Harris", " Harris argues that we can radically simplify our lives and improve society by merely telling the truth in situations where others often lie", "", "S&P Plausible but not supported.", "Correctness of", "and", "Both", "and", "are incorrect, as the Reference [1] is about a", "different book whose title is similar to The Lie.", "Input Tell me a bio about Ronaldinho (Bio)", "Output [ Retrieve =Yes] <p>Reference [1]<p>[", "=Relevant] Ronaldinho is a retired professional", "footballer from Brazil.[\t=Fully Supported][ Retrieve =Continue]He played as an attacking", "midfielder and was known for his technical skills, creativity, dribbling ability, and accuracy from free", "kicks[ Retrieve =Continue]He won two FIFA World Player of the Year awards and a Ballon d’Or.[\t=5]", "Reference [1] Ronaldo de Assis Moreira (born 21 March 1980), commonly known as Ronaldinho Gau´cho or simply Ronaldinho, is a Brazilian retired professional footballer who played mostly as an attacking midfielder, but was also deployed as a winger", " Considered one of the best players of his generation and regarded by many as one of the greatest of all time, Ronaldinho won two FIFA World Player of the Year awards and a Ballon d’Or", " A global icon of the sport, he was renowned for his technical skills, creativity, dribbling ability and accuracy from free-kicks, as well as his use of tricks, feints, no-look passes and overhead", "", "", "", "S&P Plausible and fully supported.", "Correctness of", "and", "Both", "and", "are correct.", "Input Tell me a bio about Sergei Bodrov (Bio)", "Output [ Retrieve =Yes] <p>Reference [1]<p>[", "=Relevant] Sergei Vladimirovich Bodrov", "(born June 28,  1948) is a Russian film director,  screenwriter,  and producer.[\t=Fully", "Supported][ Retrieve =Continue]He was born in Moscow, Russia.[ Retrieve =Continue]He is the presi-", "dent of the Russian Guild of Film Producers.[\t=5]", "Reference [1] Sergei Vladimirovich Bodrov (born June 28, 1948) is a Russian film director, screenwriter, and producer", " In 2003 he was the President of the Jury at the 25th Moscow International Film Festival", "", "S&P Plausible but only partially supported", " The the Reference [1] does not explicitly mention the person is born in Moscow and there is no description about the Russian Guild of Film Producers", "", "Correctness of", "and", "and", "are correct as the reference document is highly relevant", "and the first sentence is fully supported.", "Table 6: Examples of human evaluation results.", "Input When did sunday became the seventh day of the week (asqa)", "Output [ Retrieve =Yes] <p>Reference [1]<p>[\t=Relevant] In 321 AD, the Roman Emperor Con-", "stantine the Great made Sunday a day of rest from labor, stating: “On the venerable Day of the Sun let the", "magistrates and people residing in cities rest, and let all workshops be closed”.[\t=Fully Supported]", "[ Retrieve =Yes] <p>Reference [2]<p>[\t=Relevant] The official adoption of Sunday as a day of", "rest by Constantine the Great in AD 321 made Sunday the seventh day of the week.[2][\t=Fully", "Supported][\t=5]", "Reference [1] Emperor Constantine then enacted the first Sunday Laws, for “the venerable Day of the Sun” in 321 A", "D", " On March 7, 321, the Roman emperor Constantine issued a decree making Sunday a day of rest from labor, stating: We find a good description of this in sources such as the book Rest Days which states: Early Christian observance of both the spiritual seventh-day sabbath and a Lords´ Day assembly is evidenced in Ignatiuss´ letter to the Magnesians ca", " 110", "", "Reference [2] Despite the official adoption of Sunday as a day of rest by Constantine, the seven-day week and the nundial cycle continued to be used side-by-side until at least the Calendar of 354 and probably later  The", "fact that the canon had to be issued at all is an indication that adoption of Constantine’s decree of 321 was still not universal ", "", "", "", "Input Tell me a bio about Rory Tapner. (bio generation)", "Output <p>Reference [1]<p>[\t=Relevant] Rory Tapner is a British businessman who has served as", "the Chief Executive Officer of Coutts, a private banking and wealth management company, since 2010.[", "=Contradictory], Reference [2]<p>[\t=Relevant] Rory Tapner was born on 30 September 1959", "in London, England.[\t=Fully Supported]", "Reference [1] Rory Tapner Rory Tapner is a UK businessman who, in September 2010 was appointed CEO of Coutts, the Wealth Management division of Royal Bank of Scotland Group. In February 2015 he stepped down as CEO when he was replaced in the role by Alison Rose", "Reference [2] Holdings (from August 2016); and the Council of the University of Buckingham (from July 2017)", " Rory Tapner Rory Tapner (born 30 September 1959) is a UK businessman ", "", "", "", "Input Tell me a bio about G", " Venugopa", " (bio generation)", "Output (ranked 1) [ Retrieve =Yes] <p>Reference [1]<p>[\t\t=Relevant] G", " Venugopal is a popu- lar playback singer in the Malayalam film industry", " [\t=Continue] He has sung over 300 songs in", "Malayalam, Tamil, and Hindi movies.[\t=Partially Supported] [ Retrieve =Yes] <p>Reference", "[2]<p>G", " Venugopal was born on December 10, 1960 in India", "[\t=Fully Supported]", "Reference [1] ’G", " Venugopal G Venugopal (born 10 December 1960) is an Indian playback singer known for his work in Malayalam films", " He started his singing career in the film “Odaruthammaava Aalariyaam” (1984)", " Since then he has sung in more than 300 films; and has over 500 private albums to his credit", " The many awards he has won include the coveted Best Playback Singer (Kerala State) which he won thrice, the Film Critics award and the Kerala Kaumudi Gallop Poll award (twice)", " He won The Kerala State award for Best Playback singer (2004) third time for the song ”aadedee", "", "aadaadedee” from the film ”Ullam”", "Venugopal’", "Reference [2] Kerala State Film Awards: Kerala Film Critics Award Kerala State Government Award (Profes- sional Drama): Asianet Film Awards: Kerala Kaumadi Gallup Poll Award: Academic G", " Venugopal G Venugopal (born 10 December 1960) is an Indian playback singer known for his work in Malayalam films", "", "Table 7: Examples of outputs.", "Instructions", "Given an instruction, please make a judgment on whether finding some external documents from the web (e", "g", ", Wikipedia) helps to generate a better response", " Please answer [Yes] or [No] and write an explanation", "", "Demonstrations", "Instruction Give three tips for staying healthy.", "Need retrieval? [Yes]", "Explanation There might be some online sources listing three tips for staying healthy or some reliable sources to explain the effects of different behaviors on health", " So retrieving documents is helpful to improve the response to this query", "", "Instruction Describe a time when you had to make a difficult decision.", "Need retrieval? [No]", "Explanation This instruction is asking about some personal experience and thus it does not require one to find some external documents.", "Instruction Write a short story in third person narration about a protagonist who has to make an important career decision.", "Need retrieval? [No]", "Explanation This instruction asks us to write a short story, which does not require external evidence to verify.", "Instruction What is the capital of France?", "Need retrieval? [Yes]", "Explanation While the instruction simply asks us to answer the capital of France, which is a widely known fact, retrieving web documents for this question can still help.", "Instruction Find the area of a circle given its radius. Radius = 4", "Need retrieval? [No]", "Explanation This is a math question and although we may be able to find some documents describing a formula, it is unlikely to find a document exactly mentioning the answer.", "Instruction Arrange the words in the given sentence to form a grammatically cor- rect sentence. quickly the brown fox jumped", "Need retrieval? [No]", "Explanation This task doesn’t require any external evidence, as it is a simple grammatical question.", "Instruction Explain the process of cellular respiration in plants.", "Need retrieval? [Yes]", "Explanation This instruction asks for a detailed description of a scientific concept, and is highly likely that we can find a reliable and useful document to support the response.", "Table 8: Instructions and demonstrations for\taspect given the input only.", "Table 9: Instructions and demonstrations for and retrieved passages.", "aspect given the input, preceding generations,", "Table 10: Instructions and demonstrations for\taspect given the input only.", "Instructions", "You will receive an instruction, evidence, and output, and optional preceding sentences", " If the preceding sentence is given, the output should be the sentence that follows those preceding sentences", " Your task is to evaluate if the output is fully supported by the information provided in the evidence", "", "Use the following entailment scale to generate a score:", "[Fully supported] - All information in output is supported by the evidence, or extractions from the evidence", " This is only applicable when the output and part of the evidence are almost identical", "", "[Partially supported] - The output is supported by the evidence to some extent, but there is major information in the output that is not discussed in the evidence", " For example, if an instruction asks about two concepts and the evidence only discusses either of them, it should be considered a [Partially supported]", "", "[No support / Contradictory] - The output completely ignores evidence, is unrelated to the evidence, or contradicts the evidence", " This can also happen if the evidence is irrelevant to the instruction", "", "Make sure to not use any external information/knowledge to judge whether the out- put is true or not", " Only check whether the output is supported by the evidence, and not whether the output follows the instructions or not", "", "Instruction Explain the use of word embeddings in Natural Language Processing", " Preceding sentences Word embeddings are one of the most powerful tools available for Natural Language Processing (NLP)", " They are mathematical representations of words or phrases in a vector space, allowing similarities between words and the context in which they are used to be measured", "", "Output Word embeddings are useful for tasks such as sentiment analysis, text classification, predicting the next word in a sequence, and understanding synonyms and analogies.", "Evidence Word embedding", "Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers", " Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with a much lower dimension", " Methods to generate this mapping include neural networks, dimensionality reduction on the word co-occurrence matrix, probabilistic models, explainable knowledge base method, and explicit representation in terms of the context in which words appear", " Word and phrase embeddings, when used as the underlying input representation, have been shown to boost the performance in NLP tasks such as syntactic parsing, sentiment analysis, next token predictions as well and analogy detection", "", "Score [Fully supported]", "Explanation The output sentence discusses the application of word embeddings, and the evidence mentions all of the applications syntactic parsing, sentiment analysis, next token predictions as well as analogy detection as the applications", " Therefore, the score should be [Fully supported]", "", "Table 11: Instructions and demonstrations for\ttokens.", "Table 12: Instructions and demonstrations for\ttokens."], "2310.11511v1.docx"]
[["Retrieval-Augmented Generation for Large Language Models: A Survey", "Yunfan Gaoa, Yun Xiongb, Xinyu Gaob, Kangxiang Jiab, Jinliu Panb, Yuxi Bic, Yi Daia, Jiawei Suna, Meng Wangc, and Haofen Wang a,c", "aShanghai Research Institute for Intelligent Autonomous Systems, Tongji University", "bShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University", "cCollege of Design and Innovation, Tongji University", "Abstract—Large Language Models (LLMs) showcase impres- sive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes", " Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases", " This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain- specific information", " RAG synergistically merges LLMs’ intrin- sic knowledge with the vast, dynamic repositories of external databases", " This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG", " It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques", " The paper highlights the state-of-the- art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems", " Furthermore, this paper introduces up-to-date evalua- tion framework and benchmark", " At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development 1", "", "Index Terms—Large language model, retrieval-augmented gen- eration, natural language processing, information retrieval", "Introduction", "ARGE language models (LLMs) have achieved remark- able success, though they still face significant limitations, especially in domain-specific or knowledge-intensive tasks [1], notably producing “hallucinations” [2] when handling queries beyond their training data or requiring current information", " To overcome challenges, Retrieval-Augmented Generation (RAG) enhances LLMs by retrieving relevant document chunks from external knowledge base through semantic similarity calcu- lation", " By referencing external knowledge, RAG effectively reduces the problem of generating factually incorrect content", " Its integration into LLMs has resulted in widespread adoption, establishing RAG as a key technology in advancing chatbots and enhancing the suitability of LLMs for real-world applica-", "tions.", "RAG technology has rapidly developed in recent years, and the technology tree summarizing related research is shown", "Corresponding Author", "Email:haofen", "wang@tongji", "edu", "cn", "1Resources\tare\tavailable\tat\thttps://github.com/Tongji-KGLLM/ RAG-Survey", "in Figure 1", " The development trajectory of RAG in the era of large models exhibits several distinct stage characteristics", " Initially, RAG’s inception coincided with the rise of the Transformer architecture, focusing on enhancing language models by incorporating additional knowledge through Pre- Training Models (PTM)", " This early stage was characterized by foundational work aimed at refining pre-training techniques [3]–[5]", "The subsequent arrival of ChatGPT [6] marked a pivotal moment, with LLM demonstrating powerful in context learning (ICL) capabilities", " RAG research shifted towards providing better information for LLMs to answer more com- plex and knowledge-intensive tasks during the inference stage, leading to rapid development in RAG studies", " As research progressed, the enhancement of RAG was no longer limited to the inference stage but began to incorporate more with LLM fine-tuning techniques", "", "The burgeoning field of RAG has experienced swift growth, yet it has not been accompanied by a systematic synthesis that could clarify its broader trajectory", " This survey endeavors to fill this gap by mapping out the RAG process and charting its evolution and anticipated future paths, with a focus on the integration of RAG within LLMs", " This paper considers both technical paradigms and research methods, summarizing three main research paradigms from over 100 RAG studies, and analyzing key technologies in the core stages of “Retrieval,” “Generation,” and “Augmentation", "” On the other hand, current research tends to focus more on methods, lacking analysis and summarization of how to evaluate RAG", " This paper compre- hensively reviews the downstream tasks, datasets, benchmarks, and evaluation methods applicable to RAG", " Overall, this paper sets out to meticulously compile and categorize the foundational technical concepts, historical progression, and the spectrum of RAG methodologies and applications that have emerged post-LLMs", " It is designed to equip readers and professionals with a detailed and structured understanding of both large models and RAG", " It aims to illuminate the evolution of retrieval augmentation techniques, assess the strengths and weaknesses of various approaches in their respective contexts, and speculate on upcoming trends and innovations", "", "Our contributions are as follows:", "In this survey, we present a thorough and systematic review of the state-of-the-art RAG methods, delineating its evolution through paradigms including naive RAG,", "Fig", " 1", " Technology tree of RAG research", " The stages of involving RAG mainly include pre-training, fine-tuning, and inference", " With the emergence of LLMs, research on RAG initially focused on leveraging the powerful in context learning abilities of LLMs, primarily concentrating on the inference stage", " Subsequent research has delved deeper, gradually integrating more with the fine-tuning of LLMs", " Researchers have also been exploring ways to enhance language models in the pre-training stage through retrieval-augmented techniques", "", "advanced RAG, and modular RAG", " This review contex- tualizes the broader scope of RAG research within the landscape of LLMs", "", "We identify and discuss the central technologies integral to the RAG process, specifically focusing on the aspects of “Retrieval”, “Generation” and “Augmentation”, and delve into their synergies, elucidating how these com- ponents intricately collaborate to form a cohesive and effective RAG framework.", "We have summarized the current assessment methods of RAG, covering 26 tasks, nearly 50 datasets, outlining the evaluation objectives and metrics, as well as the current evaluation benchmarks and tools", " Additionally, we anticipate future directions for RAG, emphasizing potential enhancements to tackle current challenges", "", "The paper unfolds as follows: Section II introduces the main concept and current paradigms of RAG", " The following three sections explore core components—“Retrieval”, “Gen- eration” and “Augmentation”, respectively", " Section III focuses on optimization methods in retrieval,including indexing, query and embedding optimization", " Section IV concentrates on post- retrieval process and LLM fine-tuning in generation", " Section V analyzes the three augmentation processes", " Section VI focuses on RAG’s downstream tasks and evaluation system", " Sec- tion VII mainly discusses the challenges that RAG currently", "faces and its future development directions", " At last, the paper concludes in Section VIII", "", "Overview of RAG", "A typical application of RAG is illustrated in Figure 2", " Here, a user poses a question to ChatGPT about a recent, widely discussed news", " Given ChatGPT’s reliance on pre- training data, it initially lacks the capacity to provide up- dates on recent developments", " RAG bridges this information gap by sourcing and incorporating knowledge from external databases", " In this case, it gathers relevant news articles related to the user’s query", " These articles, combined with the original question, form a comprehensive prompt that empowers LLMs to generate a well-informed answer", "", "The RAG research paradigm is continuously evolving, and we categorize it into three stages: Naive RAG, Advanced RAG, and Modular RAG, as showed in Figure 3", " Despite RAG method are cost-effective and surpass the performance of the native LLM, they also exhibit several limitations", " The development of Advanced RAG and Modular RAG is a response to these specific shortcomings in Naive RAG", "", "Naive RAG", "The Naive RAG research paradigm represents the earli- est methodology, which gained prominence shortly after the", "Fig", " 2", " A representative instance of the RAG process applied to question answering", " It mainly consists of 3 steps", " 1) Indexing", " Documents are split into chunks, encoded into vectors, and stored in a vector database", " 2) Retrieval", " Retrieve the Top k chunks most relevant to the question based on semantic similarity", " 3) Generation", " Input the original question and the retrieved chunks together into LLM to generate the final answer", "", "widespread adoption of ChatGPT", " The Naive RAG follows a traditional process that includes indexing, retrieval, and generation, which is also characterized as a “Retrieve-Read” framework [7]", "", "Indexing starts with the cleaning and extraction of raw data in diverse formats like PDF, HTML, Word, and Markdown, which is then converted into a uniform plain text format", " To accommodate the context limitations of language models, text is segmented into smaller, digestible chunks", " Chunks are then encoded into vector representations using an embedding model and stored in vector database", " This step is crucial for enabling efficient similarity searches in the subsequent retrieval phase", " Retrieval", " Upon receipt of a user query, the RAG system employs the same encoding model utilized during the indexing phase to transform the query into a vector representation", " It then computes the similarity scores between the query", "vector and the vector of chunks within the indexed corpus", " The system prioritizes and retrieves the top K chunks that demonstrate the greatest similarity to the query", " These chunks are subsequently used as the expanded context in prompt", "", "Generation", " The posed query and selected documents are synthesized into a coherent prompt to which a large language model is tasked with formulating a response", " The model’s approach to answering may vary depending on task-specific criteria, allowing it to either draw upon its inherent parametric knowledge or restrict its responses to the information con- tained within the provided documents", " In cases of ongoing dialogues, any existing conversational history can be integrated into the prompt, enabling the model to engage in multi-turn dialogue interactions effectively", "", "However, Naive RAG encounters notable drawbacks:", "Retrieval Challenges", " The retrieval phase often struggles with precision and recall, leading to the selection of misaligned or irrelevant chunks, and the missing of crucial information", "", "Generation Difficulties", " In generating responses, the model may face the issue of hallucination, where it produces con- tent not supported by the retrieved context", " This phase can also suffer from irrelevance, toxicity, or bias in the outputs, detracting from the quality and reliability of the responses", "", "Augmentation Hurdles", " Integrating retrieved information with the different task can be challenging, sometimes resulting in disjointed or incoherent outputs", " The process may also encounter redundancy when similar information is retrieved from multiple sources, leading to repetitive responses", " Deter- mining the significance and relevance of various passages and ensuring stylistic and tonal consistency add further complexity", " Facing complex issues, a single retrieval based on the original query may not suffice to acquire adequate context information", " Moreover, there’s a concern that generation models might overly rely on augmented information, leading to outputs that simply echo retrieved content without adding insightful or", "synthesized information.", "Advanced RAG", "Advanced RAG introduces specific improvements to over- come the limitations of Naive RAG", " Focusing on enhancing re- trieval quality, it employs pre-retrieval and post-retrieval strate- gies", " To tackle the indexing issues, Advanced RAG refines its indexing techniques through the use of a sliding window approach, fine-grained segmentation, and the incorporation of metadata", " Additionally, it incorporates several optimization methods to streamline the retrieval process [8]", "", "Fig", " 3", " Comparison between the three paradigms of RAG", " (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation", " (Middle) Advanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a chain-like structure", " (Right) Modular RAG inherits and develops from the previous paradigm, showcasing greater flexibility overall", " This is evident in the introduction of multiple specific functional modules and the replacement of existing modules", " The overall process is not limited to sequential retrieval and generation; it includes methods such as iterative and adaptive retrieval", "", "Pre-retrieval process", " In this stage, the primary focus is on optimizing the indexing structure and the original query", " The goal of optimizing indexing is to enhance the quality of the content being indexed", " This involves strategies: enhancing data granularity, optimizing index structures, adding metadata, alignment optimization, and mixed retrieval", " While the goal of query optimization is to make the user’s original question clearer and more suitable for the retrieval task", " Common methods include query rewriting query transformation, query expansion and other techniques [7], [9]–[11]", "", "Post-Retrieval Process", " Once relevant context is retrieved, it’s crucial to integrate it effectively with the query", " The main methods in post-retrieval process include rerank chunks and context compressing", " Re-ranking the retrieved information to relocate the most relevant content to the edges of the prompt is a key strategy", " This concept has been implemented in frame- works such as LlamaIndex2, LangChain3, and HayStack [12]", " Feeding all relevant documents directly into LLMs can lead to information overload, diluting the focus on key details with irrelevant content", "To mitigate this, post-retrieval efforts con- centrate on selecting the essential information, emphasizing critical sections, and shortening the context to be processed", "", "2https://www", "llamaindex", "ai", "3https://www", "langchain", "com/", "Modular RAG", "The modular RAG architecture advances beyond the for- mer two RAG paradigms, offering enhanced adaptability and versatility", " It incorporates diverse strategies for improving its components, such as adding a search module for similarity searches and refining the retriever through fine-tuning", " Inno- vations like restructured RAG modules [13] and rearranged RAG pipelines [14] have been introduced to tackle specific challenges", " The shift towards a modular RAG approach is becoming prevalent, supporting both sequential processing and integrated end-to-end training across its components", " Despite its distinctiveness, Modular RAG builds upon the foundational principles of Advanced and Naive RAG, illustrating a progres- sion and refinement within the RAG family", "", "New Modules: The Modular RAG framework introduces additional specialized components to enhance retrieval and processing capabilities", " The Search module adapts to spe- cific scenarios, enabling direct searches across various data sources like search engines, databases, and knowledge graphs, using LLM-generated code and query languages [15]", " RAG- Fusion addresses traditional search limitations by employing a multi-query strategy that expands user queries into diverse perspectives, utilizing parallel vector searches and intelligent re-ranking to uncover both explicit and transformative knowl- edge [16]", " The Memory module leverages the LLM’s memory to guide retrieval, creating an unbounded memory pool that", "aligns the text more closely with data distribution through iter- ative self-enhancement [17], [18]", " Routing in the RAG system navigates through diverse data sources, selecting the optimal pathway for a query, whether it involves summarization, specific database searches, or merging different information streams [19]", " The Predict module aims to reduce redundancy and noise by generating context directly through the LLM, ensuring relevance and accuracy [13]", " Lastly, the Task Adapter module tailors RAG to various downstream tasks, automating prompt retrieval for zero-shot inputs and creating task-specific retrievers through few-shot query generation [20], [21] ", "This comprehensive approach not only streamlines the retrieval pro- cess but also significantly improves the quality and relevance of the information retrieved, catering to a wide array of tasks and queries with enhanced precision and flexibility", "", "New Patterns: Modular RAG offers remarkable adapt-", "ability by allowing module substitution or reconfiguration to address specific challenges", " This goes beyond the fixed structures of Naive and Advanced RAG, characterized by a simple “Retrieve” and “Read” mechanism", " Moreover, Modular RAG expands this flexibility by integrating new modules or adjusting interaction flow among existing ones, enhancing its applicability across different tasks", "", "Innovations such as the Rewrite-Retrieve-Read [7]model leverage the LLM’s capabilities to refine retrieval queries through a rewriting module and a LM-feedback mechanism to update rewriting model", ", improving task performance", " Similarly, approaches like Generate-Read [13] replace tradi- tional retrieval with LLM-generated content, while Recite- Read [22] emphasizes retrieval from model weights, enhanc- ing the model’s ability to handle knowledge-intensive tasks", " Hybrid retrieval strategies integrate keyword, semantic, and vector searches to cater to diverse queries", " Additionally, em- ploying sub-queries and hypothetical document embeddings (HyDE) [11] seeks to improve retrieval relevance by focusing on embedding similarities between generated answers and real documents", "", "Adjustments in module arrangement and interaction, such as the Demonstrate-Search-Predict (DSP) [23] framework and the iterative Retrieve-Read-Retrieve-Read flow of ITER- RETGEN [14], showcase the dynamic use of module out- puts to bolster another module’s functionality, illustrating a sophisticated understanding of enhancing module synergy", " The flexible orchestration of Modular RAG Flow showcases the benefits of adaptive retrieval through techniques such as FLARE [24] and Self-RAG [25]", " This approach transcends the fixed RAG retrieval process by evaluating the necessity of retrieval based on different scenarios", " Another benefit of a flexible architecture is that the RAG system can more easily integrate with other technologies (such as fine-tuning or reinforcement learning) [26]", " For example, this can involve fine-tuning the retriever for better retrieval results, fine-tuning the generator for more personalized outputs, or engaging in collaborative fine-tuning [27]", "", "RAG vs Fine-tuning", "The augmentation of LLMs has attracted considerable atten- tion due to their growing prevalence. Among the optimization", "methods for LLMs, RAG is often compared with Fine-tuning (FT) and prompt engineering", " Each method has distinct charac- teristics as illustrated in Figure 4", " We used a quadrant chart to illustrate the differences among three methods in two dimen- sions: external knowledge requirements and model adaption requirements", " Prompt engineering leverages a model’s inherent capabilities with minimum necessity for external knowledge and model adaption", " RAG can be likened to providing a model with a tailored textbook for information retrieval, ideal for pre- cise information retrieval tasks", " In contrast, FT is comparable to a student internalizing knowledge over time, suitable for scenarios requiring replication of specific structures, styles, or formats", "", "RAG excels in dynamic environments by offering real- time knowledge updates and effective utilization of external knowledge sources with high interpretability", " However, it comes with higher latency and ethical considerations regarding data retrieval", " On the other hand, FT is more static, requiring retraining for updates but enabling deep customization of the model’s behavior and style", " It demands significant compu- tational resources for dataset preparation and training, and while it can reduce hallucinations, it may face challenges with unfamiliar data", "", "In multiple evaluations of their performance on various knowledge-intensive tasks across different topics, [28] re- vealed that while unsupervised fine-tuning shows some im- provement, RAG consistently outperforms it, for both exist- ing knowledge encountered during training and entirely new knowledge", " Additionally, it was found that LLMs struggle to learn new factual information through unsupervised fine- tuning", " The choice between RAG and FT depends on the specific needs for data dynamics, customization, and com- putational capabilities in the application context", " RAG and FT are not mutually exclusive and can complement each other, enhancing a model’s capabilities at different levels", " In some instances, their combined use may lead to optimal performance", " The optimization process involving RAG and FT may require multiple iterations to achieve satisfactory results", "", "Retrieval", "In the context of RAG, it is crucial to efficiently retrieve relevant documents from the data source", " There are several key issues involved, such as the retrieval source, retrieval granularity, pre-processing of the retrieval, and selection of the corresponding embedding model", "", "Retrieval Source", "RAG relies on external knowledge to enhance LLMs, while the type of retrieval source and the granularity of retrieval units both affect the final generation results.", "Data Structure: Initially, text is s the mainstream source of retrieval", " Subsequently, the retrieval source expanded to in- clude semi-structured data (PDF) and structured data (Knowl- edge Graph, KG) for enhancement", " In addition to retrieving from original external sources, there is also a growing trend in recent researches towards utilizing content generated by LLMs themselves for retrieval and enhancement purposes", "", "TABLE I", "Summary of RAG methods", "Fig", " 4", " RAG compared with other model optimization methods in the aspects of “External Knowledge Required” and “Model Adaption Required”", " Prompt Engineering requires low modifications to the model and external knowledge, focusing on harnessing the capabilities of LLMs themselves", " Fine-tuning, on the other hand, involves further training the model", " In the early stages of RAG (Naive RAG), there is a low demand for model modifications", " As research progresses, Modular RAG has become more integrated with fine-tuning techniques", "", "Unstructured Data, such as text, is the most widely used retrieval source, which are mainly gathered from corpus", " For open-domain question-answering (ODQA) tasks, the primary retrieval sources are Wikipedia Dump with the current major versions including HotpotQA 4 (1st October , 2017), DPR5 (20 December, 2018)", " In addition to encyclopedic data, common unstructured data includes cross-lingual text [19] and domain- specific data (such as medical [67]and legal domains [29])", "", "Semi-structured data", " typically refers to data that contains a combination of text and table information, such as PDF", " Han- dling semi-structured data poses challenges for conventional RAG systems due to two main reasons", " Firstly, text splitting processes may inadvertently separate tables, leading to data corruption during retrieval", " Secondly, incorporating tables into the data can complicate semantic similarity searches", " When dealing with semi-structured data, one approach involves lever- aging the code capabilities of LLMs to execute Text-2-SQL queries on tables within databases, such as TableGPT [85]", " Alternatively, tables can be transformed into text format for further analysis using text-based methods [75]", " However, both of these methods are not optimal solutions, indicating substan- tial research opportunities in this area", "", "Structured data, such as knowledge graphs (KGs) [86] , which are typically verified and can provide more precise in- formation", " KnowledGPT [15] generates KB search queries and stores knowledge in a personalized base, enhancing the RAG model’s knowledge richness", " In response to the limitations of LLMs in understanding and answering questions about textual graphs, G-Retriever [84] integrates Graph Neural Networks", "4https://hotpotqa", "github", "io/wiki-readme", "html 5https://github", "com/facebookresearch/DPR", "(GNNs), LLMs and RAG, enhancing graph comprehension and question-answering capabilities through soft prompting of the LLM, and employs the Prize-Collecting Steiner Tree (PCST) optimization problem for targeted graph retrieval", " On the contrary, it requires additional effort to build, validate, and maintain structured databases", " On the contrary, it requires additional effort to build, validate, and maintain structured databases", "", "LLMs-Generated Content", " Addressing the limitations of external auxiliary information in RAG, some research has focused on exploiting LLMs’ internal knowledge", " SKR [58] classifies questions as known or unknown, applying retrieval enhancement selectively", " GenRead [13] replaces the retriever with an LLM generator, finding that LLM-generated contexts often contain more accurate answers due to better alignment with the pre-training objectives of causal language modeling", " Selfmem [17] iteratively creates an unbounded memory pool with a retrieval-enhanced generator, using a memory selec- tor to choose outputs that serve as dual problems to the original question, thus self-enhancing the generative model", " These methodologies underscore the breadth of innovative data source utilization in RAG, striving to improve model performance and task effectiveness", "", "Retrieval Granularity: Another important factor besides the data format of the retrieval source is the granularity of the retrieved data", " Coarse-grained retrieval units theoretically can provide more relevant information for the problem, but they may also contain redundant content, which could distract the retriever and language models in downstream tasks [50], [87]", " On the other hand, fine-grained retrieval unit granularity increases the burden of retrieval and does not guarantee seman- tic integrity and meeting the required knowledge", " Choosing", "the appropriate retrieval granularity during inference can be a simple and effective strategy to improve the retrieval and downstream task performance of dense retrievers.", "In text, retrieval granularity ranges from fine to coarse, including Token, Phrase, Sentence, Proposition, Chunks, Doc- ument", " Among them, DenseX [30]proposed the concept of using propositions as retrieval units", " Propositions are defined as atomic expressions in the text, each encapsulating a unique factual segment and presented in a concise, self-contained nat- ural language format", " This approach aims to enhance retrieval precision and relevance", " On the Knowledge Graph (KG), retrieval granularity includes Entity, Triplet, and sub-Graph", " The granularity of retrieval can also be adapted to downstream tasks, such as retrieving Item IDs [40]in recommendation tasks and Sentence pairs [38]", " Detailed information is illustrated in Table I", "", "Indexing Optimization", "In the Indexing phase, documents will be processed, seg- mented, and transformed into Embeddings to be stored in a vector database", " The quality of index construction determines whether the correct context can be obtained in the retrieval phase", "", "Chunking Strategy: The most common method is to split the document into chunks on a fixed number of tokens (e", "g", ", 100, 256, 512) [88]", " Larger chunks can capture more context, but they also generate more noise, requiring longer processing time and higher costs", " While smaller chunks may not fully convey the necessary context, they do have less noise", " How- ever, chunks leads to truncation within sentences, prompting the optimization of a recursive splits and sliding window meth- ods, enabling layered retrieval by merging globally related information across multiple retrieval processes [89]", " Never- theless, these approaches still cannot strike a balance between semantic completeness and context length", " Therefore, methods like Small2Big have been proposed, where sentences (small) are used as the retrieval unit, and the preceding and following sentences are provided as (big) context to LLMs [90]", "", "Metadata Attachments: Chunks can be enriched with metadata information such as page number, file name, au- thor,category timestamp", " Subsequently, retrieval can be filtered based on this metadata, limiting the scope of the retrieval", " Assigning different weights to document timestamps during retrieval can achieve time-aware RAG, ensuring the freshness of knowledge and avoiding outdated information", "", "In addition to extracting metadata from the original doc- uments, metadata can also be artificially constructed", " For example, adding summaries of paragraph, as well as intro- ducing hypothetical questions", " This method is also known as Reverse HyDE", " Specifically, using LLM to generate questions that can be answered by the document, then calculating the similarity between the original question and the hypothetical question during retrieval to reduce the semantic gap between the question and the answer", "", "Structural Index: One effective method for enhancing information retrieval is to establish a hierarchical structure for the documents", " By constructing In structure, RAG system can expedite the retrieval and processing of pertinent data", "", "Hierarchical index structure", " File are arranged in parent- child relationships, with chunks linked to them", " Data sum- maries are stored at each node, aiding in the swift traversal of data and assisting the RAG system in determining which chunks to extract", " This approach can also mitigate the illusion caused by block extraction issues", "", "Knowledge Graph index", " Utilize KG in constructing the hierarchical structure of documents contributes to maintaining consistency", " It delineates the connections between different concepts and entities, markedly reducing the potential for illusions", " Another advantage is the transformation of the information retrieval process into instructions that LLM can comprehend, thereby enhancing the accuracy of knowledge retrieval and enabling LLM to generate contextually coherent responses, thus improving the overall efficiency of the RAG system", " To capture the logical relationship between document content and structure, KGP [91] proposed a method of building an index between multiple documents using KG", " This KG consists of nodes (representing paragraphs or structures in the documents, such as pages and tables) and edges (indicating semantic/lexical similarity between paragraphs or relationships within the document structure), effectively addressing knowl- edge retrieval and reasoning problems in a multi-document environment", "", "Query Optimization", "One of the primary challenges with Naive RAG is its direct reliance on the user’s original query as the basis for retrieval", " Formulating a precise and clear question is difficult, and imprudent queries result in subpar retrieval effectiveness", " Sometimes, the question itself is complex, and the language is not well-organized", " Another difficulty lies in language complexity ambiguity", " Language models often struggle when dealing with specialized vocabulary or ambiguous abbrevi- ations with multiple meanings", " For instance, they may not discern whether “LLM” refers to large language model or a Master of Laws in a legal context", "", "Query Expansion: Expanding a single query into mul- tiple queries enriches the content of the query, providing further context to address any lack of specific nuances, thereby ensuring the optimal relevance of the generated answers.", "Multi-Query", " By employing prompt engineering to expand queries via LLMs, these queries can then be executed in parallel", " The expansion of queries is not random, but rather meticulously designed", "", "Sub-Query", " The process of sub-question planning represents the generation of the necessary sub-questions to contextualize and fully answer the original question when combined", " This process of adding relevant context is, in principle, similar to query expansion", " Specifically, a complex question can be decomposed into a series of simpler sub-questions using the least-to-most prompting method [92]", "", "Chain-of-Verification(CoVe)", " The expanded queries undergo validation by LLM to achieve the effect of reducing halluci- nations", " Validated expanded queries typically exhibit higher reliability [93]", "", "Query Transformation: The core concept is to retrieve chunks based on a transformed query instead of the user’s original query.", "Query Rewrite", "The original queries are not always optimal for LLM retrieval, especially in real-world scenarios", " There- fore, we can prompt LLM to rewrite the queries", " In addition to using LLM for query rewriting, specialized smaller language models, such as RRR (Rewrite-retrieve-read) [7]", " The imple- mentation of the query rewrite method in the Taobao, known as BEQUE [9] has notably enhanced recall effectiveness for long-tail queries, resulting in a rise in GMV", "", "Another query transformation method is to use prompt engineering to let LLM generate a query based on the original query for subsequent retrieval", " HyDE [11] construct hypothet- ical documents (assumed answers to the original query)", " It focuses on embedding similarity from answer to answer rather than seeking embedding similarity for the problem or query", " Using the Step-back Prompting method [10], the original query is abstracted to generate a high-level concept question (step-back question)", " In the RAG system, both the step-back question and the original query are used for retrieval, and both the results are utilized as the basis for language model answer generation", "", "Query Routing: Based on varying queries, routing to distinct RAG pipeline,which is suitable for a versatile RAG system designed to accommodate diverse scenarios.", "Metadata Router/ Filter", " The first step involves extracting keywords (entity) from the query, followed by filtering based on the keywords and metadata within the chunks to narrow down the search scope", "", "Semantic Router is another method of routing involves leveraging the semantic information of the query", " Specific apprach see Semantic Router 6", " Certainly, a hybrid routing approach can also be employed, combining both semantic and metadata-based methods for enhanced query routing", "", "Embedding", "In RAG, retrieval is achieved by calculating the similarity (e", "g", " cosine similarity) between the embeddings of the ques- tion and document chunks, where the semantic representation capability of embedding models plays a key role", " This mainly includes a sparse encoder (BM25) and a dense retriever (BERT architecture Pre-training language models)", " Recent research has introduced prominent embedding models such as AngIE, Voyage, BGE,etc [94]–[96], which are benefit from multi-task instruct tuning", " Hugging Face’s MTEB leaderboard 7 evaluates embedding models across 8 tasks, covering 58 datasests", " Ad- ditionally, C-MTEB focuses on Chinese capability, covering 6 tasks and 35 datasets", " There is no one-size-fits-all answer to “which embedding model to use", "” However, some specific models are better suited for particular use cases", "", "Mix/hybrid Retrieval : Sparse and dense embedding approaches capture different relevance features and can ben- efit from each other by leveraging complementary relevance information. For instance, sparse retrieval models can be used", "6https://github.com/aurelio-labs/semantic-router", "7https://huggingface.co/spaces/mteb/leaderboard", "to provide initial search results for training dense retrieval models", " Additionally, pre-training language models (PLMs) can be utilized to learn term weights to enhance sparse retrieval", " Specifically, it also demonstrates that sparse retrieval models can enhance the zero-shot retrieval capability of dense retrieval models and assist dense retrievers in handling queries containing rare entities, thereby improving robustness", "", "Fine-tuning Embedding Model: In instances where the context significantly deviates from pre-training corpus, partic- ularly within highly specialized disciplines such as healthcare, legal practice, and other sectors replete with proprietary jargon, fine-tuning the embedding model on your own domain dataset becomes essential to mitigate such discrepancies.", "In addition to supplementing domain knowledge, another purpose of fine-tuning is to align the retriever and generator, for example, using the results of LLM as the supervision signal for fine-tuning, known as LSR (LM-supervised Retriever)", " PROMPTAGATOR [21] utilizes the LLM as a few-shot query generator to create task-specific retrievers, addressing chal- lenges in supervised fine-tuning, particularly in data-scarce domains", " Another approach, LLM-Embedder [97], exploits LLMs to generate reward signals across multiple downstream tasks", " The retriever is fine-tuned with two types of supervised signals: hard labels for the dataset and soft rewards from the LLMs", " This dual-signal approach fosters a more effective fine-tuning process, tailoring the embedding model to diverse downstream applications", " REPLUG [72] utilizes a retriever and an LLM to calculate the probability distributions of the retrieved documents and then performs supervised training by computing the KL divergence", " This straightforward and effective training method enhances the performance of the retrieval model by using an LM as the supervisory signal, eliminating the need for specific cross-attention mechanisms", " Moreover, inspired by RLHF (Reinforcement Learning from Human Feedback), utilizing LM-based feedback to reinforce the retriever through reinforcement learning", "", "Adapter", "Fine-tuning models may present challenges, such as in- tegrating functionality through an API or addressing con- straints arising from limited local computational resources", " Consequently, some approaches opt to incorporate an external adapter to aid in alignment", "", "To optimize the multi-task capabilities of LLM, UP- RISE [20] trained a lightweight prompt retriever that can automatically retrieve prompts from a pre-built prompt pool that are suitable for a given zero-shot task input", " AAR (Augmentation-Adapted Retriver) [47] introduces a universal adapter designed to accommodate multiple downstream tasks", " While PRCA [69] add a pluggable reward-driven contextual adapter to enhance performance on specific tasks", " BGM [26] keeps the retriever and LLM fixed,and trains a bridge Seq2Seq model in between", " The bridge model aims to transform the retrieved information into a format that LLMs can work with effectively, allowing it to not only rerank but also dynami- cally select passages for each query, and potentially employ more advanced strategies like repetition", " Furthermore, PKG", "introduces an innovative method for integrating knowledge into white-box models via directive fine-tuning [75]", " In this approach, the retriever module is directly substituted to gen- erate relevant documents according to a query", " This method assists in addressing the difficulties encountered during the fine-tuning process and enhances model performance", "", "Generation", "After retrieval, it is not a good practice to directly input all the retrieved information to the LLM for answering questions", " Following will introduce adjustments from two perspectives: adjusting the retrieved content and adjusting the LLM", "", "Context Curation", "Redundant information can interfere with the final gener- ation of LLM, and overly long contexts can also lead LLM to the “Lost in the middle” problem [98]", " Like humans, LLM tends to only focus on the beginning and end of long texts, while forgetting the middle portion", " Therefore, in the RAG system, we typically need to further process the retrieved content", "", "Reranking: Reranking fundamentally reorders document chunks to highlight the most pertinent results first, effectively reducing the overall document pool, severing a dual purpose in information retrieval, acting as both an enhancer and a filter, delivering refined inputs for more precise language model processing [70]", " Reranking can be performed using rule-based methods that depend on predefined metrics like Diversity, Relevance, and MRR, or model-based approaches like Encoder-Decoder models from the BERT series (e", "g", ", SpanBERT), specialized reranking models such as Cohere rerank or bge-raranker-large, and general large language mod- els like GPT [12], [99]", "", "Context Selection/Compression: A common misconcep- tion in the RAG process is the belief that retrieving as many relevant documents as possible and concatenating them to form a lengthy retrieval prompt is beneficial", " However, excessive context can introduce more noise, diminishing the LLM’s perception of key information ", "", "(Long) LLMLingua [100], [101] utilize small language models (SLMs) such as GPT-2 Small or LLaMA-7B, to detect and remove unimportant tokens, transforming it into a form that is challenging for humans to comprehend but well understood by LLMs", " This approach presents a direct and practical method for prompt compression, eliminating the need for additional training of LLMs while balancing language integrity and compression ratio", " PRCA tackled this issue by training an information extractor [69]", " Similarly, RECOMP adopts a comparable approach by training an information condenser using contrastive learning [71]", " Each training data point consists of one positive sample and five negative sam- ples, and the encoder undergoes training using contrastive loss throughout this process [102] ", "", "In addition to compressing the context, reducing the num- ber of documents aslo helps improve the accuracy of the model’s answers", " Ma et al", " [103] propose the “Filter-Reranker” paradigm, which combines the strengths of LLMs and SLMs", "", "In this paradigm, SLMs serve as filters, while LLMs function as reordering agents", " The research shows that instructing LLMs to rearrange challenging samples identified by SLMs leads to significant improvements in various Information Extraction (IE) tasks", " Another straightforward and effective approach involves having the LLM evaluate the retrieved content before generating the final answer", " This allows the LLM to filter out documents with poor relevance through LLM critique", " For instance, in Chatlaw [104], the LLM is prompted to self-suggestion on the referenced legal provisions to assess their relevance", "", "LLM Fine-tuning", "Targeted fine-tuning based on the scenario and data char- acteristics on LLMs can yield better results", " This is also one of the greatest advantages of using on-premise LLMs", " When LLMs lack data in a specific domain, additional knowledge can be provided to the LLM through fine-tuning", " Huggingface’s fine-tuning data can also be used as an initial step", "", "Another benefit of fine-tuning is the ability to adjust the model’s input and output", " For example, it can enable LLM to adapt to specific data formats and generate responses in a par- ticular style as instructed [37]", " For retrieval tasks that engage with structured data, the SANTA framework [76] implements a tripartite training regimen to effectively encapsulate both structural and semantic nuances", " The initial phase focuses on the retriever, where contrastive learning is harnessed to refine the query and document embeddings", "", "Aligning LLM outputs with human or retriever preferences through reinforcement learning is a potential approach", " For instance, manually annotating the final generated answers and then providing feedback through reinforcement learning", " In addition to aligning with human preferences, it is also possible to align with the preferences of fine-tuned models and retrievers [79]", " When circumstances prevent access to powerful proprietary models or larger parameter open-source models, a simple and effective method is to distill the more powerful models(e", "g", " GPT-4)", " Fine-tuning of LLM can also be coordinated with fine-tuning of the retriever to align pref- erences", " A typical approach, such as RA-DIT [27], aligns the scoring functions between Retriever and Generator using KL divergence", "", "Augmentation process in RAG", "In the domain of RAG, the standard practice often involves a singular (once) retrieval step followed by generation, which can lead to inefficiencies and sometimes is typically insuffi- cient for complex problems demanding multi-step reasoning, as it provides a limited scope of information [105]", " Many studies have optimized the retrieval process in response to this issue, and we have summarised them in Figure 5", "", "Iterative Retrieval", "Iterative retrieval is a process where the knowledge base is repeatedly searched based on the initial query and the text generated so far, providing a more comprehensive knowledge", "Fig", " 5", " In addition to the most common once retrieval, RAG also includes three types of retrieval augmentation processes", " (left) Iterative retrieval involves alternating between retrieval and generation, allowing for richer and more targeted context from the knowledge base at each step", " (Middle) Recursive retrieval involves gradually refining the user query and breaking down the problem into sub-problems, then continuously solving complex problems through retrieval and generation", " (Right) Adaptive retrieval focuses on enabling the RAG system to autonomously determine whether external knowledge retrieval is necessary and when to stop retrieval and generation, often utilizing LLM-generated special tokens for control", "", "base for LLMs", " This approach has been shown to enhance the robustness of subsequent answer generation by offering additional contextual references through multiple retrieval iterations", " However, it may be affected by semantic discon- tinuity and the accumulation of irrelevant information", " ITER- RETGEN [14] employs a synergistic approach that lever- ages “retrieval-enhanced generation” alongside “generation- enhanced retrieval” for tasks that necessitate the reproduction of specific information", " The model harnesses the content required to address the input task as a contextual basis for retrieving pertinent knowledge, which in turn facilitates the generation of improved responses in subsequent iterations", "", "Recursive Retrieval", "Recursive retrieval is often used in information retrieval and NLP to improve the depth and relevance of search results", " The process involves iteratively refining search queries based on the results obtained from previous searches", " Recursive Retrieval aims to enhance the search experience by gradu- ally converging on the most pertinent information through a feedback loop", " IRCoT [61] uses chain-of-thought to guide the retrieval process and refines the CoT with the obtained retrieval results", " ToC [57] creates a clarification tree that systematically optimizes the ambiguous parts in the Query", " It can be particularly useful in complex search scenarios where the user’s needs are not entirely clear from the outset or where the information sought is highly specialized or nuanced", " The recursive nature of the process allows for continuous learning and adaptation to the user’s requirements, often resulting in improved satisfaction with the search outcomes", "", "To address specific data scenarios, recursive retrieval and multi-hop retrieval techniques are utilized together. Recursive", "retrieval involves a structured index to process and retrieve data in a hierarchical manner, which may include summarizing sections of a document or lengthy PDF before performing a retrieval based on this summary", " Subsequently, a secondary retrieval within the document refines the search, embodying the recursive nature of the process", " In contrast, multi-hop retrieval is designed to delve deeper into graph-structured data sources, extracting interconnected information [106]", "", "Adaptive Retrieval", "Adaptive retrieval methods, exemplified by Flare [24] and Self-RAG [25], refine the RAG framework by enabling LLMs to actively determine the optimal moments and content for retrieval, thus enhancing the efficiency and relevance of the information sourced.", "These methods are part of a broader trend wherein LLMs employ active judgment in their operations, as seen in model agents like AutoGPT, Toolformer, and Graph- Toolformer [107]–[109]", " Graph-Toolformer, for instance, di- vides its retrieval process into distinct steps where LLMs proactively use retrievers, apply Self-Ask techniques, and em- ploy few-shot prompts to initiate search queries", " This proactive stance allows LLMs to decide when to search for necessary information, akin to how an agent utilizes tools", "", "WebGPT [110] integrates a reinforcement learning frame- work to train the GPT-3 model in autonomously using a search engine during text generation", " It navigates this process using special tokens that facilitate actions such as search engine queries, browsing results, and citing references, thereby expanding GPT-3’s capabilities through the use of external search engines", " Flare automates timing retrieval by monitoring the confidence of the generation process, as indicated by the", "probability of generated terms [24]", " When the probability falls below a certain threshold would activates the retrieval system to collect relevant information, thus optimizing the retrieval cycle", " Self-RAG [25] introduces “reflection tokens” that allow the model to introspect its outputs", " These tokens come in two varieties: “retrieve” and “critic”", " The model autonomously decides when to activate retrieval, or alternatively, a predefined threshold may trigger the process", " During retrieval, the gen- erator conducts a fragment-level beam search across multiple paragraphs to derive the most coherent sequence", " Critic scores are used to update the subdivision scores, with the flexibility to adjust these weights during inference, tailoring the model’s behavior", " Self-RAG’s design obviates the need for additional classifiers or reliance on Natural Language Inference (NLI) models, thus streamlining the decision-making process for when to engage retrieval mechanisms and improving the model’s autonomous judgment capabilities in generating ac- curate responses", "", "Task and Evaluation", "The rapid advancement and growing adoption of RAG in the field of NLP have propelled the evaluation of RAG models to the forefront of research in the LLMs community", " The primary objective of this evaluation is to comprehend and optimize the performance of RAG models across diverse application scenarios", "This chapter will mainly introduce the main downstream tasks of RAG, datasets, and how to evaluate RAG systems", "", "Downstream Task", "The core task of RAG remains Question Answering (QA), including traditional single-hop/multi-hop QA, multiple- choice, domain-specific QA as well as long-form scenarios suitable for RAG", " In addition to QA, RAG is continuously being expanded into multiple downstream tasks, such as Infor- mation Extraction (IE), dialogue generation, code search, etc", " The main downstream tasks of RAG and their corresponding datasets are summarized in Table II", "", "Evaluation Target", "Historically, RAG models assessments have centered on their execution in specific downstream tasks", " These evaluations employ established metrics suitable to the tasks at hand", " For instance, question answering evaluations might rely on EM and F1 scores [7], [45], [59], [72], whereas fact-checking tasks often hinge on Accuracy as the primary metric [4], [14], [42]", " BLEU and ROUGE metrics are also commonly used to evaluate answer quality [26], [32], [52], [78]", " Tools like RALLE, designed for the automatic evaluation of RAG applications, similarly base their assessments on these task- specific metrics [160]", " Despite this, there is a notable paucity of research dedicated to evaluating the distinct characteristics of RAG models", "The main evaluation objectives include:", "Retrieval Quality", " Evaluating the retrieval quality is crucial for determining the effectiveness of the context sourced by the retriever component", " Standard metrics from the domains", "of search engines, recommendation systems, and information retrieval systems are employed to measure the performance of the RAG retrieval module", " Metrics such as Hit Rate, MRR, and NDCG are commonly utilized for this purpose [161], [162]", "", "Generation Quality", " The assessment of generation quality centers on the generator’s capacity to synthesize coherent and relevant answers from the retrieved context", " This evaluation can be categorized based on the content’s objectives: unlabeled and labeled content", " For unlabeled content, the evaluation encompasses the faithfulness, relevance, and non-harmfulness of the generated answers", " In contrast, for labeled content, the focus is on the accuracy of the information produced by the model [161]", " Additionally, both retrieval and generation quality assessments can be conducted through manual or automatic evaluation methods [29], [161], [163]", "", "Evaluation Aspects", "Contemporary evaluation practices of RAG models empha- size three primary quality scores and four essential abilities, which collectively inform the evaluation of the two principal targets of the RAG model: retrieval and generation.", "Quality Scores: Quality scores include context rele- vance, answer faithfulness, and answer relevance", " These qual- ity scores evaluate the efficiency of the RAG model from different perspectives in the process of information retrieval and generation [164]–[166]", "", "Context Relevance evaluates the precision and specificity of the retrieved context, ensuring relevance and minimizing processing costs associated with extraneous content.", "Answer Faithfulness ensures that the generated answers remain true to the retrieved context, maintaining consistency and avoiding contradictions.", "Answer Relevance requires that the generated answers are directly pertinent to the posed questions, effectively addressing the core inquiry.", "Required Abilities: RAG evaluation also encompasses four abilities indicative of its adaptability and efficiency: noise robustness, negative rejection, information integration, and counterfactual robustness [167], [168]", " These abilities are critical for the model’s performance under various challenges and complex scenarios, impacting the quality scores", "", "Noise Robustness appraises the model’s capability to man- age noise documents that are question-related but lack sub- stantive information.", "Negative Rejection assesses the model’s discernment in refraining from responding when the retrieved documents do not contain the necessary knowledge to answer a question.", "Information Integration evaluates the model’s proficiency in synthesizing information from multiple documents to address complex questions.", "Counterfactual Robustness tests the model’s ability to rec- ognize and disregard known inaccuracies within documents, even when instructed about potential misinformation.", "Context relevance and noise robustness are important for evaluating the quality of retrieval, while answer faithfulness, answer relevance, negative rejection, information integration, and counterfactual robustness are important for evaluating the quality of generation.", "TABLE II", "TABLE III", "Summary of metrics applicable for evaluation aspects of RAG", "Relevance", "The specific metrics for each evaluation aspect are sum- marized in Table III", " It is essential to recognize that these metrics, derived from related work, are traditional measures and do not yet represent a mature or standardized approach for quantifying RAG evaluation aspects", " Custom metrics tailored to the nuances of RAG models, though not included here, have also been developed in some evaluation studies", "", "Evaluation Benchmarks and Tools", "A series of benchmark tests and tools have been proposed to facilitate the evaluation of RAG", "These instruments furnish quantitative metrics that not only gauge RAG model perfor- mance but also enhance comprehension of the model’s capabil- ities across various evaluation aspects", " Prominent benchmarks such as RGB, RECALL and CRUD [167]–[169] focus on appraising the essential abilities of RAG models", " Concur- rently, state-of-the-art automated tools like RAGAS [164], ARES [165], and TruLens8 employ LLMs to adjudicate the quality scores", " These tools and benchmarks collectively form a robust framework for the systematic evaluation of RAG models, as summarized in Table IV", "", "Discussion and Future Prospects", "Despite the considerable progress in RAG technology, sev- eral challenges persist that warrant in-depth research", "This chapter will mainly introduce the current challenges and future research directions faced by RAG", "", "RAG vs Long Context", "With the deepening of related research, the context of LLMs is continuously expanding [170]–[172]", " Presently, LLMs can effortlessly manage contexts exceeding 200,000 tokens 9", " This capability signifies that long-document question answering, previously reliant on RAG, can now incorporate the entire document directly into the prompt", " This has also sparked discussions on whether RAG is still necessary when LLMs", "8https://www", "trulens", "org/trulens eval/core concepts rag triad/", "\t\t ", "9https://kimi", "moonshot", "cn", "are not constrained by context", " In fact, RAG still plays an irreplaceable role", " On one hand, providing LLMs with a large amount of context at once will significantly impact its inference speed, while chunked retrieval and on-demand input can significantly improve operational efficiency", " On the other hand, RAG-based generation can quickly locate the original references for LLMs to help users verify the generated an- swers", " The entire retrieval and reasoning process is observable, while generation solely relying on long context remains a black box", " Conversely, the expansion of context provides new opportunities for the development of RAG, enabling it to address more complex problems and integrative or summary questions that require reading a large amount of material to answer [49]", " Developing new RAG methods in the context of super-long contexts is one of the future research trends", "", "RAG Robustness", "The presence of noise or contradictory information during retrieval can detrimentally affect RAG’s output quality", " This situation is figuratively referred to as “Misinformation can be worse than no information at all”", " Improving RAG’s resistance to such adversarial or counterfactual inputs is gain- ing research momentum and has become a key performance metric [48], [50], [82]", " Cuconasu et al", " [54] analyze which type of documents should be retrieved, evaluate the relevance of the documents to the prompt, their position, and the number included in the context", " The research findings reveal that including irrelevant documents can unexpectedly increase accuracy by over 30%, contradicting the initial assumption of reduced quality", " These results underscore the importance of developing specialized strategies to integrate retrieval with language generation models, highlighting the need for further research and exploration into the robustness of RAG", "", "Hybrid Approaches", "Combining RAG with fine-tuning is emerging as a leading strategy. Determining the optimal integration of RAG and fine-tuning whether sequential, alternating, or through end-to- end joint training—and how to harness both parameterized", "TABLE IV", "Summary of evaluation frameworks", "Evaluation Framework\tEvaluation Targets\tEvaluation Aspects\tQuantitative Metrics", "†\t\tRetrieval Quality Generation Quality", "Noise Robustness Negative Rejection Information Integration Counterfactual Robustness", "Accuracy EM", "Accuracy Accuracy", "RECALL†\tGeneration Quality\tCounterfactual Robustness\tR-Rate (Reappearance Rate)", "RAGAS‡", "ARES‡", "TruLens‡", "Retrieval Quality Generation Quality", "Retrieval Quality Generation Quality", "Retrieval Quality Generation Quality", "Context Relevance Faithfulness Answer Relevance", "Context Relevance Faithfulness Answer Relevance", "Context Relevance Faithfulness Answer Relevance", "Creative Generation", "*", "*", "Cosine Similarity", "Accuracy Accuracy Accuracy", "*", "*", "*", "BLEU", "†\t\tRetrieval Quality Generation Quality", "Knowledge-intensive QA Error Correction Summarization", "ROUGE-L", "BertScore RAGQuestEval", "† represents a benchmark, and ‡ represents a tool", " * denotes customized quantitative metrics, which deviate from traditional metrics", " Readers are encouraged to consult pertinent literature for the specific quantification formulas associated with these metrics, as required", "", "and non-parameterized advantages are areas ripe for explo- ration [27]", " Another trend is to introduce SLMs with specific functionalities into RAG and fine-tuned by the results of RAG system", " For example, CRAG [67] trains a lightweight retrieval evaluator to assess the overall quality of the retrieved docu- ments for a query and triggers different knowledge retrieval actions based on confidence levels", "", "Scaling laws of RAG", "End-to-end RAG models and pre-trained models based on RAG are still one of the focuses of current re- searchers [173]", "The parameters of these models are one of the key factors", "While scaling laws [174] are established for LLMs, their applicability to RAG remains uncertain", " Initial studies like RETRO++ [44] have begun to address this, yet the parameter count in RAG models still lags behind that of LLMs", " The possibility of an Inverse Scaling Law 10, where smaller models outperform larger ones, is particularly intriguing and merits further investigation", "", "Production-Ready RAG", "RAG’s practicality and alignment with engineering require- ments have facilitated its adoption. However, enhancing re- trieval efficiency, improving document recall in large knowl- edge bases, and ensuring data security—such as preventing", "10https://github.com/inverse-scaling/prize", "inadvertent disclosure of document sources or metadata by LLMs—are critical engineering challenges that remain to be addressed [175].", "The development of the RAG ecosystem is greatly impacted by the progression of its technical stack", " Key tools like LangChain and LLamaIndex have quickly gained popularity with the emergence of ChatGPT, providing extensive RAG- related APIs and becoming essential in the realm of LLMs", "The emerging technology stack, while not as rich in features as LangChain and LLamaIndex, stands out through its specialized products", " For example, Flowise AI prioritizes a low-code approach, allowing users to deploy AI applications, including RAG, through a user-friendly drag-and-drop interface", " Other technologies like HayStack, Meltano, and Cohere Coral are also gaining attention for their unique contributions to the field", " In addition to AI-focused vendors, traditional software and cloud service providers are expanding their offerings to include RAG-centric services", " Weaviate’s Verba 11 is designed for personal assistant applications, while Amazon’s Kendra 12 offers intelligent enterprise search services, enabling users to browse various content repositories using built-in connectors", " In the development of RAG technology, there is a clear trend towards different specialization directions, such as: 1) Customization - tailoring RAG to meet specific requirements", "", "2) Simplification - making RAG easier to use to reduce the", "11https://github", "com/weaviate/Verba 12https://aws", "amazon", "com/cn/kendra/", "Fig", " 6", " Summary of RAG ecosystem", "initial learning curve", " 3) Specialization - optimizing RAG to better serve production environments", "", "The mutual growth of RAG models and their technology stacks is evident; technological advancements continuously establish new standards for existing infrastructure", " In turn, enhancements to the technology stack drive the development of RAG capabilities", " RAG toolkits are converging into a foundational technology stack, laying the groundwork for advanced enterprise applications", " However, a fully integrated, comprehensive platform concept is still in the future, requiring further innovation and development", "", "Multi-modal RAG", "RAG has transcended its initial text-based question- answering confines, embracing a diverse array of modal data. This expansion has spawned innovative multimodal models that integrate RAG concepts across various domains:", "Image", " RA-CM3 [176] stands as a pioneering multimodal model of both retrieving and generating text and images", " BLIP-2 [177] leverages frozen image encoders alongside LLMs for efficient visual language pre-training, enabling zero- shot image-to-text conversions", " The “Visualize Before You Write” method [178] employs image generation to steer the LM’s text generation, showing promise in open-ended text generation tasks", "", "Audio and Video", " The GSS method retrieves and stitches together audio clips to convert machine-translated data into speech-translated data [179]", " UEOP marks a significant ad- vancement in end-to-end automatic speech recognition by incorporating external, offline strategies for voice-to-text con- version [180]", " Additionally, KNN-based attention fusion lever- ages audio embeddings and semantically related text embed- dings to refine ASR, thereby accelerating domain adaptation", "", "Vid2Seq augments language models with specialized temporal markers, facilitating the prediction of event boundaries and textual descriptions within a unified output sequence [181].", "Code", " RBPS [182] excels in small-scale learning tasks by retrieving code examples that align with developers’ objectives through encoding and frequency analysis", " This approach has demonstrated efficacy in tasks such as test assertion genera- tion and program repair", " For structured knowledge, the CoK method [106] first extracts facts pertinent to the input query from a knowledge graph, then integrates these facts as hints within the input, enhancing performance in knowledge graph question-answering tasks", "", "Conclusion", "The summary of this paper, as depicted in Figure 6, empha- sizes RAG’s significant advancement in enhancing the capa- bilities of LLMs by integrating parameterized knowledge from language models with extensive non-parameterized data from external knowledge bases", " The survey showcases the evolution of RAG technologies and their application on many different tasks", " The analysis outlines three developmental paradigms within the RAG framework: Naive, Advanced, and Modu- lar RAG, each representing a progressive enhancement over its predecessors", " RAG’s technical integration with other AI methodologies, such as fine-tuning and reinforcement learning, has further expanded its capabilities", " Despite the progress in RAG technology, there are research opportunities to improve its robustness and its ability to handle extended contexts", " RAG’s application scope is expanding into multimodal do- mains, adapting its principles to interpret and process diverse data forms like images, videos, and code", " This expansion high- lights RAG’s significant practical implications for AI deploy- ment, attracting interest from academic and industrial sectors", "", "The growing ecosystem of RAG is evidenced by the rise in RAG-centric AI applications and the continuous development of supportive tools", " As RAG’s application landscape broadens, there is a need to refine evaluation methodologies to keep pace with its evolution", " Ensuring accurate and representative performance assessments is crucial for fully capturing RAG’s contributions to the AI research and development community", "", "References", "N", " Kandpal, H", " Deng, A", " Roberts, E", " Wallace, and C", " Raffel, “Large language models struggle to learn long-tail knowledge,” in Interna- tional Conference on Machine Learning", " PMLR, 2023, pp", " 15 696– 15 707", "", "Y", " Zhang, Y", " Li, L", " Cui, D", " Cai, L", " Liu, T", " Fu, X", " Huang, E", " Zhao,", "Y", " Zhang, Y", " Chen et al", ", “Siren’s song in the ai ocean: A survey on hal- lucination in large language models,” arXiv preprint arXiv:2309", "01219, 2023", "", "D", " Arora, A", " Kini, S", " R", " Chowdhury, N", " Natarajan, G", " Sinha, and", "A", " Sharma, “Gar-meets-rag paradigm for zero-shot information re- trieval,” arXiv preprint arXiv:2310", "20158, 2023", "", "P", " Lewis, E", " Perez, A", " Piktus, F", " Petroni, V", " Karpukhin, N", " Goyal,", "H", " Ku¨ttler, M", " Lewis, W", "-t", " Yih, T", " Rockta¨schel et al", ", “Retrieval- augmented generation for knowledge-intensive nlp tasks,” Advances in Neural Information Processing Systems, vol", " 33, pp", " 9459–9474, 2020", "", "S", " Borgeaud, A", " Mensch, J", " Hoffmann, T", " Cai, E", " Rutherford, K", " Milli- can, G", " B", " Van Den Driessche, J", "-B", " Lespiau, B", " Damoc, A", " Clark et al", ", “Improving language models by retrieving from trillions of tokens,” in International conference on machine learning", " PMLR, 2022, pp", " 2206–2240", "", "L", " Ouyang, J", " Wu, X", " Jiang, D", " Almeida, C", " Wainwright, P", " Mishkin,", "C", " Zhang, S", " Agarwal, K", " Slama, A", " Ray et al", ", “Training language models to follow instructions with human feedback,” Advances in neural information processing systems, vol", " 35, pp", " 27 730–27 744,", "2022.", "X", " Ma, Y", " Gong, P", " He, H", " Zhao, and N", " Duan, “Query rewrit- ing for retrieval-augmented large language models,” arXiv preprint arXiv:2305", "14283, 2023", "", "I", "\tILIN,\t“Advanced\trag\ttechniques:\tan\til- lustrated\t\toverview,”\t\t\thttps://pub", "towardsai", "net/ advanced-rag-techniques-an-illustrated-overview-04d193d8fec6,  2023", "", "W", " Peng, G", " Li, Y", " Jiang, Z", " Wang, D", " Ou, X", " Zeng, E", " Chen et al", ", “Large language model based long-tail query rewriting in taobao search,” arXiv preprint arXiv:2311", "03758, 2023", "", "H", " S", " Zheng, S", " Mishra, X", " Chen, H", "-T", " Cheng, E", " H", " Chi, Q", " V", " Le, and D", " Zhou, “Take a step back: Evoking reasoning via abstraction in large language models,” arXiv preprint arXiv:2310", "06117, 2023", "", "L", " Gao, X", " Ma, J", " Lin, and J", " Callan, “Precise zero-shot dense retrieval without relevance labels,” arXiv preprint arXiv:2212", "10496, 2022", "", "V", " Blagojevi, “Enhancing rag pipelines in haystack: Introducing diver- sityranker and lostinthemiddleranker,” https://towardsdatascience", "com/ enhancing-rag-pipelines-in-haystack-45f14e2bc9f5, 2023", "", "W", " Yu, D", " Iter, S", " Wang, Y", " Xu, M", " Ju, S", " Sanyal, C", " Zhu, M", " Zeng, and M", " Jiang, “Generate rather than retrieve: Large language models are strong context generators,” arXiv preprint arXiv:2209", "10063, 2022", "", "Z", " Shao, Y", " Gong, Y", " Shen, M", " Huang, N", " Duan, and W", " Chen, “Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy,” arXiv preprint arXiv:2305", "15294, 2023", "", "X", " Wang, Q", " Yang, Y", " Qiu, J", " Liang, Q", " He, Z", " Gu, Y", " Xiao, and W", " Wang, “Knowledgpt: Enhancing large language models with retrieval and storage access on knowledge bases,” arXiv preprint arXiv:2308", "11761, 2023", "", "A", "   H", "   Raudaschl,   “Forget   rag,   the   future is\trag-fusion,”\thttps://towardsdatascience", "com/ forget-rag-the-future-is-rag-fusion-1147298d8ad1, 2023", "", "X", " Cheng, D", " Luo, X", " Chen, L", " Liu, D", " Zhao, and R", " Yan, “Lift yourself up: Retrieval-augmented text generation with self memory,” arXiv preprint arXiv:2305", "02437, 2023", "", "S", " Wang, Y", " Xu, Y", " Fang, Y", " Liu, S", " Sun, R", " Xu, C", " Zhu, and", "M", " Zeng, “Training data is more valuable than you think: A simple and effective method by retrieving from training data,” arXiv preprint arXiv:2203", "08773, 2022", "", "X", " Li, E", " Nie, and S", " Liang, “From classification to generation: Insights into crosslingual retrieval augmented icl,” arXiv preprint arXiv:2311", "06595, 2023", "", "D", " Cheng, S", " Huang, J", " Bi, Y", " Zhan, J", " Liu, Y", " Wang, H", " Sun,", "F", " Wei, D", " Deng, and Q", " Zhang, “Uprise: Universal prompt retrieval for improving zero-shot evaluation,” arXiv preprint arXiv:2303", "08518, 2023", "", "Z", " Dai, V", " Y", " Zhao, J", " Ma, Y", " Luan, J", " Ni, J", " Lu, A", " Bakalov, K", " Guu,", "K", " B", " Hall, and M", "-W", " Chang, “Promptagator: Few-shot dense retrieval from 8 examples,” arXiv preprint arXiv:2209", "11755, 2022", "", "Z", " Sun, X", " Wang, Y", " Tay, Y", " Yang, and D", " Zhou, “Recitation-augmented language models,” arXiv preprint arXiv:2210", "01296, 2022", "", "O", " Khattab, K", " Santhanam, X", " L", " Li, D", " Hall, P", " Liang, C", " Potts, and M", " Zaharia, “Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp,” arXiv preprint arXiv:2212", "14024, 2022", "", "Z", " Jiang, F", " F", " Xu, L", " Gao, Z", " Sun, Q", " Liu, J", " Dwivedi-Yu, Y", " Yang,", "J", " Callan, and G", " Neubig, “Active retrieval augmented generation,”", "arXiv preprint arXiv:2305", "06983, 2023", "", "A", " Asai, Z", " Wu, Y", " Wang, A", " Sil, and H", " Hajishirzi, “Self-rag: Learning to retrieve, generate, and critique through self-reflection,” arXiv preprint arXiv:2310", "11511, 2023", "", "Z", " Ke, W", " Kong, C", " Li, M", " Zhang, Q", " Mei, and M", " Bendersky, “Bridging the preference gap between retrievers and llms,” arXiv preprint arXiv:2401", "06954, 2024", "", "X", " V", " Lin, X", " Chen, M", " Chen, W", " Shi, M", " Lomeli, R", " James, P", " Ro- driguez, J", " Kahn, G", " Szilvasy, M", " Lewis et al", ", “Ra-dit: Retrieval- augmented dual instruction tuning,” arXiv preprint arXiv:2310", "01352, 2023", "", "O", " Ovadia, M", " Brief, M", " Mishaeli, and O", " Elisha, “Fine-tuning or retrieval? comparing knowledge injection in llms,” arXiv preprint arXiv:2312", "05934, 2023", "", "T", " Lan, D", " Cai, Y", " Wang, H", " Huang, and X", "-L", " Mao, “Copy is all you need,” in The Eleventh International Conference on Learning Representations, 2022", "", "T", " Chen, H", " Wang, S", " Chen, W", " Yu, K", " Ma, X", " Zhao, D", " Yu, and", "H", " Zhang, “Dense x retrieval: What retrieval granularity should we use?” arXiv preprint arXiv:2312", "06648, 2023", "", "F", " Luo and M", " Surdeanu, “Divide & conquer for entailment-aware multi-hop evidence retrieval,” arXiv preprint arXiv:2311", "02616, 2023", "", "Q", " Gou, Z", " Xia, B", " Yu, H", " Yu, F", " Huang, Y", " Li, and N", " Cam-Tu, “Diversify question generation with retrieval-augmented style transfer,” arXiv preprint arXiv:2310", "14503, 2023", "", "Z", " Guo, S", " Cheng, Y", " Wang, P", " Li, and Y", " Liu, “Prompt-guided re- trieval augmentation for non-knowledge-intensive tasks,” arXiv preprint arXiv:2305", "17653, 2023", "", "Z", " Wang, J", " Araki, Z", " Jiang, M", " R", " Parvez, and G", " Neubig, “Learning to filter context for retrieval-augmented generation,” arXiv preprint arXiv:2311", "08377, 2023", "", "M", " Seo, J", " Baek, J", " Thorne, and S", " J", " Hwang, “Retrieval-augmented data augmentation for low-resource domain tasks,” arXiv preprint arXiv:2402", "13482, 2024", "", "Y", " Ma, Y", " Cao, Y", " Hong, and A", " Sun, “Large language model is not a good few-shot information extractor, but a good reranker for hard samples!” arXiv preprint arXiv:2303", "08559, 2023", "", "X", " Du and H", " Ji, “Retrieval-augmented generative question answering for event argument extraction,” arXiv preprint arXiv:2211", "07067, 2022", "", "L", " Wang, N", " Yang, and F", " Wei, “Learning to retrieve in-context examples for large language models,” arXiv preprint arXiv:2307", "07164, 2023", "", "S", " Rajput, N", " Mehta, A", " Singh, R", " H", " Keshavan, T", " Vu, L", " Heldt,", "L", " Hong, Y", " Tay, V", " Q", " Tran, J", " Samost et al", ", “Recommender systems with generative retrieval,” arXiv preprint arXiv:2305", "05065, 2023", "", "B", " Jin, H", " Zeng, G", " Wang, X", " Chen, T", " Wei, R", " Li, Z", " Wang, Z", " Li,", "Y", " Li, H", " Lu et al", ", “Language models as semantic indexers,” arXiv preprint arXiv:2310", "07815, 2023", "", "R", " Anantha, T", " Bethi, D", " Vodianik, and S", " Chappidi, “Context tuning for retrieval augmented generation,” arXiv preprint arXiv:2312", "05708, 2023", "", "G", " Izacard, P", " Lewis, M", " Lomeli, L", " Hosseini, F", " Petroni, T", " Schick,", "J", " Dwivedi-Yu, A", " Joulin, S", " Riedel, and E", " Grave, “Few-shot learning with retrieval augmented language models,” arXiv preprint arXiv:2208", "03299, 2022", "", "J", " Huang, W", " Ping, P", " Xu, M", " Shoeybi, K", " C", "-C", " Chang, and B", " Catan- zaro, “Raven: In-context learning with retrieval augmented encoder- decoder language models,” arXiv preprint arXiv:2308", "07922, 2023", "", "B", " Wang, W", " Ping, P", " Xu, L", " McAfee, Z", " Liu, M", " Shoeybi, Y", " Dong,", "O", " Kuchaiev, B", " Li, C", " Xiao et al", ", “Shall we pretrain autoregressive language models with retrieval? a comprehensive study,” arXiv preprint arXiv:2304", "06762, 2023", "", "B", " Wang, W", " Ping, L", " McAfee, P", " Xu, B", " Li, M", " Shoeybi, and B", " Catan- zaro, “Instructretro: Instruction tuning post retrieval-augmented pre- training,” arXiv preprint arXiv:2310", "07713, 2023", "", "S", " Siriwardhana, R", " Weerasekera, E", " Wen, T", " Kaluarachchi, R", " Rana, and S", " Nanayakkara, “Improving the domain adaptation of retrieval augmented generation (rag) models for open domain question answer- ing,” Transactions of the Association for Computational Linguistics, vol", " 11, pp", " 1–17, 2023", "", "Z", " Yu, C", " Xiong, S", " Yu, and Z", " Liu, “Augmentation-adapted retriever improves generalization of language models as generic plug-in,” arXiv preprint arXiv:2305", "17331, 2023", "", "O", " Yoran, T", " Wolfson, O", " Ram, and J", " Berant, “Making retrieval- augmented language models robust to irrelevant context,” arXiv preprint arXiv:2310", "01558, 2023", "", "H", "-T", " Chen, F", " Xu, S", " A", " Arora, and E", " Choi, “Understanding re- trieval augmentation for long-form question answering,” arXiv preprint arXiv:2310", "12150, 2023", "", "W", " Yu, H", " Zhang, X", " Pan, K", " Ma, H", " Wang, and D", " Yu, “Chain-of-note: Enhancing robustness in retrieval-augmented language models,” arXiv preprint arXiv:2311", "09210, 2023", "", "S", " Xu, L", " Pang, H", " Shen, X", " Cheng, and T", "-S", " Chua, “Search-in-the- chain: Towards accurate, credible and traceable large language models for knowledgeintensive tasks,” CoRR, vol", " abs/2304", "14732, 2023", "", "M", " Berchansky, P", " Izsak, A", " Caciularu, I", " Dagan, and M", " Wasserblat, “Optimizing retrieval-augmented reader models via token elimination,” arXiv preprint arXiv:2310", "13682, 2023", "", "J", " La´la, O", " O’Donoghue, A", " Shtedritski, S", " Cox, S", " G", " Rodriques, and A", " D", " White, “Paperqa: Retrieval-augmented generative agent for scientific research,” arXiv preprint arXiv:2312", "07559, 2023", "", "F", " Cuconasu, G", " Trappolini, F", " Siciliano, S", " Filice, C", " Campagnano,", "Y", " Maarek, N", " Tonellotto, and F", " Silvestri, “The power of noise: Redefining retrieval for rag systems,” arXiv preprint arXiv:2401", "14887, 2024", "", "Z", " Zhang, X", " Zhang, Y", " Ren, S", " Shi, M", " Han, Y", " Wu, R", " Lai, and", "Z", " Cao, “Iag: Induction-augmented generation framework for answer- ing reasoning questions,” in Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, 2023, pp", " 1–14", "", "N", " Thakur, L", " Bonifacio, X", " Zhang, O", " Ogundepo, E", " Kamalloo,", "D", " Alfonso-Hermelo, X", " Li, Q", " Liu, B", " Chen, M", " Rezagholizadeh et al", ", “Nomiracl: Knowing when you don’t know for robust multilingual retrieval-augmented generation,” arXiv preprint arXiv:2312", "11361, 2023", "", "G", " Kim, S", " Kim, B", " Jeon, J", " Park, and J", " Kang, “Tree of clarifica- tions: Answering ambiguous questions with retrieval-augmented large language models,” arXiv preprint arXiv:2310", "14696, 2023", "", "Y", " Wang, P", " Li, M", " Sun, and Y", " Liu, “Self-knowledge guided retrieval augmentation for large language models,” arXiv preprint arXiv:2310", "05002, 2023", "", "Z", " Feng, X", " Feng, D", " Zhao, M", " Yang, and B", " Qin, “Retrieval- generation synergy augmented large language models,” arXiv preprint arXiv:2310", "05149, 2023", "", "P", " Xu, W", " Ping, X", " Wu, L", " McAfee, C", " Zhu, Z", " Liu, S", " Subramanian,", "E", " Bakhturina, M", " Shoeybi, and B", " Catanzaro, “Retrieval meets long context large language models,” arXiv preprint arXiv:2310", "03025, 2023", "", "H", " Trivedi, N", " Balasubramanian, T", " Khot, and A", " Sabharwal, “Interleav- ing retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions,” arXiv preprint arXiv:2212", "10509, 2022", "", "R", " Ren, Y", " Wang, Y", " Qu, W", " X", " Zhao, J", " Liu, H", " Tian, H", " Wu, J", "-", "R", " Wen, and H", " Wang, “Investigating the factual knowledge boundary of large language models with retrieval augmentation,” arXiv preprint arXiv:2307", "11019, 2023", "", "P", " Sarthi, S", " Abdullah, A", " Tuli, S", " Khanna, A", " Goldie, and C", " D", " Manning, “Raptor: Recursive abstractive processing for tree-organized retrieval,” arXiv preprint arXiv:2401", "18059, 2024", "", "O", " Ram, Y", " Levine, I", " Dalmedigos, D", " Muhlgay, A", " Shashua, K", " Leyton- Brown, and Y", " Shoham, “In-context retrieval-augmented language models,” arXiv preprint arXiv:2302", "00083, 2023", "", "Y", " Ren, Y", " Cao, P", " Guo, F", " Fang, W", " Ma, and Z", " Lin, “Retrieve-and- sample: Document-level event argument extraction via hybrid retrieval augmentation,” in Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2023, pp", " 293–306", "", "Z", " Wang, X", " Pan, D", " Yu, D", " Yu, J", " Chen, and H", " Ji, “Zemi: Learning zero-shot semi-parametric language models from multiple tasks,” arXiv preprint arXiv:2210", "00185, 2022", "", "S", "-Q", " Yan, J", "-C", " Gu, Y", " Zhu, and Z", "-H", " Ling, “Corrective retrieval augmented generation,” arXiv preprint arXiv:2401", "15884, 2024", "", "P", " Jain, L", " B", " Soares, and T", " Kwiatkowski, “1-pager: One pass answer generation and evidence retrieval,” arXiv preprint arXiv:2310", "16568, 2023", "", "H", " Yang, Z", " Li, Y", " Zhang, J", " Wang, N", " Cheng, M", " Li, and J", " Xiao, “Prca: Fitting black-box large language models for retrieval question answer- ing via pluggable reward-driven contextual adapter,” arXiv preprint arXiv:2310", "18347, 2023", "", "S", " Zhuang, B", " Liu, B", " Koopman, and G", " Zuccon, “Open-source large language models are strong zero-shot query likelihood models for document ranking,” arXiv preprint arXiv:2310", "13243, 2023", "", "F", " Xu, W", " Shi, and E", " Choi, “Recomp: Improving retrieval-augmented lms with compression and selective augmentation,” arXiv preprint arXiv:2310", "04408, 2023", "", "W", " Shi, S", " Min, M", " Yasunaga, M", " Seo, R", " James, M", " Lewis, L", " Zettle- moyer, and W", "-t", " Yih, “Replug: Retrieval-augmented black-box lan- guage models,” arXiv preprint arXiv:2301", "12652, 2023", "", "E", " Melz, “Enhancing llm intelligence with arm-rag: Auxiliary ra- tionale memory for retrieval augmented generation,” arXiv preprint arXiv:2311", "04177, 2023", "", "H", " Wang, W", " Huang, Y", " Deng, R", " Wang, Z", " Wang, Y", " Wang, F", " Mi,", "J", " Z", " Pan, and K", "-F", " Wong, “Unims-rag: A unified multi-source retrieval-augmented generation for personalized dialogue systems,” arXiv preprint arXiv:2401", "13256, 2024", "", "Z", " Luo, C", " Xu, P", " Zhao, X", " Geng, C", " Tao, J", " Ma, Q", " Lin, and D", " Jiang, “Augmented large language models with parametric knowledge guid- ing,” arXiv preprint arXiv:2305", "04757, 2023", "", "X", " Li, Z", " Liu, C", " Xiong, S", " Yu, Y", " Gu, Z", " Liu, and G", " Yu, “Structure- aware language model pretraining improves dense retrieval on struc- tured data,” arXiv preprint arXiv:2305", "19912, 2023", "", "M", " Kang, J", " M", " Kwak, J", " Baek, and S", " J", " Hwang, “Knowledge graph-augmented language models for knowledge-grounded dialogue generation,” arXiv preprint arXiv:2305", "18846, 2023", "", "W", " Shen, Y", " Gao, C", " Huang, F", " Wan, X", " Quan, and W", " Bi, “Retrieval- generation alignment for end-to-end task-oriented dialogue system,” arXiv preprint arXiv:2310", "08877, 2023", "", "T", " Shi, L", " Li, Z", " Lin, T", " Yang, X", " Quan, and Q", " Wang, “Dual-feedback knowledge retrieval for task-oriented dialogue systems,” arXiv preprint arXiv:2310", "14528, 2023", "", "P", " Ranade and A", " Joshi, “Fabula: Intelligence report generation using retrieval-augmented narrative construction,” arXiv preprint arXiv:2310", "13848, 2023", "", "X", " Jiang, R", " Zhang, Y", " Xu, R", " Qiu, Y", " Fang, Z", " Wang, J", " Tang,", "H", " Ding, X", " Chu, J", " Zhao et al", ", “Think and retrieval: A hypothesis knowledge graph enhanced medical large language models,” arXiv preprint arXiv:2312", "15883, 2023", "", "J", " Baek, S", " Jeong, M", " Kang, J", " C", " Park, and S", " J", " Hwang, “Knowledge-augmented language model verification,” arXiv preprint arXiv:2310", "12836, 2023", "", "L", " Luo, Y", "-F", " Li, G", " Haffari, and S", " Pan, “Reasoning on graphs: Faithful and interpretable large language model reasoning,” arXiv preprint arXiv:2310", "01061, 2023", "", "X", " He, Y", " Tian, Y", " Sun, N", " V", " Chawla, T", " Laurent, Y", " LeCun,", "X", " Bresson, and B", " Hooi, “G-retriever: Retrieval-augmented generation for textual graph understanding and question answering,” arXiv preprint arXiv:2402", "07630, 2024", "", "L", " Zha, J", " Zhou, L", " Li, R", " Wang, Q", " Huang, S", " Yang, J", " Yuan, C", " Su,", "X", " Li, A", " Su et al", ", “Tablegpt: Towards unifying tables, nature language and commands into one gpt,” arXiv preprint arXiv:2307", "08674, 2023", "", "M", " Gaur, K", " Gunaratna, V", " Srinivasan, and H", " Jin, “Iseeq: Information seeking question generation using dynamic meta-information retrieval and knowledge graphs,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol", " 36, no", " 10, 2022, pp", " 10 672–10 680", "", "F", " Shi, X", " Chen, K", " Misra, N", " Scales, D", " Dohan, E", " H", " Chi, N", " Scha¨rli, and D", " Zhou, “Large language models can be easily distracted by irrelevant context,” in International Conference on Machine Learning", " PMLR, 2023, pp", " 31 210–31 227", "", "R", " Teja, “Evaluating the ideal chunk size for a rag system  using  llamaindex,”  https://www", "llamaindex", "ai/blog/", "evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5, 2023.", "Langchain, “Recursively split by character,” https://python", "langchain", " com/docs/modules/data connection/document transformers/recursive text splitter, 2023", "", "S", "\tYang,\t\t“Advanced\t\trag\t01:\tSmall-to- big\t\tretrieval,”\thttps://towardsdatascience", "com/ advanced-rag-01-small-to-big-retrieval-172181b396d4, 2023", "", "Y", " Wang, N", " Lipka, R", " A", " Rossi, A", " Siu, R", " Zhang, and T", " Derr, “Knowledge graph prompting for multi-document question answering,” arXiv preprint arXiv:2308", "11730, 2023", "", "D", " Zhou, N", " Scha¨rli, L", " Hou, J", " Wei, N", " Scales, X", " Wang, D", " Schu- urmans, C", " Cui, O", " Bousquet, Q", " Le et al", ", “Least-to-most prompting enables complex reasoning in large language models,” arXiv preprint arXiv:2205", "10625, 2022", "", "S", " Dhuliawala, M", " Komeili, J", " Xu, R", " Raileanu, X", " Li, A", " Celikyilmaz, and J", " Weston, “Chain-of-verification reduces hallucination in large language models,” arXiv preprint arXiv:2309", "11495, 2023", "", "X", " Li and J", " Li, “Angle-optimized text embeddings,” arXiv preprint arXiv:2309", "12871, 2023", "", "VoyageAI, “Voyage’s embedding models,” https://docs", "voyageai", "com/ embeddings/, 2023", "", "BAAI,\t“Flagembedding,”\thttps://github", "com/FlagOpen/ FlagEmbedding, 2023", "", "P", " Zhang, S", " Xiao, Z", " Liu, Z", " Dou, and J", "-Y", " Nie, “Retrieve anything to augment large language models,” arXiv preprint arXiv:2310", "07554, 2023", "", "N", " F", " Liu, K", " Lin, J", " Hewitt, A", " Paranjape, M", " Bevilacqua, F", " Petroni, and P", " Liang, “Lost in the middle: How language models use long contexts,” arXiv preprint arXiv:2307", "03172, 2023", "", "Y", " Gao, T", " Sheng, Y", " Xiang, Y", " Xiong, H", " Wang, and J", " Zhang, “Chat- rec: Towards interactive and explainable llms-augmented recommender system,” arXiv preprint arXiv:2303", "14524, 2023", "", "N", " Anderson, C", " Wilson, and S", " D", " Richardson, “Lingua: Addressing scenarios for live interpretation and automatic dubbing,” in Proceedings of the 15th Biennial Conference of the Association for Machine Translation in the Americas (Volume 2: Users and Providers Track and Government Track), J", " Campbell, S", " Larocca, J", " Marciano,", "K", " Savenkov, and A", " Yanishevsky, Eds", " Orlando, USA: Association for Machine Translation in the Americas, Sep", " 2022, pp", " 202–209", " [Online]", " Available: https://aclanthology", "org/2022", "amta-upg", "14", "H", " Jiang, Q", " Wu, X", " Luo, D", " Li, C", "-Y", " Lin, Y", " Yang, and L", " Qiu, “Longllmlingua: Accelerating and enhancing llms in long context scenarios via prompt compression,” arXiv preprint arXiv:2310", "06839, 2023", "", "V", " Karpukhin, B", " Og˘uz, S", " Min, P", " Lewis, L", " Wu, S", " Edunov, D", " Chen, and W", "-t", " Yih, “Dense passage retrieval for open-domain question answering,” arXiv preprint arXiv:2004", "04906, 2020", "", "Y", " Ma, Y", " Cao, Y", " Hong, and A", " Sun, “Large language model is not a good few-shot information extractor, but a good reranker for hard samples!” ArXiv, vol", " abs/2303", "08559, 2023", " [Online]", " Available: https://api", "semanticscholar", "org/CorpusID:257532405", "J", " Cui, Z", " Li, Y", " Yan, B", " Chen, and L", " Yuan, “Chatlaw: Open-source legal large language model with integrated external knowledge bases,” arXiv preprint arXiv:2306", "16092, 2023", "", "O", " Yoran, T", " Wolfson, O", " Ram, and J", " Berant, “Making retrieval- augmented language models robust to irrelevant context,” arXiv preprint arXiv:2310", "01558, 2023", "", "X", " Li, R", " Zhao, Y", " K", " Chia, B", " Ding, L", " Bing, S", " Joty, and S", " Poria, “Chain of knowledge: A framework for grounding large language mod- els with structured knowledge bases,” arXiv preprint arXiv:2305", "13269, 2023", "", "H", " Yang, S", " Yue, and Y", " He, “Auto-gpt for online decision making: Benchmarks and additional opinions,” arXiv preprint arXiv:2306", "02224, 2023", "", "T", " Schick, J", " Dwivedi-Yu, R", " Dess`ı, R", " Raileanu, M", " Lomeli, L", " Zettle- moyer, N", " Cancedda, and T", " Scialom, “Toolformer: Language models can teach themselves to use tools,” arXiv preprint arXiv:2302", "04761, 2023", "", "J", " Zhang, “Graph-toolformer: To empower llms with graph rea- soning ability via prompt augmented by chatgpt,” arXiv preprint arXiv:2304", "11116, 2023", "", "R", " Nakano, J", " Hilton, S", " Balaji, J", " Wu, L", " Ouyang, C", " Kim,", "C", " Hesse, S", " Jain, V", " Kosaraju, W", " Saunders et al", ", “Webgpt: Browser-", "of the Association for Computational Linguistics, vol", " 7, pp", " 453–466, 2019", "", "Y", " Liu, S", " Yavuz, R", " Meng, M", " Moorthy, S", " Joty, C", " Xiong, and Y", " Zhou, “Exploring the integration strategies of retriever and large language models,” arXiv preprint arXiv:2308", "12574, 2023", "", "M", " Joshi, E", " Choi, D", " S", " Weld, and L", " Zettlemoyer, “Triviaqa: A large scale distantly supervised challenge dataset for reading comprehen- sion,” arXiv preprint arXiv:1705", "03551, 2017", "", "P", " Rajpurkar, J", " Zhang, K", " Lopyrev, and P", " Liang, “Squad: 100,000+ questions for machine comprehension of text,” arXiv preprint arXiv:1606", "05250, 2016", "", "J", " Berant, A", " Chou, R", " Frostig, and P", " Liang, “Semantic parsing on freebase from question-answer pairs,” in Proceedings of the 2013 conference on empirical methods in natural language processing, 2013,", "pp", " 1533–1544", "", "A", " Mallen, A", " Asai, V", " Zhong, R", " Das, H", " Hajishirzi, and D", " Khashabi, “When not to trust language models: Investigating effectiveness and limitations of parametric and non-parametric memories,” arXiv preprint arXiv:2212", "10511, 2022", "", "T", " Nguyen, M", " Rosenberg, X", " Song, J", " Gao, S", " Tiwary, R", " Majumder, and L", " Deng, “Ms marco: A human-generated machine reading com- prehension dataset,” 2016", "", "Z", " Yang, P", " Qi, S", " Zhang, Y", " Bengio, W", " W", " Cohen, R", " Salakhutdi- nov, and C", " D", " Manning, “Hotpotqa: A dataset for diverse, explain- able multi-hop question answering,” arXiv preprint arXiv:1809", "09600, 2018", "", "X", " Ho, A", "-K", " D", " Nguyen, S", " Sugawara, and A", " Aizawa, “Constructing a multi-hop qa dataset for comprehensive evaluation of reasoning steps,” arXiv preprint arXiv:2011", "01060, 2020", "", "H", " Trivedi, N", " Balasubramanian, T", " Khot, and A", " Sabharwal, “Musique: Multihop questions via single-hop question composition,” Transactions of the Association for Computational Linguistics, vol", " 10, pp", " 539–554, 2022", "", "A", " Fan, Y", " Jernite, E", " Perez, D", " Grangier, J", " Weston, and M", " Auli, “Eli5: Long form question answering,” arXiv preprint arXiv:1907", "09190, 2019", "", "T", " Kocˇisky`, J", " Schwarz, P", " Blunsom, C", " Dyer, K", " M", " Hermann, G", " Melis, and E", " Grefenstette, “The narrativeqa reading comprehension chal- lenge,” Transactions of the Association for Computational Linguistics, vol", " 6, pp", " 317–328, 2018", "", "K", "-H", " Lee, X", " Chen, H", " Furuta, J", " Canny, and I", " Fischer, “A human- inspired reading agent with gist memory of very long contexts,” arXiv preprint arXiv:2402", "09727, 2024", "", "I", " Stelmakh, Y", " Luan, B", " Dhingra, and M", "-W", " Chang, “Asqa: Factoid questions meet long-form answers,” arXiv preprint arXiv:2204", "06092, 2022", "", "M", " Zhong, D", " Yin, T", " Yu, A", " Zaidi, M", " Mutuma, R", " Jha, A", " H", " Awadallah, A", " Celikyilmaz, Y", " Liu, X", " Qiu et al", ", “Qmsum: A new benchmark for query-based multi-domain meeting summarization,” arXiv preprint arXiv:2104", "05938, 2021", "", "P", " Dasigi, K", " Lo, I", " Beltagy, A", " Cohan, N", " A", " Smith, and M", " Gardner, “A dataset of information-seeking questions and answers anchored in research papers,” arXiv preprint arXiv:2105", "03011, 2021", "", "T", " Mo¨ller, A", " Reina, R", " Jayakumar, and M", " Pietsch, “Covid-qa: A question answering dataset for covid-19,” in ACL 2020 Workshop on Natural Language Processing for COVID-19 (NLP-COVID), 2020", "", "X", " Wang, G", " H", " Chen, D", " Song, Z", " Zhang, Z", " Chen, Q", " Xiao, F", " Jiang,", "J", " Li, X", " Wan, B", " Wang et al", ", “Cmb: A comprehensive medical benchmark in chinese,” arXiv preprint arXiv:2308", "08833, 2023", "", "H", " Zeng, “Measuring massive multitask chinese understanding,” arXiv preprint arXiv:2304", "12986, 2023", "", "R", " Y", " Pang, A", " Parrish, N", " Joshi, N", " Nangia, J", " Phang, A", " Chen, V", " Pad- makumar, J", " Ma, J", " Thompson, H", " He et al", ", “Quality: Question an- swering with long input texts, yes!” arXiv preprint arXiv:2112", "08608, 2021", "", "P", " Clark, I", " Cowhey, O", " Etzioni, T", " Khot, A", " Sabharwal, C", " Schoenick, and O", " Tafjord, “Think you have solved question answering? try arc, the ai2 reasoning challenge,” arXiv preprint arXiv:1803", "05457, 2018", "", "A", " Talmor, J", " Herzig, N", " Lourie, and J", " Berant, “Commonsenseqa: A question answering challenge targeting commonsense knowledge,” arXiv preprint arXiv:1811", "00937, 2018", "", "planner for personalized knowledge-grounded dialogue,” arXiv preprint arXiv:2310", "08840, 2023", "", "——, “Large language models as source planner for personal- ized knowledge-grounded dialogue,” arXiv preprint arXiv:2310", "08840, 2023", "", "X", " Xu, Z", " Gou, W", " Wu, Z", "-Y", " Niu, H", " Wu, H", " Wang, and S", " Wang, “Long time no see! open-domain conversation with long-term persona memory,” arXiv preprint arXiv:2203", "05797, 2022", "", "T", "-H", " Wen, M", " Gasic, N", " Mrksic, L", " M", " Rojas-Barahona, P", "-H", " Su, S", " Ultes, D", " Vandyke, and S", " Young, “Conditional generation and snapshot learning in neural dialogue systems,” arXiv preprint arXiv:1606", "03352, 2016", "", "R", " He and J", " McAuley, “Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering,” in proceedings of the 25th international conference on world wide web, 2016, pp", " 507–517", "", "S", " Li, H", " Ji, and J", " Han, “Document-level event argument extraction by conditional generation,” arXiv preprint arXiv:2104", "05919, 2021", "", "S", " Ebner, P", " Xia, R", " Culkin, K", " Rawlins, and B", " Van Durme, “Multi- sentence argument linking,” arXiv preprint arXiv:1911", "03766, 2019", "", "H", " Elsahar, P", " Vougiouklis, A", " Remaci, C", " Gravier, J", " Hare, F", " Laforest, and E", " Simperl, “T-rex: A large scale alignment of natural language with knowledge base triples,” in Proceedings of the Eleventh Inter- national Conference on Language Resources and Evaluation (LREC 2018), 2018", "", "O", " Levy, M", " Seo, E", " Choi, and L", " Zettlemoyer, “Zero-shot relation ex- traction via reading comprehension,” arXiv preprint arXiv:1706", "04115, 2017", "", "R", " Zellers, A", " Holtzman, Y", " Bisk, A", " Farhadi, and Y", " Choi, “Hel- laswag: Can a machine really finish your sentence?” arXiv preprint arXiv:1905", "07830, 2019", "", "S", " Kim, S", " J", " Joo, D", " Kim, J", " Jang, S", " Ye, J", " Shin, and M", " Seo, “The cot collection: Improving zero-shot and few-shot learning of language models via chain-of-thought fine-tuning,” arXiv preprint arXiv:2305", "14045, 2023", "", "A", " Saha, V", " Pahuja, M", " Khapra, K", " Sankaranarayanan, and S", " Chandar, “Complex sequential question answering: Towards learning to converse over linked question answer pairs with a knowledge graph,” in Proceed- ings of the AAAI conference on artificial intelligence, vol", " 32, no", " 1, 2018", "", "D", " Hendrycks, C", " Burns, S", " Basart, A", " Zou, M", " Mazeika, D", " Song, and", "J. Steinhardt, “Measuring massive multitask language understanding,”", "arXiv preprint arXiv:2009", "03300, 2020", "", "S", " Merity, C", " Xiong, J", " Bradbury, and R", " Socher, “Pointer sentinel mixture models,” arXiv preprint arXiv:1609", "07843, 2016", "", "M", " Geva, D", " Khashabi, E", " Segal, T", " Khot, D", " Roth, and J", " Berant, “Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies,” Transactions of the Association for Computational Linguistics, vol", " 9, pp", " 346–361, 2021", "", "J", " Thorne, A", " Vlachos, C", " Christodoulopoulos, and A", " Mittal, “Fever: a large-scale dataset for fact extraction and verification,” arXiv preprint arXiv:1803", "05355, 2018", "", "N", " Kotonya and F", " Toni, “Explainable automated fact-checking for public health claims,” arXiv preprint arXiv:2010", "09926, 2020", "", "R", " Lebret, D", " Grangier, and M", " Auli, “Neural text generation from structured data with application to the biography domain,” arXiv preprint arXiv:1603", "07771, 2016", "", "H", " Hayashi, P", " Budania, P", " Wang, C", " Ackerson, R", " Neervannan, and G", " Neubig, “Wikiasp: A dataset for multi-domain aspect-based summarization,” Transactions of the Association for Computational Linguistics, vol", " 9, pp", " 211–225, 2021", "", "S", " Narayan, S", " B", " Cohen, and M", " Lapata, “Don’t give me the details, just the summary! topic-aware convolutional neural networks for ex- treme summarization,” arXiv preprint arXiv:1808", "08745, 2018", "", "S", " Saha, J", " A", " Junaed, M", " Saleki, A", " S", " Sharma, M", " R", " Rifat, M", " Rahouti,", "S", " I", " Ahmed, N", " Mohammed, and M", " R", " Amin, “Vio-lens: A novel dataset of annotated social network posts leading to different forms of communal violence and its evaluation,” in Proceedings of the First Workshop on Bangla Language Processing (BLP-2023), 2023, pp", " 72– 84", "", "X", " Li and D", " Roth, “Learning question classifiers,” in COLING 2002: The 19th International Conference on Computational Linguistics, 2002", "", "R", " Socher, A", " Perelygin, J", " Wu, J", " Chuang, C", " D", " Manning, A", " Y", " Ng, and C", " Potts, “Recursive deep models for semantic compositionality over a sentiment treebank,” in Proceedings of the 2013 conference on empirical methods in natural language processing, 2013, pp", " 1631– 1642", "", "H", " Husain, H", "-H", " Wu, T", " Gazit, M", " Allamanis, and M", " Brockschmidt, “Codesearchnet challenge: Evaluating the state of semantic code search,” arXiv preprint arXiv:1909", "09436, 2019", "", "K", " Cobbe, V", " Kosaraju, M", " Bavarian, M", " Chen, H", " Jun, L", " Kaiser,", "M", " Plappert, J", " Tworek, J", " Hilton, R", " Nakano et al", ", “Training verifiers to solve math word problems,” arXiv preprint arXiv:2110", "14168, 2021", "", "R", " Steinberger, B", " Pouliquen, A", " Widiger, C", " Ignat, T", " Erjavec, D", " Tufis, and D", " Varga, “The jrc-acquis: A multilingual aligned parallel corpus with 20+ languages,” arXiv preprint cs/0609058, 2006", "", "Y", " Hoshi, D", " Miyashita, Y", " Ng, K", " Tatsuno, Y", " Morioka, O", " Torii, and J", " Deguchi, “Ralle: A framework for developing and eval- uating retrieval-augmented large language models,” arXiv preprint arXiv:2308", "10633, 2023", "", "J", " Liu, “Building production-ready rag applications,” https://www", "ai", " engineer/summit/schedule/building-production-ready-rag-applications, 2023", "", "I", " Nguyen, “Evaluating rag part i: How to evaluate document retrieval,” https://www", "deepset", "ai/blog/rag-evaluation-retrieval, 2023", "", "Q", " Leng, K", " Uhlenhuth, and A", " Polyzotis, “Best practices for llm evaluation of rag applications,” https://www", "databricks", "com/blog/ LLM-auto-eval-best-practices-RAG, 2023", "", "S", " Es, J", " James, L", " Espinosa-Anke, and S", " Schockaert, “Ragas: Au- tomated evaluation of retrieval augmented generation,” arXiv preprint arXiv:2309", "15217, 2023", "", "J", " Saad-Falcon, O", " Khattab, C", " Potts, and M", " Zaharia, “Ares: An automated evaluation framework for retrieval-augmented generation systems,” arXiv preprint arXiv:2311", "09476, 2023", "", "C", " Jarvis and J", " Allard, “A survey of techniques for maximizing llm performance,” https://community", "openai", " com/t/openai-dev-day-2023-breakout-sessions/505213#", "a-survey-of-techniques-for-maximizing-llm-performance-2, 2023.", "J", " Chen, H", " Lin, X", " Han, and L", " Sun, “Benchmarking large lan- guage models in retrieval-augmented generation,” arXiv preprint arXiv:2309", "01431, 2023", "", "Y", " Liu, L", " Huang, S", " Li, S", " Chen, H", " Zhou, F", " Meng, J", " Zhou, and", "X", " Sun, “Recall: A benchmark for llms robustness against external counterfactual knowledge,” arXiv preprint arXiv:2311", "08147, 2023", "", "Y", " Lyu, Z", " Li, S", " Niu, F", " Xiong, B", " Tang, W", " Wang, H", " Wu, H", " Liu,", "T", " Xu, and E", " Chen, “Crud-rag: A comprehensive chinese benchmark for retrieval-augmented generation of large language models,” arXiv preprint arXiv:2401", "17043, 2024", "", "P", " Xu, W", " Ping, X", " Wu, L", " McAfee, C", " Zhu, Z", " Liu, S", " Subramanian,", "E", " Bakhturina, M", " Shoeybi, and B", " Catanzaro, “Retrieval meets long context large language models,” arXiv preprint arXiv:2310", "03025, 2023", "", "C", " Packer, V", " Fang, S", " G", " Patil, K", " Lin, S", " Wooders, and J", " E", " Gon- zalez, “Memgpt: Towards llms as operating systems,” arXiv preprint arXiv:2310", "08560, 2023", "", "G", " Xiao, Y", " Tian, B", " Chen, S", " Han, and M", " Lewis, “Efficient streaming language models with attention sinks,” arXiv preprint arXiv:2309", "17453, 2023", "", "T", " Zhang, S", " G", " Patil, N", " Jain, S", " Shen, M", " Zaharia, I", " Stoica, and J", " E", " Gonzalez, “Raft: Adapting language model to domain specific rag,” arXiv preprint arXiv:2403", "10131, 2024", "", "J", " Kaplan, S", " McCandlish, T", " Henighan, T", " B", " Brown, B", " Chess,", "R", " Child, S", " Gray, A", " Radford, J", " Wu, and D", " Amodei, “Scaling laws for neural language models,” arXiv preprint arXiv:2001", "08361, 2020", "", "U", " Alon, F", " Xu, J", " He, S", " Sengupta, D", " Roth, and G", " Neubig, “Neuro- symbolic language modeling with automaton-augmented retrieval,” in International Conference on Machine Learning", " PMLR, 2022, pp", " 468–485", "", "M", " Yasunaga, A", " Aghajanyan, W", " Shi, R", " James, J", " Leskovec, P", " Liang,", "M", " Lewis, L", " Zettlemoyer, and W", "-t", " Yih, “Retrieval-augmented multi- modal language modeling,” arXiv preprint arXiv:2211", "12561, 2022", "", "J", " Li, D", " Li, S", " Savarese, and S", " Hoi, “Blip-2: Bootstrapping language- image pre-training with frozen image encoders and large language models,” arXiv preprint arXiv:2301", "12597, 2023", "", "W", " Zhu, A", " Yan, Y", " Lu, W", " Xu, X", " E", " Wang, M", " Eckstein, and W", " Y", " Wang, “Visualize before you write: Imagination-guided open-ended text generation,” arXiv preprint arXiv:2210", "03765, 2022", "", "J", " Zhao, G", " Haffar, and E", " Shareghi, “Generating synthetic speech from spokenvocab for speech translation,” arXiv preprint arXiv:2210", "08174, 2022", "", "D", " M", " Chan, S", " Ghosh, A", " Rastrow, and B", " Hoffmeister, “Using external off-policy speech-to-text mappings in contextual end-to-end automated speech recognition,” arXiv preprint arXiv:2301", "02736, 2023", "", "A", " Yang, A", " Nagrani, P", " H", " Seo, A", " Miech, J", " Pont-Tuset, I", " Laptev,", "J", " Sivic, and C", " Schmid, “Vid2seq: Large-scale pretraining of a visual language model for dense video captioning,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, pp", " 10 714–10 726", "", "N", " Nashid, M", " Sintaha, and A", " Mesbah, “Retrieval-based prompt selection for code-related few-shot learning,” in 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE), 2023, pp", " 2450–2462", ""], "2312.10997v5.docx"]
